[
    "ModelGame: A Quality Model for Gamified Software Modeling\nLearning\nEd Wilson J\u00fanior\u2217\nUniversidade do Vale do Rio dos Sinos\nS\u00e3o Leopoldo, Rio Grande do Sul, Brazil\nedwjr7@edu.unisinos.brKleinner Farias\nUniversidade do Vale do Rio dos Sinos\nS\u00e3o Leopoldo, Rio Grande do Sul, Brazil\nkleinnerfarias@unisinos.br\nABSTRACT\nGamification has been adopted in software development tasks in\nrecent years. This adoption seeks, for example, to improve the en-\ngagement of developers while creating UML models or writing\ncode. Empirical studies report that UML models suffer from incom-\npleteness and inconsistency problems. This study conjectures that\ngamification mechanics can improve learner engagement while\nlearning software modeling, mitigating such problems concern-\ning UML models. The current literature lacks studies that explore\ngamification and UML model quality in the context of software\nmodeling learning. This article, therefore, proposes ModelGame ,\nwhich is a quality model to support software modeling learning in a\ngamified way. It serves as a reference framework so that instructors\ncan obtain a parameterized way to evaluate UML models created\nby learners. The quality of UML models can be improved by apply-\ning gamified activities and providing guidelines aware of quality\nissues. A qualitative questionnaire was answered by 19 instructors\nwho teach software modeling at higher education institutions. The\nresults show that (1) 94.7% recognize that the proposed model can\nimprove the quality of UML models, indicating that they would\nadopt the ModelGame in their learning practices; and (2) 47.4% do\nnot use any gamification mechanics in their classes. The results are\nencouraging, showing the potential for applying and improving\nthe teaching and learning of software modeling.\nCCS CONCEPTS\n\u2022Software and its engineering \u2192Software design engineer-\ning.\nKEYWORDS\nModel design, learning model, Gamification\nACM Reference Format:\nEd Wilson J\u00fanior and Kleinner Farias. 2021. ModelGame: A Quality Model\nfor Gamified Software Modeling Learning. In 15th Brazilian Symposium\non Software Components, Architectures, and Reuse (SBCARS \u201921), September\n27-October 1, 2021, Joinville, Brazil. ACM, New York, NY, USA, 10 pages.\nhttps://doi.org/10.1145/3483899.3483910\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nSBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil\n\u00a92021 Association for Computing Machinery.\nACM ISBN 978-1-4503-8419-3/21/09. . . $15.00\nhttps://doi.org/10.1145/3483899.34839101 INTRODUCTION\nGamification has been adopted in software development tasks in\nrecent years. This adoption seeks, for example, to improve the en-\ngagement of developers while creating UML models or writing\ncode. Empirical studies [ 7,9,14] report that UML models suffer\nfrom incompleteness and inconsistency problems. Lange [ 14] rein-\nforces that these defects bring potential risks that can cause mis-\ninterpretation and communication failure, representing a risk to\nsoftware quality. Thus, finding formats that favor student learning\nand consequently in generating increasingly effective UML mod-\nels can become one of the main challenges faced by instructors\nthat include UML (Unified Modeling Language) as part of software\nmodeling content.\nSome studies [ 3,12,25] sought to understand how to apply gam-\nification in software modeling teaching using some elements such\nas points, emblems and levels. However, instructors and researchers\nstill find limitations when applying, evaluating, and measuring the\nuse of this tool in the learning of software modeling students and,\nconsequently, in the models developed by them, since in the current\nliterature there is no \u201cframe of reference\u201d that guides them. This\nstudy conjectures that gamification mechanics can improve learner\nengagement while learning software modeling, mitigating such\nproblems concerning UML models. The current literature lacks\nstudies that explore gamification and model quality in the context\nof software modeling learning.\nThis article, therefore, introduces ModelGame , which is a quality\nmodel to support software modeling learning in a gamified way.\nIt serves as a reference framework so that instructors can obtain\na parameterized way to evaluate UML models created by learners.\nThe quality of UML models can be improved by applying gami-\nfied activities and providing guidelines aware of quality issues. A\nreference framework would help to (1) establish parameters for eval-\nuating UML models created by learners; (2) provide guidelines to\nimprove the quality of these artifacts; (3) to analyze which elements\nof gamification could be included in each of the phases of modeling\nusing UML; (4) identify intrinsic and extrinsic aspects of students\nduring the modeling stages, to improve the models; (5) to compare\nvalidated theories about the inclusion of gamification in software\nmodeling teaching, taking into account the types of learning and\nmethodologies used; and (6) contributing to the identification of\ngamification use objectives in modeling activities.\nA qualitative questionnaire was answered by 19 instructors who\nteach software modeling at higher education institutions. The re-\nsults show that (1) 94.7% recognize that the proposed model can\nimprove the quality of UML models, indicating that they would\nadopt it in their learning practices; and (2) 47.4% do not use any\n100\n",
    "SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil Ed Wilson J\u00fanior and Kleinner Farias\ngamification mechanics in their classes. These results are encourag-\ning, showing the potential for applying and improving the teaching\nand learning of software modeling.\nThe remainder of the paper is organized as follows. Section 2\npresents the main concepts discussed throughout the article. Sec-\ntion 3 discusses the related work, highlighting research opportu-\nnities. Section 4 introduces the proposed quality model. Section 5\npresents how the quality model was evaluated. Section 6 points out\nsome threats to validity. Finally, Section 7 presents some concluding\nremarks and future work.\n2 BACKGROUND\nThis section presents the essential concepts for understanding this\nwork, including gamification and software engineering teaching\n(Section 2.1), and software modeling and model quality (Section\n2.2).\n2.1 Gamification and Software Engineering\nTeaching\nGamification aims to use game elements in the context of not game\n[5], bringing all positive aspects they provide as a way to encourage\nand engage \u201cplayers,\u201d thereby broadening their motivations.\nWerbach [ 23] classifies gamification into three dimensions: Dy-\nnamics, Mechanics, and Components. Dynamics include all game\naspects related to the emotional responses of \u201cplayers\u201d (e.g., rela-\ntionship, progression, and narrative). Mechanics offer elements that\npromote the action of a game \u2014 usually elaborated via a rule-based\ndevelopment \u2014, so that the player can interact with such elements,\ne.g., challenges, feedback, and rewards. Components represent\nthe aesthetic elements of gamification, whose goal is to present\nvisual aspects with which players can perform the interaction, for\nexample, points, scores, and emblems (badges).\nKnowing that the teaching of Software Engineering should in-\nvolve students to experience the professional practices of the area\nso that they can understand which practices and techniques are\nuseful in several different situations [ 2]. The challenges of teaching\nnew software engineers are not limited to learning programming,\nbut also include paying attention to detail, considering the quality\nof created models, established schedule and defined budgets [ 1]. In\naddition to understanding the technical challenges, these future\nprofessionals must be up to date with nontechnical issues, including\nteamwork, communication and management.\nTo meet these new demands of the current context, the format\nwith exhibition classes is no longer considered enough and may\neven become demotivating and ineffective in learning students. In\nthis sense, gamification has been increasingly used in the teach-\ning of software engineering as a way to promote behavioral and\npsychological changes [ 11] providing an environment that favors\ncommunication, cooperation, feedback, reward, achievement and\nother recurring elements that are capable of improving perfor-\nmance, efficiency and engagement in educational activities , and\ncan enhance, for example, the learning of software modeling.\n2.2 Software Modeling and Model Quality\nSoftware modeling encompasses the set of principles, concepts, and\npractices that lead to the development of a high-quality system orproduct. The principles of this activity establish a philosophy that\nguides the entire software development process.\nIn this scenario, UML models play a crucial role in software\ndevelopment tasks, for example, documenting project decisions,\nunderstanding development details, promoting better communica-\ntion between teams, and generating greater efficiency in software\ndevelopment [ 19]. However, these models suffer problems of in-\nconsistency and incompleteness [ 10,18], as well as end up being\noverlooked within the modeling process, as pointed out in some\nempirical studies in the literature [ 14,15]. Class and sequence dia-\ngrams, for example, present inconsistencies when sequence diagram\nobjects are not found in the class diagram, consequently developers\nend up living with inconsistencies throughout the development\nprocess.\nA research challenge still open is how to evaluate these diagrams,\nboth in industry and in the teaching process, in terms of quality,\nsuch as syntactic and semantic, for example.\n3 RELATED WORK\nThe selection of related works was carried out following two steps:\n(1) search in digital repositories, such as Google Scholar andScopus\n(Elsevier) of articles related to gamification, quality modeling, and\nmodeling learning; and (2) filter selected articles considering the\nalignment of such works with the objective of the work (Section 4).\nAfter selecting the works, they were analyzed (Section 3.1) and\ncompared (Section 3.2), seeking to identify research opportunities.\n3.1 Analysis of Related Works\nPorto et al. (2021) [4]. This work performed a systematic map-\nping with the objective of characterizing how gamification has\nbeen adopted in noneducational contexts of software engineering\nactivities. The main results of this study show that gamification\nprovided benefits for activities such as requirements specification,\ndevelopment, testing, project management, and support process.\nIn addition, he pointed out that the number of publications and\nnew research initiatives has increased over the years, many posi-\ntive results have been achieved in software engineering activities.\nNevertheless, the study reinforced that gamification can still be\nexplored for other tasks in this area, as empirical evidence is very\nlimited.\nMarin (2021) [17]. It performed the application of gamification\non some topics of a software engineering course to engage students\nand increase their motivation and argued that, with due motiva-\ntion, students can better exercise the topics and obtain more solid\nknowledge. There were five games related to risk management,\nBPMN modeling, Scrum process, design and inspection of class\ndiagrams, and cosmic functional size measurement to assist in the\nlearning process of the software engineering course. This study also\npresented the lessons learned about the application of gamification\nand serious games in software engineering, including limitations\nor disadvantages.\nJurgelaitis et al. (2018) [12]. This work conducted a research to\ninvestigate how gamification could be inserted into an Information\nSystems Modeling course, which covers a range of topics on UML.\nAs a result, an implementation of the gamified system modeling\ncourse in the Moodle environment was presented, using additional\n101",
    "ModelGame: A Quality Model for Gamified Software Modeling Learning SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil\nplugins for the use of the necessary gamified elements. The study\nshowed good results and obtained a positive acceptance by the\nparticipating students.\nRodrigues et al. (2018) [22]. They investigated the use of games\nand game elements in software engineering education, through a\nresearch that had the participation of 88 instructors of this disci-\npline. The results showed that most instructors are aware of these\neducational approaches, however, the games were adopted by only\n21 participants and game elements were adopted only by 19. Games\nare most often used to cover \u201cSoftware Process\u201d and \u201cProject Man-\nagement\u201d. The most commonly used game elements are points,\nquizzes, and challenges. The results also show that the main rea-\nsons for not adopting the resources are the lack of knowledge,\ninformation about games relevant to the engineering of teaching\nsoftware, and the lack of time to plan and include these approaches\nin the classroom.\nCosentino et al. (2017) [3]. They present a model-based ap-\nproach to learning modeling in a gamified way. The approach in-\ncludes a new language to model the gamification process itself and\nan environment where it can be incorporated into current mod-\neling tools to allow instructors and students to design and use a\ncomplete modeling framework, including gamification elements. In\naddition, the approach also had as a proposal to provide support to\ncollect and analyze gamification data, thus facilitating monitoring\nactivities.\nYohannis (2016) [25]. This research presents an exploration of\ngame design as an approach to strengthening the student\u2019s mas-\ntery in software modeling by developing their abstraction skills. It\nbrought together concepts of gamification development, such as the\nlens of atoms of intrinsic skill and principles of pedagogical design\nof various theories and models of learning. The research follows\nthe Design Science Research Methodology and explores the best\npractices of Model Oriented Engineering. As a result, a modeling\ngame design framework and generation structure and a series of\nproduced games are presented.\nPedreira et al. (2015) [21]. They developed a systematic map-\nping of gamification in Software Engineering based on 29 studies.\nThe mapping revealed that software implementation is the area\nin which most studies focus, followed by software requirements,\nfew others in different areas, such as project planning and software\ntesting, and even to a lesser extent in activities involving software\nmodeling. However, the highlight of this work was to highlight that\ngamification in software engineering is still at a very early stage\nand the evidence on its impact in this field remains inconclusive.\n3.2 Comparative Analysis and Opportunities\nFive Comparison Criteria (CC) were defined selecting the most rele-\nvant variables to assist in the process of identifying similarities and\ndifferences between the proposed work and the selected articles.\nThis comparison is crucial to make the process of identifying re-\nsearch opportunities using objective rather than subjective criteria.\nThe criteria are described below:\n\u2022Context (CC01): Works that explore the use of gamification\nin software modeling teaching/learning.\n\u2022Participant profile (CC02): Studies that collected data from\nparticipants for screening and profile characterization.\u2022Applicability of Gamification in UML (CC03): Studies\nthat evaluated how gamification can contribute to UML mod-\nels.\n\u2022Model creation (CC04): Studies that have developed a model\nto improve factors that imply the non-adoption of UML.\n\u2022Instructor participation (CC05): Studies that collected\nqualitative data through the participation of software mod-\neling instructors.\nTable 1 shows the comparison of the selected works, confronting\nthis work. Some gaps and research opportunities are observed: (1)\nonly the proposed work was the only one to fully meet all compar-\nison criteria; (2) although most of them targeted the application\nof gamification in software modeling teaching, they were not di-\nrected to the use of UML; (3) no study has developed a model to\nevaluate the learning and improvement of UML models developed\nby students; and (4) most of them did not have the participation\nof instructors to identify the difficulties and opportunities in the\napplication of gamification in the teaching of software modeling.\nThus, the next Section presents a quality model to explore these\nidentified opportunities.\nRelated WorkComparison Criterion\nCC1 CC2 CC3 CC4 CC5\nProposed Work      \nPorto et al (2021) [4] ## ##\nMarin (2021) [17]  #G #G ##\nJurgelaitis et al (2018) [12]  #  #\nRodrigues et al (2018) [22]   G ## \nCosentino et al (2017) [3]  #  #\nYohannis (2016) [25]  #G #G ##\nPedreira et al (2015) [21] ##G ###\n Completely Meets G #Partially Meets #Does not attend\nTable 1: Comparative analysis of the selected related works\n4 PROPOSED QUALITY MODEL\nThis section presents the proposed quality model to support soft-\nware modeling learning in a gamified way. It serves as a frame\nof reference so that instructors can evaluate the UML models cre-\nated by students through gamified activities. Section 4.1 presents\na proposal of a generic analytical framework. Section 4.2 details\nthe abstract syntax of the proposed quality model. Section 4.3 ex-\nplains the quality notions related to the gamified software modeling\nlearning.\n4.1 Generic Analytical Framework\nFigure 1 presents the generic analytical framework for improving\nthe quality of the models and serves as the basis for the creation of\nan evaluation scheme. The arrows (\"links\"), labeled as Evaluation\nand Gamified Modeling, represent the questions that the evidence\nmust answer; dotted lines represent associations; rectangles rep-\nresent the Models (rounded corners) or the quality states (square\ncorners) by which these bindings are measured. Ellipses represent\nthe adverse effects that can be generated from the evaluation and\nuse of gamification.\nThe numbers refer to the key questions and are connected with\nthe concepts and relationships of the abstract syntax of the Quality\n102",
    "SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil Ed Wilson J\u00fanior and Kleinner Farias\nFigure 1: Generic analytical framework for gamified software modeling learning.\nModel (presented in Section 4.2), as follows: (1) Are there tools\nthat assist instructors in evaluating the models developed by stu-\ndents, thus reducing the poor quality and incompleteness of these\nartifacts? (2) What is the prevalence of characteristics that cause\nmodels to be at risk? (3) Are there notions of quality to evaluate\nthe models as a way to define parameters when performing their\ncorrection? (4) Applying the use of gamification in models that\nneed intervention would be a way to identify factors that could\ngenerate models with high quality levels? (5) Does the application\nof gamification improve the quality of the model? (5.a) How are the\nmodels without gamification evaluated in relation to those with\ngamification? (5.b) Are there reasons to expect that gamification\nmodels can have better quality results than those that are gener-\nated without gamification? (6) Is the output model really effective\nwhen associated with reducing the poor quality of the model? (7)\nDoes the absence of evaluation result in adverse effects? (7.a) is the\nevaluation acceptable for the model? (7.b) What are the potential\nharms, and how often do they occur? (8) Does gamification result\nin adverse effects on models?\nFact is that it is not enough just to include this \"toolbox\" in the\nUML learning process, it is necessary to provide the instructor with\na model (guide) that can serve as a reference to evaluate the quality\nof diagrams elaborated through gamified activities. For example,\nthe instructor could create models predefining inconsistencies by\nmaking use of these questions raised to evaluate the models created\nby the students. The set of questions serves as the starting point for\nthis evaluation. Knowing that the adaptation of the gamification\napproach requires a significant effort [ 20], in this study we present\nThe ModelGame as a way to identify factors that contribute to\nthe quality of these artifacts and, consequently, to the students\u2019\nlearning.\n4.2 Abstract Syntax\nFollowing the specification pattern of the UML metamodel, Figure 2\npresents the abstract syntax of the proposed Quality Model for\ngamified software modeling learning (ModelGame). It identifies\nthe main concepts and relationships. The numbers represent thenotions of quality that are discussed in Section 4.3. The following\nare detailed each of these concepts and relationships.\nDomain. The first concept presented in this study is the domain,\nwhich corresponds to a specific context of the application to be\ndeveloped to solve the problem. In this process, the design template\nrepresents the solution given to the domain.\nAssociation\n\u2022contextualizes : Challenges[*]\nEach contextualise refers to the domain that will serve as the\nbasis for the challenges launched.\nChallenges. This concept represents the phase in which the\nproblem is contextualized (domain-based), as well as what will be\nthe missions, phases, scenarios, and other elements presented to\nthe players, in this case the students, who must use the principles\nof software engineering to perform the modeling and reach the\nfinal goal.\nAssociation\n\u2022influences : Design Model[*]\nEach influence represents that the proposed challenge interfered\nin aspects of the design model, causing the user to seek to make a\ncontinuous improvement.\nModeling Language. Software modeling is an important step\nfor development to happen in a way that adheres to the require-\nments established by the requester, for this, there is the modeling\nlanguage, which offers a standardized way to document and design\nsoftware. Through the use of modeling languages, it is possible to\nachieve a high level of understanding about the software in ques-\ntion, improving the communication between all those involved in\nthe process, thus avoiding implementation errors. It points out that\nsoftware engineers use these languages to communicate design\ndecisions and verify the feasibility of implementing the intended\ndesign. The UML was consolidated as the Modeling Language in\nthe paradigm of object orientation, in which it is possible through\nvisual notation generated from the diagrams- presented later in this\nstudy as Design Models- to perform the representation of various\nperspectives of the system.\nAssociation\n103",
    "ModelGame: A Quality Model for Gamified Software Modeling Learning SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil\nFigure 2: Abstract Quality Model Syntax.\n\u2022expresses : Design Model[*]\nPerforms the representation of the intended design templates, in\nwhich the Modeling Language should be applicable to the domain\ntype.\nUser. This concept corresponds to the individual who performs\nthe interpretation of the developed design models, whose objective\nis to be able to understand the domain in question. In the gamified\ncontext, the user has the role of player and it is he who performs\nthe whole process, being able to perform the interpretation of ex-\nisting models or even creating new ones. The user can also identify\nand resolve inconsistencies that arise from compositions between\nmodels.\nAssociation\n\u2022creates : Design Model[1..*]\nRepresents the process in which the user creates a design template,\nwhich can be one or more.\n\u2022interprets : Design Model[1..*]\nIn this association, the user performs the interpretation of the design\ntemplate. When interpreting the model, paths for the resolution of\ninconsistencies can be identified.\n\u2022detects : Inconsistency [*]\nRepresents the user\u2019s discovery of design model inconsistencies,\nfor example, those that are generated from identifying conflicts,\nwhether a class is abstract or not.\n\u2022resolves : Inconsistency [*]\nEach resolves equates to the resolution representation of the incon-\nsistencies by the user that happens after he analyzes and determines\nthe best alternative to perform this action.\n\u2022uses : Modeling Tools [*]\nDetermines that the user can use modeling tools to generate/update\ndesign models.Association\n\u2022Without a directed relationship .\nModeling Tool. This concept represents the applications that\nare used to carry out the construction of design models. There are\nseveral tools available, online and desktop, and it is up to the user\nto choose the one that will best meet their needs and adapt to the\ncontext in question, that is, they work in any domain that is being\nconsidered.\nDesign Model. The design model refers to a visual notation\n(diagram) to represent static and dynamic aspects. These models are\nbuilt according to a specific objective or task and tend to facilitate\nthe logical interpretation of the software in several aspects. The\nmost popular diagrams are Use Cases and Classes, the first being\nstatic and representing a set of actions generated from functional\nrequirements (use cases) and presenting the interactions generated\nwith external users (actors). The second is a static diagram and\nmakes the representation of the logical structure of the software\ninvolving the classes, their attributes, methods, and relationships\nbetween them [19].\nAssociation\n\u2022describes : Domain[1]\nEach describes makes the representation of a specific domain\nand means that every design model must describe it.\nInconsistency. It corresponds to the defects found in the models\ndeveloped by users. They may occur because of the nonidentifi-\ncation and correction of possible conflicts and even an erroneous\ninterpretation.\nAssociation\n\u2022affects : Design Model[*]\nThis association indicates that with each occurrence of the affect, a\nproblem is presented harming the quality of the design model.\n104",
    "SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil Ed Wilson J\u00fanior and Kleinner Farias\nPoints. This concept represents one of the most used game me-\nchanics in software engineering and functions as a quantitative\nreward for each action developed, in which it is possible to regulate\nthe number of rewarded points of the player, defined here as user,\nbased on the importance of each action. Through this concept, it\nis possible to stimulate competition, collaboration, and creativity\namong users, stimulating learning. Points appear as a derivation\nof the association affects, since when each inconsistency error is\nidentified or not, the user will receive a score and the association\ndescribes, because the points will also be applied when making\nconnections between the model and the domain.\nProgress. The concept of progress emerges as a factor that makes\nthe user able to perceive its evolution in the process, in this case,\nsoftware modeling. Progress emerges as a derivation of the associa-\ntion interprets, making the user know when they have performed\na correct interpretation of the proposed design model or what still\nneeds to be improved.\nFeedback. Feedback has the role of making the user realize that\nthe proposed goal can be achieved and follow its evolution, includ-\ning analyzing how to change or creating new strategies to achieve\nthe goal. This concept emerges as a derivation between the associa-\ntions it creates, causing the user to receive a return to the model\ncreation process.\n4.3 Quality Notions\nAs discussed in Section 2, gamification can bring important ele-\nments for learning software modeling and, therefore, the objective\nof this section is to produce the notions of quality of the model\nof this study. The ModelGame is composed of ten counts, four of\nwhich are proposed in this study - scope, use, motivational and en-\ngagement - extracted from the main benefits that the gamification\nelements presented in Figure 2 can bring to the models. The others\nare adaptations of previous works [ 6,14,15], they are, syntactic,\nsemantic, social, effort, detection and resolution.\nScope Quality (1). It seeks to determine how much the proposed\nchallenge is contextualized with the design model, as well as the def-\ninition of the domain, problem, competencies, concepts, behaviors\nand attitudes that will be developed throughout the process.\nSyntactic Quality (2). This notion makes the representation of\nthe process of correction of the design models that are produced\nby the modeling language, because if it is not used correctly, incon-\nsistencies will arise. It is important to insert this notion of quality\ninto our study, since during the process of developing the models,\nusers may come across the composition of two class diagrams, for\nexample.\nSemantic Quality (3). It is necessary to verify that the design\nmodel and the problem domain match, so this notion performs\nthis type of analysis. Communication problems may occur between\nusers if the semantic elements of the model are affected.\nSocial Quality (4). Design models are used to communicate\nbetween members of a team to inform all established decisions\nabout software development [ 8]. If divergent interpretations occur,\nthis communication will be greatly impaired.\nQuality of Effort (5). This notion refers to the production chal-\nlenges of the model that will be generated, including factors such\nas time and cost.Quality of Use (6). To produce design templates, users can use\nunusual tools such as paper, whiteboard, and more. However, most\nof the time they choose to use formal tools (CASES) and can be\nonline or desktop. This notion corresponds to the level of ease and\napplicability of the models elaborated when making use of these\ntools, it is also important to contribute to communication between\nusers through collaboration-related functionalities.\nDetection Quality (7). This notion is referenced to the process\nof locating inconsistencies, since when users arise, they should\nperform traceability of them quickly. If the detection is complicated,\nit could hinder the process of correcting the models.\nResolution Quality (8). It corresponds to the level of quality\nrelated to the effort that users take to look for alternatives to solve\nthe identified problem.\nMotivational Quality (9). This notion refers to the motiva-\ntional factors involved during the learning and development of\ndesign models, which can be intrinsic and extrinsic. Elements of\ngamification such as points, feedback and progress bring the user a\ndegree of satisfaction in continuing their discovery and transfor-\nmations throughout the process.\nQuality of Engagement (10). The user in tracking their progress\ncan feel committed to the objective in question, and this notion\nrepresents the measurement of the level of commitment of them\nduring the development of design models.\n5 EVALUATION\nThis section describes the methodology followed to evaluate the\nproposed quality model. This methodology follows well-established\nempirical guidelines [ 24]. Section 5.1 details the objective and re-\nsearch questions (RQ). Section 5.2 presents the questionnaire formu-\nlated to evaluate the proposed quality model. Section 5.3 explains\nthe context and selection of participants. Section 5.4 describes the\npresentation of the Model. Section 5.5 presents the analysis of the\ncollected data.\n5.1 Objective and Research Questions\nThe objective (O)of this study is twofold: (O1) Introduce Model-\nGame as a tool for teaching Software Modeling; and (O2) Analyze\nthe applicability of the quality model regarding the improvement\nof UML models.\nTo analyze the different facets of the objectives, two Research\nQuestions (RQ) have been formulated:\n\u2022RQ1: How do instructors evaluate the use of gamification\nin software modeling?\n\u2022RQ2: What is the acceptance of ModelGame by software\nmodeling instructors?\n5.2 Questionnaire\nData was collected through an online questionnaire created through\nGoogle Forms1following well-established guidelines described in\n[24]. This strategy was chosen because the questionnaire could\nbe applied quickly and easily collect data from individuals in geo-\ngraphically diverse locations. The questions of the questionnaire\n1Questionnaire: https://forms.gle/qjaFDpErEtGdLuWw6\n105",
    "ModelGame: A Quality Model for Gamified Software Modeling Learning SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil\nwere concerned with examining the research gaps of previous stud-\nies and apprehending the structures of the previously developed\nquestionnaire.\nPart 1: Participant profile. The first part of the questionnaire\nconsisted of collecting data that are related to the characteristics\nand opinions of the participants. The creation of the participant\nprofile through this data is important to make the selection of\npossible users of ModelGame. Without this profile, participants\nwith an inadequate profile may generate inconsistent assessments.\nParticipants were asked to provide more general information, such\nas age, education level, academic background. Information about\nthe time of experience in teaching was also considered, including\nteaching software modeling and level of knowledge about UML\nmodels.\nPart 2: TAM questionnaire. The second part addressed ques-\ntions about the usability and acceptance of the technique, aiming\nto explore q3. To this end, this part of our questionnaire is based on\nthe technology acceptance model (TAM) [ 16]. This part contained\nnine questions, which were answered through the Likert Scale, in-\ncluding Totally Agree, Partially Agree, Neutral, Partially Disagree,\nand Totally Disagree. The questions formulated (Q) dealt with sev-\neral topics, including perceived ease of use (Q1-3), perceived utility\n(Q4-7), attitude towards use (Q8), and behavioral intention to use\n(Q9).\n5.3 Selection of participants\nThe participants were selected based on the following criteria: in-\nstructors and/or professionals working in the teaching of software\nmodeling in higher education institutions in Brazil. Using this cri-\nterion, we sought to select participants with academic training\nand practical experience in teaching. This finite set of all possible\nparticipants represents the target population [ 13]. This popula-\ntion represents those people who are in a position to answer the\nquestions formulated and to whom the results of the survey apply\n[13]. In all, 19 people (n) answered the questionnaire. The partici-\npants were invited via e-mail to participate in the study and each\nof them previously received the explanation/training about the\nmodel proposed through the researcher and there was no doubt,\nthey could leave for the next step that consisted of completing the\nTAM questionnaire. We discussed the experimental process in the\nnext section.\n5.4 Experimental Process\nFigure 3 presents the experimental process used in this study, which\nis composed of three phases discussed below:\nPhase 1: Presentation. It has an activity, presentation , in which\nthe researcher explained to the participants through a video detail\nabout the quality model. This process took place individually and\nin a standard way, where space was also made available for par-\nticipants to answer possible doubts about the proposed study and\nmodel, lasting an average of 20 minutes.\nPhase 2: Application of the TAM questionnaire. It has two\nactivities, the first being Collect demographic data . The participants\nanswered a list of questions (input) so that we could collect their\ncharacteristics and opinions about the ModelGame. The demo-\ngraphic data collected (output) became the result of this activity.The second activity Apply TAM questionnaire (input) . Participants\nreceived a list of questions about the perception of ease of use, per-\nceived utility, attitudes, and intention of behavior, in relation to the\nModelGame. Qualitative data (output) were generated, regarding\nthe usability and acceptance of the Model under the perspective\nof professionals who teach software modeling. This questionnaire\nfollowed the guidelines of the TAM [16].\nPhase 3: Analysis and result report. It has two activities. The\nfirst, Analyze data sought to perform a thorough analysis of the data\ncollected through the questionnaire and the researcher\u2019s perception\nregarding the participants\u2019 doubts during the presentation stage.\nFor this, the collected data were analyzed separately, as well as con-\nfronted, aiming to perform a triangulation of them. Subsequently,\nthere was an Evaluation data , as a way to understand in a more\ndepth the context, the perceptions of the participants in relation to\nthe proposed model as well as its applicability.\nFigure 3: The experimental process.\n5.5 Result Analysis\n5.5.1 Profile data of the participants. Table 3 describes the profile\ndata, reporting the characteristics and opinions of the participants.\nThese data were collected from May 18 to June 5, 2021. In total,\nwe had 19 participants. Our participants are between 20 and 49\nyears old, most of them have a degree in Computer Science (52.6%),\nInformation Systems (26.3%) or Systems Analysis (21.1%) and are\nspecialists (36.8%), masters (36.8%) and doctors (15.8%). About the\nworking time in teaching, the majority (42.1%) they have been teach-\ning for more than 8 years and teach disciplines related to software\nmodeling, including software engineering, systems analysis and\nsoftware projects. A total of 47.4% have a full level of knowledge\nabout UML and almost half of them (47.4%) has not yet used gamifi-\ncation in the teaching of software modeling. Therefore, we consider\n106",
    "SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil Ed Wilson J\u00fanior and Kleinner Farias\nTotally agree Partially agree Neutral Partially disagree Totally disagree\nPerceived ease of use\nI found the quality model easy to use 8 9 2 0 0\nI found the quality model easy to learn 10 9 0 0 0\nI found the quality model easy to master 6 12 0 1 0\nPerceived usefulness\nThe model would make it easier to understand which elements of gamification can be used in modeling . 12 5 2 0 0\nUsing the quality model would help increase productivity. 9 8 2 0 0\nThe model would provide an understanding of how to mitigate the incompleteness of UML diagrams. 5 8 5 1 0\nThe model would help compare theories about gamification in software modeling teaching. 13 4 2\nAttitude towards use\nUsing the Quality Model for Gamified Software Modeling Learning is a good idea. 13 5 1 0 0\nBehavioral intention to use\nI would use the quality model in software modeling classes. 10 7 2 0 0\nTable 2: Collected data related to TAM questionnaire.\nthat although small, our sample is adequate to carry out an initial\nevaluation of the proposed approach.\nCharacteristic and Opinion (n=19) Answer # %\nAge < 20 years 0 0.0%\n20-29 years 4 21.1%\n30-39 years 8 42.1%\n40-49 years 5 26.3%\n> 49 years 2 10.5%\nEducation Undergraduate* 0 0.0%\nSpecialization* 7 36.8%\nMaster* 7 36.8%\nPhD* 3 15.8%\nOthers 2 10.6%\nUndergraduate course Information Systems 5 26.3%\nComputer Science 10 52.6%\nComputer Engineering 0 0.0%\nSystem Analysis 4 21,1%\nOthers 0 0.0%\nTime of experience in teaching < 2 years 4 21.1%\n2-4 years 2 10.5%\n5-6 years 3 15.8%\n7-8 years 2 10.5%\n> 8 years 8 42.1%\nExperience in teaching < 2 years 3 15.8%\nsoftware modeling 2-4 years 5 26.3%\n5-6 years 3 15.8%\n7-8 years 2 10.5%\n> 8 years 6 31,6%\nLevel of knowledge Beginner 2 10.5%\nabout UML models Junior 5 26.3%\nFull 9 47.4%\nSenior 3 15.8%\nUsed gamification in teaching Yes 9 47.4%\nNo 9 47,4%\nMaybe 1 5.3%\nGamification can contribute to the quality Totally agree 10 52.6%\nof the models of UML diagrams generated Partially agree 8 42.1%\nby students Neutral 1 5.3%\nPartially disagree 0 0.0%\nTotally disagree 0 0.0%\nTable 3: The profile data of the participants.\n5.5.2 RQ1: How do instructors evaluate the use of gamification in\nsoftware modeling? Table 3 presents the collected data related to\nthe RQ formulated. First, we begin the analysis by verifying how\ninstructors visualize gamification in software modeling teaching.\nAlthough most of them (47.4%) have not yet used gamificationelements (scores, challenge, emblem, among others) in their classes,\nmost (52.6%) totally agree and (42.1%) partially agree that the use\nof these can contribute to the quality of the models developed by\nthe students.\nWe consider the percentage of instructors who have not yet\nused gamification in their classes to be high and this may be tied\nto factors such as lack of knowledge, information about the tool,\nand even time to plan and include these approaches [ 22]. Although\nthey were based on software modeling teaching context, previous\nstudies [ 3,4,12,17,25] they did not count on the participation of\ninstructors and we understand that this participation is fundamental\nto understand the perceptions of these professionals since they will\nbe at the forefront of the use of gamification.\nThe ModelGame proposed in this study could help them insert\ngamification into their classes, according to the software modeling\nlearning design [ 25], based on the assumption that for this, it is\nnecessary to develop a better understanding of the tasks, activities,\nskills and operations that the different elements of gamification can\noffer and how they can correspond to the desired learning outcomes\nby developing a more concrete and motivating presentation that\ncan involve students and facilitate deep learning with UML.\n5.5.3 RQ2: What is the acceptance of the ModelGame by software\nmodeling instructors? Using the TAM questionnaire, we tried to\nevaluate the ease of use, perceived usefulness, attitude, and behav-\nioral intention to use the Quality Model. Table 2 shows the data\nobtained. Our data obtained show that no one disagreed that the\nModelGame is easy to use, learn, and master. On the contrary, al-\nmost 90% of participants find the model easy to use (42.1% totally\nagree and 47.4% partially agrees and 10.5% neutral), learn (52.6%\n107",
    "ModelGame: A Quality Model for Gamified Software Modeling Learning SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil\nfully agree and 47.4% partially agree) and master (31.6% fully agree,\n63.2% partially agree and 5.3% partially disagree).\nThe results are also favorable considering the perception of util-\nity. Most participants realized that the ModelGame would make it\neasier to understand which elements of gamification can be used in\neach of the phases of modeling using UML(63.3% totally agree, 26.3%\npartially agree and 10.5% neutral), increase productivity (47.4% fully\nagree, 42.1% partially agree and 10.5% neutral), and the use of the\nquality model would provide an understanding of how to mitigate\nthe incompleteness of UML diagrams (26.3% agree totalmen 42.1%\npartially agree, 26.3% neutral and 5.3% partially disagree). Still in\nthe useful aspect, we tried to know if the quality model would help\nto compare validated theories about the inclusion of gamification\nin software modeling teaching (68.4% totally agree, 21.1% partially\nagree and 10.5% neutral).\nConsidering the attitude towards use, participants believe that\nusing the ModelGame is a good idea (68.4% totally agree, 26.3%\npartially agree and 5.3% neutral), just as they are confident and\nwould use the Model in software modeling classes (52.6% totally\nagree, 36.8% partially agree and 10.5% neutral). These findings show\nthe potential for acceptance by people with profiles similar to those\nof participants. The results are encouraging and show the potential\nto use the proposed approach in the educational scenario.\n6 THREATS TO VALIDITY\nThis section discusses the possible threats to the validity of the\nstudy.\nInternal validity. The main point affecting the internal validity\nof our study concerns the total time used for the exploratory phase.\nTo mitigate this threat, we performed the video recording of a pilot\nexplaining the operating details and objectives of the ModelGame.\nIn relation to the methods used, the threats related to internal\nvalidity relate to how we extract the perceptions of the discussions\nand whether they represent the perceptions of teachers about the\nuse of the Model. We try to reduce this threat by applying the TAM\nquestionnaire.\nExternal validity. We identified threats related to external va-\nlidity, such as the number of participants who never applied the use\nof gamification. This study was limited to 19 participants (teachers)\nfrom various educational institutions, of which 9 (47.4%) never used\nany element of gamification in their classes, this factor can interfere\nin the data, since the model intends to evaluate the quality of UML\ndiagrams from gamified activities.\nConclusion validity. Threats related to the validity of the con-\nclusion are related to treatment and outcome. We try to make the\nreduction by combining quantitative and qualitative data through\ndifferent resources. These data were obtained through audio and\nquestionnaires. We analyze this data to answer the research ques-\ntions.7 CONCLUSIONS AND FUTURE WORK\nThis study proposed an initial quality model (ModelGame) that\nserves as a reference framework for instructors for qualitative eval-\nuations of UML models developed from gamified activities, the\napplication of an empirical study with 19 participants was carried\nout to understand their vision in relation to gamification and the\nacceptance of the proposed Model. It was identified that most have\nnot yet used gamification in their classes, but agree that their use\ncan contribute to the quality of the models developed by the stu-\ndents and were open to using the model. Our findings can enhance\nthe adoption of new teaching practices through gamification, result-\ning in the improvement of software modeling learning using UML,\nand consequently the creation of models developed by students.\nThese approaches can stimulate students\u2019 immersion in the design\nof systems as future professionals during learning.\nFinally, we hope to carry out in the future a series of experimental\nstudies to analyze each stage of application of the ModelGame\nand that this work represents a first step to better support the\napplication of empirical studies on models of evaluation of the\nuse of gamification in software modeling. We also hope that the\nquestions described throughout the article will encourage other\nresearchers to extend our study to different modeling languages\nand teaching methodologies.\nREFERENCES\n[1]Rick Adcock, Edward Alef, Bruce Amato, Mark Ardis, Larry Bernstein, Barry\nBoehm, Pierre Bourque, John Brackett, Murray Cantor, Lillian Cassel, et al .2009.\nCurriculum guidelines for graduate degree programs in software engineering . ACM.\n[2]Mark Ardis, David Budgen, Gregory W Hislop, Jeff Offutt, Mark Sebern, and\nWillem Visser. 2015. SE 2014: Curriculum guidelines for undergraduate degree\nprograms in software engineering. Computer 48, 11 (2015), 106\u2013109.\n[3]Valerio Cosentino, S\u00e9bastien G\u00e9rard, and Jordi Cabot Sagrera. 2017. A model-\nbased approach to gamify the learning of modeling. CEUR Workshop Proceed-\nings.\n[4]Daniel de Paula Porto, Gabriela Martins de Jesus, Fabiano Cutigi Ferrari, and\nSandra Camargo Pinto Ferraz Fabbri. 2021. Initiatives and challenges of using\ngamification in software engineering: A Systematic Mapping. Journal of Systems\nand Software 173 (2021), 110870.\n[5]Sebastian Deterding, Miguel Sicart, Lennart Nacke, Kenton O\u2019Hara, and Dan\nDixon. 2011. Gamification. using game-design elements in non-gaming contexts.\nInCHI\u201911 extended abstracts on human factors in computing systems . 2425\u20132428.\n[6]Ana Fern\u00e1ndez-Saez et al. 2012. A systematic literature review on the quality of\nUML models. J. Data. Manage 22, 3 (2012), 46\u201370.\n[7]Kleinner Farias et al. 2012. Evaluating the impact of aspects on inconsistency\ndetection effort: a controlled experiment. In International Conference on Model\nDriven Engineering Languages and Systems . Springer, 219\u2013234.\n[8]Kleinner Frias et al. 2014. Towards a quality model for model composition effort.\nIn29th Annual ACM Symposium on Applied Computing . 1181\u20131183.\n[9]Kleinner Farias et al. 2015. Evaluating the effort of composing design models: a\ncontrolled experiment. Software & Systems Modeling 14, 4 (2015), 1349\u20131365.\n[10] Kleinner Farias et al. 2019. UML2Merge: a UML extension for model merging.\nIET Software 13, 6 (2019), 575\u2013586.\n[11] Juho Hamari, Jonna Koivisto, and Harri Sarsa. 2014. Does gamification work?\u2013\na literature review of empirical studies on gamification. In 2014 47th Hawaii\ninternational conference on system sciences . Ieee, 3025\u20133034.\n[12] Mantas Jurgelaitis, Vaidotas Drungilas, and Lina \u010ceponien \u02d9e. 2018. Gamified\nMoodle course for teaching UML. Baltic journal of modern computing 6, 2 (2018),\n119\u2013127.\n[13] Barbara A Kitchenham and Shari L Pfleeger. 2008. Personal opinion surveys. In\nGuide to advanced empirical software engineering . Springer, 63\u201392.\n[14] Christian Franz Josef Lange. 2007. Assessing and Improving the Quality of\nModeling: A series of Empirical Studies about the UML. (2007).\n[15] Odd Ivar Lindland, Guttorm Sindre, and Arne Solvberg. 1994. Understanding\nquality in conceptual modeling. IEEE software 11, 2 (1994), 42\u201349.\n[16] Nikola Maranguni\u0107 and Andrina Grani\u0107. 2015. Technology acceptance model: a\nliterature review from 1986 to 2013. Universal access in the information society\n14, 1 (2015), 81\u201395.\n108",
    "SBCARS \u201921, September 27-October 1, 2021, Joinville, Brazil Ed Wilson J\u00fanior and Kleinner Farias\n[17] Beatriz Mar\u00edn. 2021. Lessons Learned About Gamification in Software Engineer-\ning Education. In Latin American Women and Research Contributions to the IT\nField . IGI Global, 174\u2013197.\n[18] Kleinner Oliveira, Alessandro Garcia, and Jon Whittle. 2008. On the quantitative\nassessment of class model compositions: An exploratory study. 1th ESMDE at\nMODELS (2008).\n[19] OMG. 2017. UML: Infrastructure specification.\nhttps://www.omg.org/spec/UML/2.5.1/PDF.\n[20] Sofia Ouhbi and Nuno Pombo. 2020. Software Engineering Education: Challenges\nand Perspectives. In IEEE Global Engineering Education Conference . 202\u2013209.\n[21] Oscar Pedreira, F\u00e9lix Garc\u00eda, Nieves Brisaboa, and Mario Piattini. 2015. Gamifica-\ntion in software engineering\u2013A systematic mapping. Information and softwaretechnology 57 (2015), 157\u2013168.\n[22] Pedro Rodrigues, Mauricio Souza, and Eduardo Figueiredo. 2018. Games and\ngamification in software engineering education: A survey with educators. In 2018\nIEEE Frontiers in Education Conference (FIE) . IEEE, 1\u20139.\n[23] Kevin Werbach and Dan Hunter. 2012. For the win: How game thinking can\nrevolutionize your business . Wharton digital press.\n[24] Claes Wohlin, Per Runeson, Martin H\u00f6st, Magnus C Ohlsson, Bj\u00f6rn Regnell, and\nAnders Wessl\u00e9n. 2012. Experimentation in software engineering . Springer Science\n& Business Media.\n[25] Alfa Yohannis. 2016. Gamification of Software Modelling Learning.. In DS@\nMoDELS .\n109"
]