[
    "AI Model for Computer games based on Case Based \nReasoning and AI Planning  \nVlado Menkovski \nAthens Information Technology \n0.8km Markopoulou Ave. \nPeania, 19002, Greece \nvmen@ait.edu.gr Dimitrios Metafas \nAthens Information Technology \n0.8km Markopoulou Ave. \nPeania, 19002, Greece \ndmeta@ait.edu.gr \nAbstract\nMaking efficient AI models for games with imperfect \ninformation can be a particular challenge. Considering the large \nnumber of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This \neffort is focused on presenting a method of combined Case Based \nReasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies \nin effect discarding meaningless moves. These strategies are \nselected by finding similarities to cases in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to r each these goals. The plan is \nbasically a set of moves that brings the player to this goal. By \nfollowing these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by \nthe same amount of memory.  \nCategories and Subject Descriptors \nI.2.1 [Applications and Expert Systems]: Games\nGeneral Terms\nAlgorithms, Performance. \nKeywords\nGame AI, Case Based Reasoning, AI Planning, Game Trees \n1. Introduction \nThe goal of this effort is to explore a model for design and \nimplementation of an AI agent for turn based games. This model provides for building more capable computer opponents that rely on strategies that closely resemble human approach in solving \nproblems opposed to classical computational centric heuristics in \ngame AI. In this manner the computational resources can be focused on more sensible strategies for the game play.  With the advancement in computer hardware increasingly \nmore computing power is left for executing AI algorithms in \ng a m e s .  I n  t h e  p a s t  A I  i n  g a m e s was mainly a cheating set of \ninstructions that simulated the in creasing difficulty in the game \nenvironment so that the player had the illusion of real counterpart. \nImprovement in available memory and processing power allows \nimplementation of more intelligent algorithms for building the game environment as well as direct interaction with the human players.   \nIn this particular research the emphasis is put on the \ninteraction between the AI agent and a computer player in the \nrealm of the game rules. It is particularly focused on turn based \ngames that have the elements of uncertainty like dice or concealed information. At the beginning a description of Game AI algorithms are given; such as Game Trees and Minimax. The following section describes an approach of using AI Planning to \nimprove building Game Trees in games with imperfect \ninformation where Game Trees tend to be very large with high growth ratio. Section 4 discusses another approach that provides a significant reduction to the number of considered moves in order \nto find the favorable strategy of the AI player. This approach uses \nAI Planning techniques and Case Base Reasoning (CBR) to plan for different scenarios in predetermined strategies which would be analogous to human player experience in the particular game. The \nCBR database illustrates a set of past experiences for the AI \nproblem and the AI Planning illustrates the procedure to deal with the given situation in the game. In the next two sections implementations and evaluations of both approaches are given. \nThe AI Planning approach is implemented with the Tic-tac-toe \ngame and the combined AI Planning and CBR approach is implemented with a model for the Monopoly game. The last part contains conclusions and future work ideas.  \n2. Game Trees and Minimax \nGame Trees are common model for evaluating how different \ncombinations of moves from the player and his opponents will affect the future position of the player and eventually the end result of the game. An algorithm that decides on the next move by \nevaluating the results from the built Game Tree is minimax [1]. \nMinimax assumes that the player at hand will always choose the best possible move for him, in ot her words the player will try to \nselect the move that maximizes the result of the evaluation \nfunction over the game state. So basically the player at hand needs \nto choose the best move overall while taking into account that the next player(s) will try to do the same thing. Minimax tries to maximize the minimum gain. Minimax can be applied to multiple Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy \notherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior specific permission and/or a fee. DIMEA\u201908 , September 10\u201312, 2008, Athens, Greece. \nCopyright 2008 ACM 978-1-60558-248-1/08/09... $5.00 Interactive and Adaptable Media 295\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\n",
    "levels of nodes on the g ame tree, where the leaves bring the final \nknown (or considered) game state.  \nThe minimax theorem states: \nFor every two-person, zero-sum game there is a mixed strategy \nfor each player, such that the expected payoff for both is the same \nvalue V when the players use these strategies. Furthermore, V is the best payoff each can expect to receive from a play of the \ngame; that is, these mixed strategies are the optimal strategies for \nthe two players. \nThis theorem was established by John von Neumann, who is \nquoted as saying \"As far as I can see, there could be no theory of \ngames \u2026 without that theorem \u2026 I thought there was nothing \nworth publishing until the Minimax Theorem  was proved\" [2]. \nA simple example of minimax can be observed by building a \ngame tree of the tic-tac-toe game. The tic-tac-toe game is a simple \ngame which can end by the first player wining, the second player wining or a tie. There are nine positions for each of the players in which at each turn the player puts X or O sign. If the player has \nthree adjacent signs in a row, column or the two diagonals he or \nshe wins. This game has limited number of position and it is well \nsuited for building the whole game tree. The leaves of this tree will be final positions in the game. A heuristics evaluation \nfunction will also need to be written to evaluate the value of each \nnode along the way. \n3. AI Planning for building Game Trees \n3.1.1 AI Planning \nAI Planning also referred as Automated Planning and \nScheduling is a branch of Artificial Intelligence that focuses on finding strategies or sequences of actions that reach a predefined goal [3]. Typical execution of AI Planning algorithms is by \nintelligent agents, autonomous ro bots and unmanned vehicles. \nOpposed to classical control or classification AI Planning results with complex solutions that are derived from multidimensional space. \n AI Planning algorithms are also common in the video game \ndevelopment. They solve broad range of problems from path finding to action planning. A typical planner takes three inputs: a \ndescription of the initial state of the world, a description of the \ndesired goal, and a set of possible actions. Some efforts for incorporating planning techniques for building game trees have also shown up, similar to the approach explored in this effort. In \naddition Cased Based Reasoning [4] techniques are also gathering \npopularity in developing strategies based in prior knowledge about the problems in the games. One of the benefits from Hierarchical Task Network (HTN) [5] planning is the possibility to build Game Trees based on HTN plans; this met hod is \ndescribed in the following section. \n3.2 Game Trees with AI Planning \nAn adaptation of the HTN planning can be used to build \nmuch smaller and more efficient game trees. This idea has already been implemented in the Bridge Baron a computer program for \nthe game of Contact Bridge [6]. \nComputer programs based on Game Tree search techniques \nare now as good as or better than humans in many games like \nChess [7] and checkers [8], but there are some difficulties in \nbuilding a game tree for games that have imperfect information and added uncertainty like card or games with dice. The main problem is the enorm ous number of possibilities that the player \ncan choose from in making his move. In addition some of the moves are accompanied with probabilities based on the random \nelements in the games. The number of possible moves \nexponentially grows with each move so the depth of the search \nhas to be very limited to accommodate for the memory limitations.  \nThe basic idea behind using HTN for building game trees is \nthat the HTN provides the means of expressing high level goals and describing strategies how to reach those goals. These goals may be decomposed in goals at lower level called sub-goals. This \napproach closely resembles the way a human player usually \naddresses a complex problem. It is also good for domains where classical search for solution is no t feasible due to the vastness of \nthe problem domain or uncertainties. \n3.2.1 Hierarchical Task Networks \nThe Hierarchical Task Network, or HTN, is an approach to \nautomated planning in which the dependency among actions can \nbe given in the form of networks [9] [Figure 1]. \nA simple task network (or just a task network for short) is an \nacyclic digraph /g1875/g3404/g4666 /g1847 /g481 /g1831 /g4667  in which U is the node set, E is the \nedge set, and each node /g1873/g1488/g1847  contains a task /g1872/g3048. The edges of /g1875\ndefine a partial ordering of U. If the partial ordering is total, then we say that /g1875 is totally ordered, in which case /g1875 can be written as \na sequence of tasks /g1875/g3404 /g1731/g1872\n/g2869/g481/g1872/g2870/g481/g485/g481/g1872 /g3038/g1732.\nFigure 1: Simple Hierarchical Task Network \nA Simple Task Network (STN) method is a 4-tuple of its n ame, \ntask, precondition and a task network. The name of the method lets us refer unambiguously to substitution instances of the method, without having to write the preconditions and effects \nexplicitly. The task tells what kind of task can be applied if the \npreconditions are met. The preconditions specify the conditions that the current state needs to satisfy in order for the method to be applied. And the network defines the specific subtasks to \naccomplish in order to accomplish the task. \nA method is relevant for a task if the current state satisfies the \npreconditions of a method that implements that task. This task can \nbe then substituted with the instance of the method. The \nsubstitution is basically giving the method network as a solution for the task. \nIf there is a task \u201cGo home\u201d and the distance to home is 3km \n[Figure 2] and there exists a method walk-to and this method has a precondition that the distance is le ss than 5km, then a substation \nto the task \u201cGo home\u201d can be made with this method instance.  \nFigure 2: HTN Method Buy milk\nGo to (shop) Purchase Go to (home )\nGo-to (from, to)\nWalk (to)If (to \u2013 from) < 5km 296 DIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts",
    "If the distance is larger than 5km another meth\nto be substituted [Figure 3]. \nFigure 3: HTN Method 2 \nAn STN planning domain is a set of operati o\nmethods M. A STN planning problem is a 4- tu\nstate S 0, the task network w called initial tas k\nSTN domain. A plan /g2024/g3404 /g1731/g1853/g2869/g481/g485/g481/g1853 /g3041/g1732is a solut i\nproblem if there is a way to decompose w into \u03c0\nand each decomposition is applicable in the a p\nthe world. The algorithm that is capable to \nnetworks into plans is called Total-forward- deco\n[9] or Partial-forward- decomposition (PFD). H\ncases where one does not want to use a forw a\nprocedure. HTN planning is generalization of S\ngives the planning procedure more fr eedo m\nconstruct the task networks.  \nIn order to provide this freedom, a bookk e\nis needed to represent constraints that the plan n\nnot yet enforced. The bookkeeping is done b y\nunenforced constrain ts explicitly in the task net w\nThe HTN generalizes the definition of a\nSTN. A task network is the pair /g1875 /g3404  /g4666/g1847/g481 /g1829/g4667 w\ntask nodes and Cis a set of constraints. Eac\nspecifies a requirement that must be satisfied b y\na solution to a planning problem.  \nThe definition of a method in HTN als o\ndefinition used in STN planning. A HTN pl a\nname, task, subtasks, and constraints. The s\nconstraints form the task network. The HTN pla n\nidentical to STN planning domains except they u\ninstead of STN methods. \nCompared to classical planners the pri m\nHTN planners is their sophisticated knowledge r\nreasoning capabilities. They can represent and \nnon-classical planning problems; with a goo d\nguide them, they can solve classical planning p\nmagnitude more quickly than classical or neo c\nThe primary disadvantage of HTN is the ne e\nauthor to write not only a set of planning oper a\nof methods. \n3.2.2 HTN Planning in building Game \nFor a HTN planning algorithm to be adap\ntrees we need to define the domain (set of H\noperators) which is the domain of the game. Th i\na knowledge representation of the rules of th e\nenvironments and possible strategies of game pl a\nIn this domain the ga me rules as well as k n\ntackle specific task are defined.   The imple m\nTree building with HTN is called Tig n\nimplementation uses a procedure simil a\ndecomposition, but adapted to build up a game Drive(toIf(tGo-to (from, to) \nIf(to \u2013 from) < 5km \nWalk (to) hod instance needs \nons O and a set of \nuple of the initial \nk network and the \nion for a planning \n\u03c0 if \u03c0 is executable \nppropriate state of \ndecompose these \nomposition (TFD) \nHowever there are \nard-decomposition \nSTN planning that \nm about how to \neeping mechanism \nning algorithm has \ny representing the \nwork. \na task network in \nwhere /g1847 is a set of \nh constraint in C \ny every plan that is \no generalizes the \nan is a 4 -tuple of \nsubtasks and the \nnning domains are \nuse HTN methods \nmary advantage of \nrepresentation and \nsolve a variety of \nd set of HTNs to \nproblems orders of \nclassical planne rs. \ned of the domain \nators but also a set \nTrees\nted to build game \nHTN methods and \nis is in some sense \ne game, the game \nay.\nnown strategies to \nmentation of Game \nnum2 [9]. This \nar to forward-\ntree rather than a plan. The branches of the game tree re p\nthe methods. Tignum2 applies all me t\nstate of the world to produce ne w\ncontinues recursively until there are n\nhave not a lready been applied to t h\nworld.  \nIn the task network generated by Tign u\nactions will occur is determined by th\nBy listing the actions in the order \nnetwork can be \u201cserialized\u201d into a ga m\n4. Case Based Reasoning i n\n4.1 Case Based Reasoning\nCase-based reasoning (CBR) is a \nArtificial Intelligence (AI), both as \nproblems and as a basis for standalone \nCase-based reasoning is a paradig m\nsolving and learning that has became \napplied subfield of AI of recent ye a\nintuition that problems tend to recur. I\nare often similar to previously e n\ntherefore, that past solutions may be o f\n[10].  \nCBR is particularly applicable to prob l\navailable, even when the domain is n\nfor a deep domain model. Helpdesks ,\nsystems have been the most successf u\nto determine a fault or diagnostic \nattributes, or to determine whether o r\nrepair is necessary given a set of past s\nFigure 5: Game Tree built f rFigure 4 : HTN to Game T r)to \u2013 from) < 200km present moves generated by \nthods applicable to a given \nw states of the world and \nno applicable methods that \nhe appropriate state of the \num2, the order in which the \ne total -ordering constraints. \nthey will occur, the task \nme tree [ Figure 4] [Figure 5]. \nn Game Strategies\nwell established subfield of \na mean for addressing AI \nAI technology.\nm for combining proble m-\none of the most successful \nars. CBR is based on the \nIt means that new problems \nncountered problems and, \nf use in the current situation \nlems where earlier cases are \nnot understood well enough \n, diagnosis or classification \nul areas of application, e.g., \nan illness from observed \nr not a certain treatment or \nolved cases [11]. \nrom HTNree AlgorithmInteractive and Adaptable Media 297\n3rd International Conference on Digital Interactive Media in Entertainment and Arts",
    "Central tasks that all CBR methods have to deal with are [12]: \"to \nidentify the current problem situation, find a past case similar to the new one, use that case to suggest a solution to the current \nproblem, evaluate the proposed solution, and update the system by \nlearning from this experience. How this is done, what part of the process that is focused, what type of problems that drives the methods, etc. varies considerably, however\".  \nWhile the underlying ideas of CBR can be applied \nconsistently across application domains, the specific implementation of the CBR methods \u2013in particular retrieval and similarity functions\u2013 is highly customized to the application at \nhand. \n4.2 CBR and Games \nMany different implementations of CBR exist in games. \nCBR technology is nicely suited for recognizing complex \nsituations much easier and more elegant than traditional parameter \ncomparison or function evaluation. There are especially evident cases in real time strategies where different attack and defense of global strategies are nicely define d by CBR datasets and later used \nin the running games. Also intelligent bots behavior is also \nanother typical example. Depending on the number of enemy bots the layout of the terrain and position of human players the CBR system finds the closest CBR case and employs that strategy \nagainst the human players which in prior evaluation was proved to \nbe highly efficient. \n5. Game Trees with AI Planning \u2013 Tic-tac-toe \nIn order to show the expressive power of AI Planning in \ndefining strategies for games, and the use of these plans to build \nGame Trees I implemented an algorithm that builds Game Trees \nfor the Tic-Tac-Toe game. \nThe game tree of Tic-Tac-Toe shows 255,168 possible \ngames of which 131,184 are won by X (the first player), 77904 \nare won by O and the rest 46,080 are draw [13]. All these games \ncan be derived from building a complete Game Tree.  \nEven though it is possible to build a complete game tree of \nTic-tac-toe it is definitely not an optimal solution. Many of the \nmoves in this tree would be symmetrical and also there are a many \nmoves that would be illogical or at least a bad strategy to even consider.  \nSo what strategy should X (the first player) choose in order \nto win the game? \nThere are few positions that lead to certain victory. These \npositions involve simultaneous attack on two positions so the other player could not defend, basically the only trick in Tic-Tac-\nToe. \nFigure 6: Tic-tac-toe winning strategy positions \nPosition 1 leads to victory if th e two of the three fields: top \nmiddle, bottom left corner and bottom right corner are free [Figure 6]. \nPosition 2 lead to victory if tw o of the three fields: top right \ncorner, bottom right corner and bottom middle are free [Figure ]. And in the third position if the two of center, middle top and \nmiddle left are available the position is a certain victory. \nThere are many different arrangements of the player\u2019s tokens \nthat give equivalent positions as these three positions. By using \nplanning we do not need to consider all possible layouts but just consider these three similar to what a human would consider. \n The game starts from an empty table. \nThe two relevant strategies that would lead to these positions \nare to take one corner or to take the center [Figure 7]. \nFigure 7: Tic-tac-toe Two starting moves \nThe center position as we can see in the simulation results \nlead to a bigger number of victorious endings but it is also a straight forward strategy with obvious defense strategy. \nAt this point we need to consider the moves of the opponent. \nIf we take the left branch the opponent moves can be a center, a \ncorner or a middle field. We also need to differentiate with a move to a corner adjacent with our like top left or bottom right or across the center to bottom right [Figure 8]. \nFigure 8: Tic-tac-toe opponent response to corner move \nIn cases one and two, we have a clear path to executing \nstrategy 3 so we need to capture the diagonally opposite field. And as for the third case the best wa y to go is to capture the center \nand go for strategy 1 or 2 depending of the opponent\u2019s next move.  \nFigure 9: Tic-tac-toe move 2 after corner opening \nThe first move leads to certain victory, O will have to go to \nthe center and X will achieve strategy 3 [Figure 9]. The second \nmove is a possible way to strategy 3 if O makes a mistake in the \nnext loop, so X goes to the opposite corner. For the third case since O is playing a valid strategy the only move that leaves a possible mistake from O would be to take the center and wait for \nO to go to the middle and then achieve strategy 1 or 3 which will \nbe a symmetric situation to the one that we will find if we branched with the center. \nFigure 10: Tic-tac-toe opponent response to center move \nIf we go back to the second branch [Figure 10], a possible \nway for the second player to engage is corner or middle. The first 298 DIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts",
    "move is a valid strategy for O and can be me e\ncorner move from X to try a mistake from O in \nthe same as in the third case above from the pr e\nanother move would be go to the middle w h\nachieves strategy 1 or 2.  \nFigure 11: Tic-tac- toe Move 2 after cen t\nThe fist move will lead to win if O moves \ndraw if it goes for the corners [Figure 11 ]. In t\nhas to block the lower left corner which leave\nmiddle left or corner left which are strategy 1 an d\nTo sum the strategies for the planning, first \ncorner strategy for the beginning. Then for the c e\nthe corners with the particularly the one oppo\nholds. If the center is empty for the second strat e\nwe go for the opposite corner. After this point w\nopponent or try to implement strategies 1, 2 o r\nvictory.  \nPlan 1 : Take center  \nPreconditions : Center empty \nPlan 2 : Take corner  \nPreconditions : All corners empty \nPlan 3 : Take corner after center \nPreconditions : We have center take corner oppo s\nopponent has \nPlan 4 : Take diagonal corner \nPreconditions : We have a corner, the opponent h a\n the corner opposite to the one we have is free. \nPlan 5 : Block \nPrecondition : The opponent has tree tokens in a r\nagonal \nPlan 6 : Win \nPreconditions : We have two tokens in a row, colu\nnd the third place is free \nPlan 7 : Tie \nPreconditions : If all places are taken, it\u2019s a tie. \n5.1 Hierarchical Task Network \nTop level task is Play [Figure 12]. This is a \ncan be derived into: Win, Block, Tie or Sea r\nSearch for plan is derived to both Plan 1 and Pl a\nPlan 4, which later leads to a call for the oppo n\nrecursive call to Play. \nFigure 12: Tic-tac-toe H T\net with a opposite \nthe future exactly \nevious branch, and \nhere X eventually \nter opening\nto the middle or a \nthe second case O \nes X to go for the \nd 2.\nwe have center or \nenter we try to get \nosite to the one O \negy we go  for it or \nwe either block the \nr 3 which lead to \nsite to the  one the \nas the ce \u2212nter and\nrow, colu\u2212mn or di\nmn or dia \u2212gonal a\na complex task and \nrch for Plan. The \nan 2 or Plan 3 and \nnent\u2019s move and a \nTNThis HTN when executed will r e\ngame scenarios. By creating nodes fro m\nthem with branches wit h the move of t\ntree for the Tic-tac- toe game over wh i\nalgorithm. \nThis set up wit h 7 plans with 3 t a\nfor Tic-tac- toe which considers all po s\nplayer w ith only 457 games, 281 of w\nand 0 where the second opponent w\nreduction over the 255, 168 possible g\ntree. These reductions can be very us e\ncomputing ca pabilities but also we p r\nthat planning can be very efficient if d\ntrees by applying reasoning very \nreasoning. \nFurther improvements to the ga m\nthe opponent s moves are also planne d\nall the meaningless and symmetrical m\n6. Game AI in Monopoly \n6.1Overview of the AI Im p\nThe AI agent is responsible for \nplayers in the game. The core principl e\na Game Tree with all the sensible move\nmake from the current point of tim e\nminimax algorithm the agent selects t\nwould bring the computer player m o\nwith the highest probability. Building \nthat would be big enough to consider \nis obstructed by the vastness of pos s\nwith all the possible random landings \nnodes of the game tree exponentiall y\ntackle this problem the AI agents \ndiscussed te chnologies: Case Based R e\nThe technologies are employed \nFirst the agent searches the CBR data b\nlargest similarity with the current stat e\nassociated with a playing strategy. T h\nthat the planner needs to build plans f\nconsecutive player moves that bring t h\nway only moves that are part of that st r\nbeing a small fraction of the overall p o\nedges of the game tree at each level de c\nAt each level of the game tree th e\nof a single player. After the strate g\nconsidered the response to those strat e\nby the opponent(s). The move of the \nprobability distribution of the dice as \nplayer. A more general strategy need s\nopponent\u2019s (human player) moves si n\nthe expertise of the opponent. This g e\nmore plausible moves than the focuse d\nAfter covering all opponents t\ndeducting a feature move of the co m\nCBR selected plan strategy. After \nstrategies and reaching a reasonable s\ninto account the memory limits a n\nprobabilities that the move is possibl e\nthe dice the building of the Game Tr e\nalgorithm searches the Game Tree \nfavorable move for the AI player us i\nThe process is repeated each time the A\nesult with plans for possible \nm each position and linking \nthe player we create a game \nich we can run the minimax \narget strategies  creates a tree \nssible moves for the second \nwhich X wins 176 are draw \nwins. This is a significant \names with a complete game \neful for devices with limited \nrove a very important point \ndesigning meaningful game \nsimilar to human player \nme tree are also possible if \nd, in other words if we drop \nmoves of the opponent. \nplementation\nthe moves of the artificial \ne of the AI agent is building \nes that all the players would \ne forward. Then using the \nthe move that in the f uture \nost favorable game position \na Game Tree in this game \nsufficient number of moves \nsible moves in combination \nof the dice. The number of \ny grows at each level. To \nincorporates two already \neasoning and AI Planning. \nin the following manner. \nbase to find the case with the \ne of the board. This case is \nhe strategy consists of goal \nfor, and the plans consist of \nhe player to tha t goal. This \nrategy are considered, those \nossible moves the number of \ncreases immensely. \ne model considers the moves \ngies of the AI player are \negies needs to be considered \nopponent(s) depends of the \nwell as the strategy of the \ns to be implemented for the \nnce we cannot be aware of \neneral strategy would bring \nd strategy of the AI player.  \nthe agent comes back to \nmputer player by using the \ncreating several loops of \nsize of a Game Tree taking \nnd the rapidly decreasing \ne due to the distribution of \nee stops. Then the minimax \nand decides on the most \ning the minimax algorithm. \nAI player is up. Interactive and Adaptable Media 299\n3rd International Conference on Digital Interactive Media in Entertainment and Arts",
    "Buying, auctioning and trading game moves are always \naccompanied by return of investment calculations in making the plans. These calculations represent adaptation of the more general \nplanning associated with the cases in the CBR database. These \nadaptations are necessary due to the fact that the cases do not identically correspond to the situation on the table. In addition calculating the game position value of each node of the game tree \nis done by heuristic functions that incorporate economic \ncalculations of net present value, cash, and strategic layout and so on. For example railroads in monopoly are known to be strategically effective because they bring constant income even \nthough the income can be smaller than building on other \nproperties.  \n6.2 Details on the CBR Implementation \nThe implementation of the CBR is by using the JColibri2 \nplatform.  JColibri2 is an object-oriented framework in Java for building CBR systems that is an evolution of previous work on \nknowledge intensive CBR [14].  \nFor this implementation we need to look into three particular \nclasses of the JColibri2 platform. The StandardCBRApplication, Connector, CBRQuery. For a JColibri2 implementation the \nStandardCBRApplication interface needs to be implemented.  \nThe CBR cycle executed accepts an instance of CBRQuery. \nThis class represents a CBR query to the CBR database. The description component (instance of CaseComponent) represents the description of the case that will be looked up in the database. \nAll cases and case solutions are implementing the \nCaseComponent interf ace. \nThe JColibri2 platform connects to the CBR database via a \nConnector class. Each connector implements all the necessary \nmethods for accessing the database, retrieval of cases, storing and \ndeletion of cases. This implementation uses a custom XML structure for holding the CBR cases. Since the game will not update the CBR database only read it, a XML solution satisfies \nthe needs. The XML file to a certa in extent is similar to the XML \nrepresentation of the board. We are interested in finding one CBRCase that is the most similar case to the situation in the game at the time of the search. This procedure is done in the cycle \nmethod of the CBRApplication. The JColibri2 CBR comparison is \ndone by Nearest Neighbor (NN) search method.  \nJColibri2 offers implementations for NN search algorithms \nof simple attributes. These implementations are called local \nsimilarities. For complex attributes like in our case global \ncustomized similarity mechanisms need to be implemented. \nThe MonopolyDescription class [Figure 13] is basically a \nserialization of the GameState. It holds all the information about \nthe state of the board, the players, their amount of cash etc.  \nFigure 13: Class diagram of the Monopoly Case component \nmodels On the other hand the MonopolySolution class holds the \nthree particular attributes that are needed for the planning, the planning Domain, State and TaskList. \nThe game is implemented by using the Model-View-\nController software development pattern. The controller is responsible for implementing the game rules and handling all of the events in the game like roll of dice, input commands for \ntrading, auctioning and etc from the players. The View layer is \nresponsible for displaying the board and all of the input widgets on to the game screen, and the models are data structures representing the game state [Figure 14]. \nFigure 14: Class diagram of the Monopoly models \n6.2.1 Complex Similarity representation in CBR \nThe similarity measurement part of the Nearest Neighbor \nalgorithm JColibri2 is implemented by implementing the \nLocalSimiralrityFunction and the GlobalSimiralityFunction \ninterface. A local similarity function is applied to simple attributes by the NN algorithm, and a global similarity function is applied to compound attributes. In the case of our implementation the \nattributes of the MonopolyDescription are compound attributes \ndescribing the state of the board, number of players, amount of cash for every player and etc. Since MonopolyDescription is a custom CaseComponent a global similarity function needs to be \nimplemented to accurately find the distance between different \nCBR cases. \nThe similarity mechanism is inseparable core element of the \nCBR system. This mechanism represents how the CBR decides \nwhich strategy is best suited for the particular situation by \n300 DIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts",
    "calculating the distance or similarity to other cases in the \ndatabase.  \nFor the monopoly implementation we need to consider \nseveral basic strategies. Monopoly is based on investing in \nproperties and receiving revenues from those investments. One of the basic strategies of the game is to build a set of properties that will bring constant income larger than the one of the opponents. \nSo in time the opponents will have to declare bankruptcy. But on \nthe other hand over investment can lead to too stretched resources with low income that will eventually drove the player to bankruptcy. To decide on these two we need a clear separation \ninto two groups of cases in the CBR database. The first group of \ncases will represent a situation on the board where the player has significant income per loop formed of one or more color group properties, maybe railroads, some buildings on them and so on. It \nis important to note that in this  case the player is better situated \nthan his opponents so he only needs to survive long enough to win the game. In the other group of cases either the opponent is not well positioned on the board or its opponents are better situated. \nIn this case further investments are necessary to improve the \nsituation so the player can have a chance of winning in the long run.  \nThese metrics can be owning color groups, valuing groups of \nrailroads, evaluating the other opponents as well, and considering \nthe amount of cash. As it is obvious in monopoly the number of streets is not as nearly as important as the combination of streets the player owns. It is also important to note that one CBR case \ndoes not hold only a single strategy in place, but its solution can \nhave multiple different strategic goals. For example one CBR case might simultaneously say buy this land to form a color group but also trade some other unimportant property to increase cash \namount.  \nThe cases do not represent all possible combinations of board \npositions. They are only representation of typical game scenarios. The CBR Case solutions do not give exact instructions in general but rather strategic goals. For example one CBR Solution might \nsay trade the streets that you only have one of each for the ones \nthat you have two of that color already. Then the planner based on \nthe situation on the board needs to decompose this high level task to a low level operations. Like offer \"Mediterranean Avenue\" for \n\"Reading Railroad\" and offer $50. The exact amounts and actual \nstreets are left to the planer to evaluate.  \nThe monopoly CBR database is currently in development on \na monopoly clone game called Sp aceopoly. The cases are \narchitected based on human player experience and knowledge. \nThere is a plan of making a number of slightly different strategies that differ on the style of playing and then running simulation tests that would determine the particular validity of each database \nas well as validity of certain segments of the strategy or even \nparticular cases in the database.  \nThe actual execution of the strategies will not differ from \nstrategy to strategy since the plan  execution is more related to the \nstructure and rules of the game than to the actual playing strategy. \n6.3 Details on the Planning Implementation \nFor the purpose of planning this implementation uses a \nmodification of the JSHOP2 planner. The Java Simple Hierarchical Ordered Planner 2 is a domain independent HTN \nplanning system [15].  JSHOP2 uses ordered task decomposition  in reducing the \nHTN to list of primitive tasks which form the plans. An ordered task decomposition planner is an HTN planner that plans for tasks \nin the same order that they will be executed. This reduces the \ncomplexity of reasoning by removing a great deal of uncertainty about the world, which makes it easy to incorporate substantial expressive power into the planning algorithm. In addition to the \nusual HTN methods and operators, the planners can make use of \naxioms, can do mixed symbolic/numeric conditions, and can do external function calls. \n In order for the JSHOP2 planer to generate plans it needs \ntree crucial components: Domain, State and Tasks. The Domain \ndefines all the functionalities that the particular domain offers. These are simple and complex tasks. The complex tasks also called methods create the hierarchy with the fact that they can be \nevaluated by simple tasks of other complex tasks. This is how a \nhierarchical structure of tasks is formed. The problem reduction is done by reducing the high level complex tasks to simpler until all the tasks are primitive. The list of primitive tasks forms the plan. \nThe State represents the state of the system. It is a simple \ndatabase of facts that represent the state of the system. The State is necessary to determine the way the problems or tasks are \nreduced to their primitive level. The reduction is done by \nsatisfying different prerequisites set in the methods; these \nprerequisites are defined in the state. The Tasks are high level tasks or methods defined in the Domain. The planner based on the State and the goals selects one or more high level tasks that need \nto be reduced to plans [Figure  15]. \nFigure 15: Diagram of a Planner \nThe plans then generate the game moves. The number of \nmoves generated by the plans is just a fraction of the possible \nmoves at that point. This reduces the game tree providing the opportunity to generate smaller and deeper game trees and making more efficient decisions in general.  \n7. Conclusion \nEven though the results from the CBR database are not \ncomplete at this time partial strategies are implemented as cases and recognized during game play by the CBR system. These smaller local strategies coupled with more global higher level strategies that are particularly important at the beginning of the \ngame would form a complete CBR database and represent a \nknowledge engineered style of playing of the AI player.  \nThe AI Planning approach is a proven method by the tic-tac-\ntoe experiment and is suitable for implementing the strategies \nassociated with the CBR cases. \nThis approach in general benefits from both technologies, \nCBR as well as AI Planning and comprises an elegant solution. Even though AI Planning can be enough as a single technology \nfor some simpler problems like tic-tac-toe the complexity of \nMonopoly would mean that the Planner would have to incorporate Core Planner Tasks\nPlan StateInteractive and Adaptable Media 301\n3rd International Conference on Digital Interactive Media in Entertainment and Arts",
    "large and complex domain and a very big state model. The CBR \napplication helps reduce this complexity by focusing the planning on smaller domain of the game. Basically the CBR reduces the \noverall goal of the play (wining the game) to smaller more \nconcrete goals suitable to the particular state of the game, thus reducing the need for global planning strategies and complex planning domain.  \nFurthermore this symbiosis of technologies gives way for \nmore precise and finely tuned strategies which can be difficult to include into global plan for the whole game. One simple example for the Monopoly game would be this: Sometimes it\u2019s better to \nstay in jail because rolling double increases the probability of \nlanding on some field (two, four, six, eight, ten or twelve steps from the jail) that can be of gr eat importance to the rest of the \ngame. These and similar small local strategies can be easily \nrecognized by similar cases in the CBR database.  \nIn other words the system is flexible enough so that new \nstrategies can be incorporated easily missing strategies can be also recognized by the distance metrics as well as wrong assumptions \nin the strategies can be easily recognized. \nOne other important property of the system is that is highly \nconfigurable. The game its self can be diversely different depending on the configuration of the board. Even though the \nplatform is restricted to Monopoly type of games, changing the \nlayout and values of the fields effectively brings completely different properties of the game. In addition the CBR database represents the entire experience of the AI Player. It can be filled \nwith rich set of strategies or even configured with different flavors \nof difficulties of play, this of course coupled with the domain of the planner which can differ from a case to a case as well.  \n8. Future Work \nFurther exploration of this technology would go towards \ncomplete implementation of an AI aware agent for monopoly. \nInitial results from the local case s with more specific strategies \nshow CBR as a capable tool for representing expertise in playing the game. Completing the more general strategies and c oupling \nthem with the planning domain will give precise results on the \nbenefits from this architecture. \nThere is also need for exploring the planning of strategies of \nopponents. This task is to some extent different because we cannot always expect the opponent to select the best move we \nthink. In the Tic-tac-toe example all possible moves of the \nopponent were taken into consideration, if we used the same planner for the opponent only tie games would result from the game tree. In other words mistakes of the players also need to be \nconsidered.  \nThe CBR Platform brings other functionalities well worth of \nexploring as well. The revision stage of the JColibri2 platform is basically capable of fine tuning strategies or even developing new \nstrategies for the games. A well written underlying AI planning \nmodel with a capable feedback of the game tree evaluation back to the CBR revision capability can be an interesting concept in automatic experience acquisition for the AI model. \nThere are also many other fields were combined CBR and \nplanning approach can be incorporated into a problem solution. This combination is analogous in a big extent to a human way of reasoning. People in addition to lo gic of reasoning in situations \nwith lack of information rely to planning strategies and prior experience, exactly the intuition behind CBR \u2013 AI Planning \narchitecture.  \n9. ACKNOWLEDGMENTS \nWe would like to thank Prof. Sofia Tsekeridou for her \ninvolvement in the valuable discussions we had on the topic of CBR. \n10. REFERENCES \n[1] Minimax. Wikipedia. [Online] [Cited: April 23, 2008.] \nhttp://en.wikipedia.org/wiki/Minimax . \n[2] Von Neumann, J : Zur theorie der gesellschaftsspiele  Math. \nAnnalen. 100 (1928) 295-320 \n[3] Automated Planning. Wikipedia. [Online] [Cited: April 23, \n2008.] http://en.wikipedia.org/wiki/Automated_planning . \n[4] Sanchez-Ruiz, Antonio, et al. Game AI for a Turn-based \nStrategy Game with Plan Adaptation and Ontology-based \nretrieval .\n[5] K. Erol, J. Hendler, and D. Nau  (1994). Semantics for \nhierarchical task-network planning . Technical Report TR-94-\n31, UMIACS. \n[6] Smith, S. J. J. and Dana S. Nau, T. A. Throp.  A Planning \napproach decrarer play in contract bridge. Computational \nIntelligence. 1996, Vol. 12, 1. \n[7] One Jump Ahead: Challenging Human Supremacy in \nCheckers. J.Schaeffer.  s.l. : Springer-Verlag, 1997. \n[8] IBM.  How Deep Blue works. [Online] 1997. [Cited: April \n23, 2008.] \nhttp://www.research.ibm.com/d eepblue/meet/html/d.3.2.html\n[9] Ghallab, Malik, Nau, Dana and Traverso, Paolo.\nAutomated Planning theory and practice. s.l. : Morgan \nKaufmann Publishers, May 2004. ISBN 1-55860-856-7. \n[10] Case Based Reasoning. Experiences, Lessons and Future. \nLeake, David.  s.l. : AAAI Press. MIT Press., 1997. \n[11] Applying case-based reasoning: techniques for enterprise \nsystems. Watson, I.  San Francisco, CA, USA : Morgan \nKaufmann Publishers Inc., 1998. \n[12] Plaza, A. Aamodt and E.  Case-based reasoning: \nFoundational issues, methodological. AI Communications. \n1994, 7(i). \n[13] Tic-tac-toe. Wikipedia. [Online] [Cited: April 23, 2008.] \nhttp://en.wikipedia.org/wiki/Tic-tac-toe. \n[14] D\u00edaz-Agudo, B. and Gonz\u00e1lez-Calero, P. A.  An \narchitecture for knowledge intensive CBR systems. Advances \nin Case-Based Reasoning \u2013 (EWCBR\u201900). New York : \nSpringer-Verlag, Berlin Heidelberg, 2000. \n[15] Ilghami, Okhtay and Nau, Dana S. A General Approach to \nSynthesize Problem-Specific Planners. 2003. 302 DIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts"
]