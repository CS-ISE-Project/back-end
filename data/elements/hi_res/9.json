[
    {
        "element_id": "1856eebe-edfb-4b97-9486-645fcc330cc1",
        "metadata": {},
        "text": "Generating Diverse Code Explanations using the GPT-3 Large Language Model Andrew Tran andrew.tran10@temple.edu Temple University Philadelphia, PA, USA",
        "type": "UncategorizedText"
    },
    {
        "element_id": "ec300f45-438d-475a-b6eb-797cbca8d00f",
        "metadata": {},
        "text": "Stephen MacNeil stephen.macneil@temple.edu Temple University Philadelphia, PA, USA",
        "type": "NarrativeText"
    },
    {
        "element_id": "ded86031-d513-4b00-b26a-2845dcb9e653",
        "metadata": {},
        "text": "Dan Mogil daniel.mogil@temple.edu Temple University Philadelphia, PA, USA",
        "type": "Title"
    },
    {
        "element_id": "bb4fc8e4-4a57-41ea-b590-ef894d6c834b",
        "metadata": {},
        "text": "Seth Bernstein seth.bernstein@temple.edu Temple University Philadelphia, PA, USA",
        "type": "NarrativeText"
    },
    {
        "element_id": "783a17ff-019b-4fac-b4c9-97e5356931e5",
        "metadata": {},
        "text": "Erin Ross erinross@temple.edu Temple University Philadelphia, PA, USA",
        "type": "Title"
    },
    {
        "element_id": "15395cc5-903b-4a0c-8dac-49dbbfd2d658",
        "metadata": {},
        "text": "Ziheng Huang z8huang@ucsd.edu University of California\u2014San Diego La Jolla, CA, USA",
        "type": "Title"
    },
    {
        "element_id": "d3c7ba07-8e62-4ef0-abf2-6ebe7ec76fcf",
        "metadata": {},
        "text": "KEYWORDS large language models, natural language processing, code explana- tions, computer science education",
        "type": "UncategorizedText"
    },
    {
        "element_id": "d2fa65ff-d9bb-459a-9300-fc7a59c22b6e",
        "metadata": {},
        "text": "ACM Reference Format: Stephen MacNeil, Andrew Tran, Dan Mogil, Seth Bernstein, Erin Ross, and Ziheng Huang. 2022. Generating Diverse Code Explanations using the GPT-3 Large Language Model. In Proceedings of the 2022 ACM Conference on International Computing Education Research V.2 (ICER 2022), August 7\u201311, 2022, Lugano and Virtual Event, Switzerland. ACM, New York, NY, USA, 3 pages. https://doi.org/10.1145/3501709.3544280",
        "type": "NarrativeText"
    },
    {
        "element_id": "fe2924f8-8720-4cb4-b939-96fa94bcd964",
        "metadata": {},
        "text": "1 ABSTRACT Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these ap- proaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github\u2019s Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs\u2019 potential to support learning by explain- ing numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.",
        "type": "NarrativeText"
    },
    {
        "element_id": "78f9778c-98f4-4790-af7b-6020ca2a4b3b",
        "metadata": {},
        "text": "2 USE CASES To understand the types of explanations GPT-3 [2] can generate, we issued over 700 prompts across numerous code snippets. An example prompt and resulting explanation is shown in Figure 1. We discovered eight explanation types and Figure 2 includes three",
        "type": "NarrativeText"
    },
    {
        "element_id": "b8dc153f-2403-4e9a-962c-7982c9e48734",
        "metadata": {},
        "text": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). ICER 2022, August 7\u201311, 2022, Lugano and Virtual Event, Switzerland \u00a9 2022 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9195-5/22/08. https://doi.org/10.1145/3501709.3544280",
        "type": "NarrativeText"
    },
    {
        "element_id": "70247093-9344-47f9-8258-2a124281c727",
        "metadata": {},
        "text": "explanation types to illustrate the explanatory power of GPT-3. The additional types include: 1) tracing the execution of code, 2) fixing bugs and explaining how they were fixed, 3) generating analogies to real world settings, 4) listing relevant programming concepts, and 5) predicting the console output.",
        "type": "NarrativeText"
    },
    {
        "element_id": "027e57ff-d682-44a1-b9c1-0953cd868b11",
        "metadata": {},
        "text": "Prompt #Give areal world analogy forthis code << Directions (explanation type) public static void main(String[] args) { \u20ac Code Snippet for(int i=1;i<= for(int j=1; System.out.printin(i+\" \"+)); Explanation =: Q",
        "type": "Image"
    },
    {
        "element_id": "d197dca8-bee4-450e-a74d-05ec89da63c4",
        "metadata": {},
        "text": "Figure 1: A prompt and explanation based on analogy.",
        "type": "Title"
    },
    {
        "element_id": "63afed59-623d-4508-870b-48180ae4b250",
        "metadata": {},
        "text": "2.1 Analyzing and explaining time complexity Instructors rate time complexity as the most difficult programming topic [17]. However, understanding time complexity is important [6, 13] because it facilitates decision-making so students choose an appropriate algorithm for a given problem. This use case shows GPT-3 can identify and explain time complexity.",
        "type": "NarrativeText"
    },
    {
        "element_id": "72236dce-6439-4c9d-90f4-d87d58f2c884",
        "metadata": {},
        "text": "2.2 Identifying common mistakes made by beginner programmers",
        "type": "Title"
    },
    {
        "element_id": "81d3c0ba-7370-4d1e-aab6-79286a9ebbbd",
        "metadata": {},
        "text": "Commonality exists in how students solve programming prob- lems [15] and the mistakes they make [1, 11]. Pedagogical tech- niques, such as the \u2018muddiest point\u2019 highlight these common and most confusing concepts [3, 14]. GPT-3 can automatically create a checklist of common mistakes students might make regarding a given code snippet.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e638dccc-7e8d-4c51-a249-6a293fdd6cb4",
        "metadata": {},
        "text": "37",
        "type": "Footer"
    },
    {
        "element_id": "9543375a-3690-4e13-9643-36229e8be383",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "846e46b7-94bc-4698-9777-481078e23657",
        "metadata": {},
        "text": "ICER 2022, August 7\u201311, 2022, Lugano and Virtual Event, Switzerland",
        "type": "NarrativeText"
    },
    {
        "element_id": "1dff373c-2ccf-4c0e-943e-24be2e0cc1d8",
        "metadata": {},
        "text": "MacNeil et al.",
        "type": "Header"
    },
    {
        "element_id": "3d975874-1720-489e-b4a6-edc9ae495995",
        "metadata": {},
        "text": "Code Snippet Given Java Code: int algorithm (int arr], int |, int r, int x) { if (r >= 1) { int mid =1 + (r- 1) / 2; if (arr[mid: return mid; if (arr[mid] > x) return algorithm(arr, |, mid - 1, x); return algorithm(arr, mid + 1, r, x); } return -1; 1. Time Complexity Whatis the time complexity of this code and why? The time complexity of this code is O(log n). This is because the code is using a Binary Search algorithm, which halves the 2. Identifying Common Mistakes List the common mistakes a beginner programmer might make while writing this code. How can a beginner programmer avoid each of these mistakes? A beginner programmer might make the following mistakes while writing this code: 1. Not understanding how binary search works - Binary search is a search algorithm that searches for an element in a sorted array by repeatedly dividing the array in half and comparing the element to the middle element of the array. If the element is not found, the search continues in the lower or upper half of the array, depending on whether the element is less than or greater than the middle element, respectively. 2. Not correctly implementing the binary search algorithm - In order to correctly implement binary search, the programmer must ensure that the array is sorted before beginning the search. Furthermore, the programmer must correctly handle the case when the element is not found in the array. 3. Not using the proper data structures - Binary search can only be performed on an array. If the programmer is using a linked list, for example, binary search cannot be used. 4. Not using the proper variable types - Binary search requires that the array be of type int. If the programmer is using a different data type, binary search will not work. 5. Not understanding the time complexity of binary search - Binary search has a time complexity of O(log n), which means that it is a very efficient algorithm. If the programmer is not aware of this, they may try to improve the efficiency of the algorithm by making unnecessary changes. 3. Summarizing Code Summarize and explain the goal of this code. The goal of this code is to find the index of a given element in an array using a binary search algorithm. The code takes in an array, the left and right indices of the array, and the element to be found as parameters. If the element is found, the code returns the index of the element. If the element is not found, the code returns -1. search space each time it is called.",
        "type": "Image"
    },
    {
        "element_id": "37c08c14-5208-497d-9a8e-b3fe2647b576",
        "metadata": {},
        "text": "Figure 2: Three example explanations automatically generated by GPT-3 for an \u2018anonymized\u2019 Binary Search code snippet.",
        "type": "Title"
    },
    {
        "element_id": "c93faa01-f9e5-4646-bcf2-9114829d67e7",
        "metadata": {},
        "text": "2.3 Summarizing code at multiple levels of abstraction",
        "type": "Title"
    },
    {
        "element_id": "512fd7e2-8ad9-46cd-940f-78507b2a9ea8",
        "metadata": {},
        "text": "Before understanding how a code snippet executes, it is often useful to understand the purpose of the code [5]. The summary gener- ated by GPT-3 and shown in Figure 2 defines the goal, traces the execution, and highlights relevant CS concepts such as arrays.",
        "type": "NarrativeText"
    },
    {
        "element_id": "25c3cdd0-caf5-42fe-a729-ec1bd9ae8558",
        "metadata": {},
        "text": "[5] Kathryn Cunningham, Yike Qiao, Alex Feng, and Eleanor O\u2019Rourke. 2022. Bring- ing \"High-Level\" Down to Earth: Gaining Clarity in Conversational Program- mer Learning Goals. In Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 1 (Providence, RI, USA) (SIGCSE 2022). As- https: sociation for Computing Machinery, New York, NY, USA, 551\u2013557. //doi.org/10.1145/3478431.3499370",
        "type": "NarrativeText"
    },
    {
        "element_id": "269b978c-462d-425b-9d59-5aa8ce02a27d",
        "metadata": {},
        "text": "[6] Elvina Elvina and Oscar Karnalim. 2017. Complexitor: An educational tool for learning algorithm time complexity in practical manner. ComTech: Computer, Mathematics and Engineering Applications 8, 1 (2017), 21\u201327.",
        "type": "ListItem"
    },
    {
        "element_id": "7c3ee6b0-b878-4d1f-af16-7079af063c88",
        "metadata": {},
        "text": "3 DISCUSSION Our three use cases demonstrate the potential for GPT-3 to explain code for intro CS students. Our poster presentation will feature all eight explanation types as a design space of explanations to convey the diversity of explanations that can be generated by LLMs. We will highlight best practices for generating effective explanations and pitfalls that lead to less effective explanations. We are evaluating the usefulness of these explanations in a series of summer classes.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b6a5b1dd-c39b-4193-bf32-b83bd6b4700e",
        "metadata": {},
        "text": "[7] James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and James Prather. 2022. The Robots Are Coming: Exploring the Implications of Ope- nAI Codex on Introductory Programming. In Australasian Computing Education Conference (Virtual Event, Australia) (ACE \u201922). ACM, New York, NY, USA, 10\u201319. https://doi.org/10.1145/3511861.3511863",
        "type": "NarrativeText"
    },
    {
        "element_id": "1e36b44f-7ab2-40b2-b0f3-3e1abf1288ca",
        "metadata": {},
        "text": "[8] Philip J Guo. 2013. Online python tutor: embeddable web-based program visual- ization for cs education. In Proceeding of the 44th ACM technical symposium on Computer science education. 579\u2013584.",
        "type": "ListItem"
    },
    {
        "element_id": "4017be97-a9b2-4d07-8af6-51498b82f654",
        "metadata": {},
        "text": "[9] Andrew Head, Codanda Appachu, Marti A Hearst, and Bj\u00f6rn Hartmann. 2015. Tutorons: Generating context-relevant, on-demand explanations and demonstra- tions of online code. In 2015 IEEE Symposium on Visual Languages and Human- Centric Computing (VL/HCC). IEEE, 3\u201312.",
        "type": "ListItem"
    },
    {
        "element_id": "5658378e-1f75-4687-9bd0-f27e660922c3",
        "metadata": {},
        "text": "REFERENCES [1] Amjad Altadmri and Neil CC Brown. 2015. 37 million compilations: Investigating novice programming mistakes in large-scale student data. In Proceedings of the 46th ACM Technical Symposium on Computer Science Education. 522\u2013527. [2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in Neural Information Processing Systems 33 (2020), 1877\u20131901.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3506b06f-3dbe-4473-b841-b11bd3350c62",
        "metadata": {},
        "text": "[3] Adam Carberry, Stephen Krause, Casey Ankeny, and Cynthia Waters. 2013. \u201cUnmuddying\u201d course content using muddiest point reflections. In 2013 IEEE Frontiers in Education Conference (FIE). IEEE, 937\u2013942.",
        "type": "ListItem"
    },
    {
        "element_id": "f6c393f0-26d1-4f92-b192-8dd94c793d6d",
        "metadata": {},
        "text": "[10] Samiha Marwan, Ge Gao, Susan Fisk, Thomas W. Price, and Tiffany Barnes. 2020. Adaptive Immediate Feedback Can Improve Novice Programming Engagement and Intention to Persist in Computer Science. In Proceedings of the 2020 ACM Conference on International Computing Education Research (Virtual Event, New Zealand) (ICER \u201920). Association for Computing Machinery, New York, NY, USA, 194\u2013203. https://doi.org/10.1145/3372782.3406264",
        "type": "ListItem"
    },
    {
        "element_id": "0d87c140-7eaa-44f6-a11b-ffe0061235a1",
        "metadata": {},
        "text": "[11] Davin McCall and Michael K\u00f6lling. 2014. Meaningful categorisation of novice pro- grammer errors. In 2014 IEEE Frontiers in Education Conference (FIE) Proceedings. IEEE, 1\u20138.",
        "type": "ListItem"
    },
    {
        "element_id": "8ecdd288-28b8-4874-9547-9010e31b647a",
        "metadata": {},
        "text": "[12] Greg L Nelson, Benjamin Xie, and Amy J Ko. 2017. Comprehension first: eval- uating a novel pedagogy and tutoring system for program tracing in CS1. In Proceedings of the 2017 ACM conference on international computing education research. 2\u201311.",
        "type": "ListItem"
    },
    {
        "element_id": "22908f80-c923-4838-b763-f2f224789339",
        "metadata": {},
        "text": "[4] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021).",
        "type": "ListItem"
    },
    {
        "element_id": "394ec4a6-1399-4ece-b84d-fd33ed267cb9",
        "metadata": {},
        "text": "[13] Miranda Parker and Colleen Lewis. 2014. What makes big-O analysis difficult: understanding how students understand runtime analysis. Journal of Computing Sciences in Colleges 29, 4 (2014), 164\u2013174.",
        "type": "ListItem"
    },
    {
        "element_id": "89038702-98bd-481e-83ad-19ca8201fd02",
        "metadata": {},
        "text": "[14] Daniel Perez, Leila Zahedi, Monique Ross, Jia Zhu, Tiffany Vinci-Cannava, Laird Kramer, and Maria Charters. 2020. WIP: An exploration into the muddiest points",
        "type": "ListItem"
    },
    {
        "element_id": "c8c611b0-5f4b-4ac0-beff-9aab8d8b65c8",
        "metadata": {},
        "text": "38",
        "type": "Footer"
    },
    {
        "element_id": "528ec658-3083-4980-8642-52d3bb53a4fd",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "d55cd273-e2ca-4580-a228-441dd38cf599",
        "metadata": {},
        "text": "Generating Diverse Explanations with Large Language Models",
        "type": "NarrativeText"
    },
    {
        "element_id": "583600ee-7f25-411f-bece-05acae94d1a9",
        "metadata": {},
        "text": "and self-efficacy of students in introductory computer science courses. In 2020 IEEE Frontiers in Education Conference (FIE). IEEE, 1\u20135.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ac6e694c-19cd-40f5-be33-b9101b1bb208",
        "metadata": {},
        "text": "[15] Chris Piech, Mehran Sahami, Jonathan Huang, and Leonidas Guibas. 2015. Au- tonomously generating hints by inferring problem solving policies. In Proceedings of the second (2015) acm conference on learning@ scale. 195\u2013204.",
        "type": "ListItem"
    },
    {
        "element_id": "ea0543a7-3c26-48d6-add0-a544b5fe2b93",
        "metadata": {},
        "text": "39",
        "type": "Header"
    },
    {
        "element_id": "cdb3c204-bb89-46f5-a9cf-01a228d1c531",
        "metadata": {},
        "text": "ICER 2022, August 7\u201311, 2022, Lugano and Virtual Event, Switzerland",
        "type": "NarrativeText"
    },
    {
        "element_id": "1b3a5ffa-d641-4ebd-968f-4519d7b67259",
        "metadata": {},
        "text": "iSnap: towards intelligent tutoring in novice programming environments. In Proceedings of the 2017 ACM SIGCSE Technical Symposium on computer science education. 483\u2013488. [17] Carsten Schulte and Jens Bennedsen. 2006. What do teachers teach in introductory programming?. In Proceedings of the second international workshop on Computing education research. 17\u201328.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3a9dee84-7a0b-47bb-985d-e3188c6f8a45",
        "metadata": {},
        "text": "[16] Thomas W Price, Yihuan Dong, and Dragan Lipovac. 2017.",
        "type": "Title"
    }
]