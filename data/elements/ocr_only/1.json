[
    {
        "element_id": "d4cbe82d-4845-45f9-95d7-3607b0f9bfa8",
        "metadata": {},
        "text": "Check for updates.",
        "type": "Title"
    },
    {
        "element_id": "30136721-00d0-46c2-9678-5b19f95dc1e7",
        "metadata": {},
        "text": "Interactive and Adaptable Media 295",
        "type": "Title"
    },
    {
        "element_id": "b30f7354-25f3-470b-95bf-873e0db0ff97",
        "metadata": {},
        "text": "Al Model for Computer games based on Case Based Reasoning and Al Planning",
        "type": "UncategorizedText"
    },
    {
        "element_id": "3f171034-65f2-4685-878b-c831a240b882",
        "metadata": {},
        "text": "Vlado Menkovski Athens Information Technology",
        "type": "Title"
    },
    {
        "element_id": "910b50bd-fbf0-48ea-8dbc-38a0801201fa",
        "metadata": {},
        "text": "0.8km Markopoulou Ave. Peania, 19002, Greece vmen@ait.edu.gr",
        "type": "Title"
    },
    {
        "element_id": "a589f488-d7e9-4625-ae89-ecaf433b2c12",
        "metadata": {},
        "text": "Abstract",
        "type": "Title"
    },
    {
        "element_id": "dccf82d7-94eb-49c4-9762-92aeb3daf987",
        "metadata": {},
        "text": "Making efficient AI models for games with imperfect information can be a particular challenge. Considering the large number of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This effort is focused on presenting a method of combined Case Based Reasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies in effect discarding meaningless moves. These strategies are selected by finding similarities to s in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to reach these goals. The plan is basically a set of moves that brings the player to this goal. By following these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by the same amount of memory.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9544b3cd-592f-4063-9818-ac450de9a851",
        "metadata": {},
        "text": "Categories and Subject Descriptors",
        "type": "Title"
    },
    {
        "element_id": "85f256cf-6862-4064-b583-feee6dffb3dd",
        "metadata": {},
        "text": "1.2.1 [Applications and Expert Systems]: Games",
        "type": "Title"
    },
    {
        "element_id": "73f5233e-88fd-49f2-a604-6b5d66d33d3d",
        "metadata": {},
        "text": "General Terms Algorithms, Performance.",
        "type": "Title"
    },
    {
        "element_id": "c8694beb-c55c-4b2c-a8b2-9b4739ab7fa2",
        "metadata": {},
        "text": "Keywords",
        "type": "Title"
    },
    {
        "element_id": "a520924b-bf89-48a3-83d1-f2cd47d611cb",
        "metadata": {},
        "text": "Game AI, Case Based Reasoning, AI Planning, Game Trees",
        "type": "Title"
    },
    {
        "element_id": "10b8c3bc-6cf9-4881-80c3-4954d53c2392",
        "metadata": {},
        "text": "1. Introduction",
        "type": "ListItem"
    },
    {
        "element_id": "4db1eb1f-37ef-4f09-950f-90eea0e5c0f8",
        "metadata": {},
        "text": "The goal of this effort is to explore a model for design and implementation of an AI agent for turn based games. This model provides for building more capable computer opponents that rely on strategies that closely resemble human approach in solving problems opposed to classical computational centric heuristics in game AI. In this manner the computational resources can be focused on more sensible strategies for the game play.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a8b9c6ec-09a5-4d99-955f-35144db48cbd",
        "metadata": {},
        "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c0100c9e-fd38-471d-80c8-34910c473418",
        "metadata": {},
        "text": "DIMEA\u201908, September 10-12, 2008, Athens, Greece.",
        "type": "Title"
    },
    {
        "element_id": "005fe01f-4532-4e29-b9a8-a261e8372507",
        "metadata": {},
        "text": "Copyright 2008 ACM 978-1-60558-248-1/08/09... $5.00",
        "type": "UncategorizedText"
    },
    {
        "element_id": "a738efa3-32aa-431a-87e1-e3b0e079952b",
        "metadata": {},
        "text": "Dimitrios Metafas Athens Information Technology",
        "type": "Title"
    },
    {
        "element_id": "c3beb406-1541-4f74-94f8-1ab17ce4251c",
        "metadata": {},
        "text": "0.8km Markopoulou Ave. Peania, 19002, Greece dmeta@ait.edu.gr",
        "type": "Title"
    },
    {
        "element_id": "2655eda4-6fbd-42a8-a2b9-c14830fcd6d9",
        "metadata": {},
        "text": "With the advancement in computer hardware increasingly more computing power is left for executing AI algorithms in games. In the past AI in games was mainly a cheating set of instructions that simulated the increasing difficulty in the game environment so that the player had the illusion of real counterpart. Improvement in available memory and processing power allows implementation of more intelligent algorithms for building the game environment as well as direct interaction with the human players.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9fa9db10-72ec-4a16-87d0-4ca1ef7c27c0",
        "metadata": {},
        "text": "In this particular research the emphasis is put on the interaction between the AI agent and a computer player in the realm of the game rules. It is particularly focused on turn based games that have the elements of uncertainty like dice or concealed information. At the beginning a description of Game AI algorithms are given; such as Game Trees and Minimax. The following section describes an approach of using AI Planning to improve building Game Trees in games with imperfect information where Game Trees tend to be very large with high growth ratio. Section 4 discusses another approach that provides a significant reduction to the number of considered moves in order to find the favorable strategy of the AI player. This approach uses AI Planning techniques and Case Base Reasoning (CBR) to plan for different scenarios in predetermined strategies which would be analogous to human player experience in the particular game. The CBR database illustrates a set of past experiences for the AI problem and the AI Planning illustrates the procedure to deal with the given situation in the game. In the next two sections implementations and evaluations of both approaches are given. The AI Planning approach is implemented with the Tic-tac-toe game and the combined AI Planning and CBR approach is implemented with a model for the Monopoly game. The last part contains conclusions and future work ideas.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1ea3f3f4-afd2-4208-afb1-026b93af5ae4",
        "metadata": {},
        "text": "2. Game Trees and Minimax",
        "type": "ListItem"
    },
    {
        "element_id": "18a36a01-0158-4b61-b2d5-4d23109473ae",
        "metadata": {},
        "text": "Game Trees are common model for evaluating how different combinations of moves from the player and his opponents will affect the future position of the player and eventually the end result of the game. An algorithm that decides on the next move by evaluating the results from the built Game Tree is minimax [1]. Minimax assumes that the player at hand will always choose the best possible move for him, in other words the player will try to select the move that maximizes the result of the evaluation function over the game state. So basically the player at hand needs to choose the best move overall while taking into account that the next player(s) will try to do the same thing. Minimax tries to maximize the minimum gain. Minimax can be applied to multiple",
        "type": "NarrativeText"
    },
    {
        "element_id": "1ad66dd7-6387-40ed-b394-a984f3e2626e",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "ec3b3590-8876-4b29-95bc-61844e5924bd",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "b91cc6f5-ce49-4e61-98fc-04de67eb5983",
        "metadata": {},
        "text": "296 DIMEA 2008",
        "type": "UncategorizedText"
    },
    {
        "element_id": "5dc2bdc5-9660-4a94-a721-7a6adc9a39a3",
        "metadata": {},
        "text": "levels of nodes on the game tree, where the leaves bring the final known (or considered) game state.",
        "type": "NarrativeText"
    },
    {
        "element_id": "085dee1d-c728-4861-a453-18cd92a7a6c0",
        "metadata": {},
        "text": "The minimax theorem states:",
        "type": "Title"
    },
    {
        "element_id": "ff5ae2ec-e65b-4541-82e4-04f5d0598cae",
        "metadata": {},
        "text": "For every two-person, zero-sum game there is a mixed strategy for each player, such that the expected payoff for both is the same value V when the players use these strategies. Furthermore, V is the best payoff each can expect to receive from a play of the game; that is, these mixed strategies are the optimal strategies for the two players.",
        "type": "NarrativeText"
    },
    {
        "element_id": "40849b6b-aded-41da-b6b2-ff92e161d9a0",
        "metadata": {},
        "text": "This theorem was established by John von Neumann, who is quoted as saying \"As far as I can see, there could be no theory of games ... without that theorem ... I thought there was nothing worth publishing until the Minimax Theorem was proved\" [2].",
        "type": "NarrativeText"
    },
    {
        "element_id": "30c08fc1-a1e6-4335-abe8-a5070c32b877",
        "metadata": {},
        "text": "A simple example of minimax can be observed by building a game tree of the tic-tac-toe game. The tic-tac-toe game is a simple game which can end by the first player wining, the second player wining or a tie. There are nine positions for each of the players in which at each turn the player puts X or O sign. If the player has three adjacent signs in a row, column or the two diagonals he or she wins. This game has limited number of position and it is well suited for building the whole game tree. The leaves of this tree will be final positions in the game. A heuristics evaluation function will also need to be written to evaluate the value of each node along the way.",
        "type": "NarrativeText"
    },
    {
        "element_id": "63e85290-6444-4df0-808b-512ab1ad3873",
        "metadata": {},
        "text": "3. AI Planning for building Game Trees 3.1.1 AI Planning",
        "type": "ListItem"
    },
    {
        "element_id": "733b8311-53fd-400c-80fb-e827ff877bef",
        "metadata": {},
        "text": "AI Planning also referred as Automated Planning and Scheduling is a branch of Artificial Intelligence that focuses on finding strategies or sequences of actions that reach a predefined goal [3]. Typical execution of AI Planning algorithms is by intelligent agents, autonomous robots and unmanned vehicles. Opposed to classical control or cl: ication AI Planning results with complex solutions that are derived from multidimensional space.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ac5819d4-7ec2-4076-8b56-8eb6c979bd87",
        "metadata": {},
        "text": "AI Planning algorithms are also common in the video game development. They solve broad range of problems from path finding to action planning. A typical planner takes three inputs: a description of the initial state of the world, a description of the desired goal, and a set of possible actions. Some efforts for incorporating planning techniques for building game trees have also shown up, similar to the approach explored in this effort. In addition Cased Based Reasoning [4] techniques are also gathering popularity in developing strategies based in prior knowledge about the problems in the games. One of the benefits from Hierarchical Task Network (HTN) [5] planning is the possibility to build Game Trees based on HTN plans; this method is described in the following section.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7bd2b28a-8603-4c3f-9f12-7144f16668fe",
        "metadata": {},
        "text": "3.2. Game Trees with AI Planning",
        "type": "Title"
    },
    {
        "element_id": "c9f9ab8f-aea1-4837-bf7d-65970d549ca7",
        "metadata": {},
        "text": "An adaptation of the HTN planning can be used to build much smaller and more efficient game trees. This idea has already been implemented in the Bridge Baron a computer program for the game of Contact Bridge [6].",
        "type": "NarrativeText"
    },
    {
        "element_id": "43179028-ed51-48fc-bdc7-91d8586243c6",
        "metadata": {},
        "text": "Computer programs based on Game Tree search techniques are now as good as or better than humans in many games like Chess [7] and checkers [8], but there are some difficulties in building a game tree for games that have imperfect information and added uncertainty like card or games with dice. The main",
        "type": "NarrativeText"
    },
    {
        "element_id": "8aa231b3-cddb-4347-8ca6-3eb42fac6780",
        "metadata": {},
        "text": "problem is the enormous number of possibilities that the player can choose from in making his move. In addition some of the moves are accompanied with probabilities based on the random elements in the games. The number of possible moves exponentially grows with each move so the depth of the search has to be very limited to accommodate for the memory limitations.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e502150c-552b-481e-93d2-b45c252475cc",
        "metadata": {},
        "text": "The basic idea behind using HTN for building game trees is that the HTN provides the means of expressing high level goals and describing strategies how to reach those goals. These goals may be decomposed in goals at lower level called sub-goals. This approach closely resembles the way a human player usually addresses a complex problem. It is also good for domains where classical search for solution is not feasible due to the vastness of the problem domain or uncertainties.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f108aeb9-1513-4038-bb77-586d1cfd8875",
        "metadata": {},
        "text": "3.2.1 Hierarchical Task Networks",
        "type": "Title"
    },
    {
        "element_id": "cb4f6c1e-6291-4056-a743-a084ab613b96",
        "metadata": {},
        "text": "The Hierarchical Task Network, or HTN, is an approach to automated planning in which the dependency among actions can be given in the form of networks [9] [Figure 1].",
        "type": "NarrativeText"
    },
    {
        "element_id": "f5fb12cb-dc91-4906-bf62-a790eebf851d",
        "metadata": {},
        "text": "A simple task network (or just a task network for short) is an acyclic digraph w = (U,E) in which U is the node set, E is the edge set, and each node u \u20ac U contains a task t,,. The edges of w define a partial ordering of U. If the partial ordering is total, then we say that w is totally ordered, in which case w can be written as a sequence of tasks w = (ty, tz, ..,t,).",
        "type": "NarrativeText"
    },
    {
        "element_id": "d53710bd-f790-4f48-bc5d-b21dfef88873",
        "metadata": {},
        "text": "Purchase",
        "type": "Title"
    },
    {
        "element_id": "fe6f59bd-6673-47d4-b7e0-ef3eeef42b89",
        "metadata": {},
        "text": ">",
        "type": "UncategorizedText"
    },
    {
        "element_id": "3870c1f8-147c-40a4-890e-cd9e9ed915d2",
        "metadata": {},
        "text": "Go to (shop) Go to (home)",
        "type": "NarrativeText"
    },
    {
        "element_id": "df3c2b9e-0361-4764-825f-6d0b78b1639f",
        "metadata": {},
        "text": "Figure 1: Simple Hierarchical Task Network",
        "type": "Title"
    },
    {
        "element_id": "234ca907-d4a3-495c-bc17-b1cd5965251f",
        "metadata": {},
        "text": "A Simple Task Network (STN) method is a 4-tuple of its name, task, precondition and a task network. The name of the method ets us refer unambiguously to substitution instances of the method, without having to write the preconditions and effects explicitly. The task tells what kind of task can be applied if the reconditions are met. The preconditions specify the conditions that the current state needs to satisfy in order for the method to be applied. And the network defines the specific subtasks to accomplish in order to accomplish the task.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8645ae2c-38c0-4f34-be19-ad6cf24cfc24",
        "metadata": {},
        "text": "A method is relevant for a task if the current state satisfies the reconditions of a method that implements that task. This task can be then substituted with the instance of the method. The substitution is basically giving the method network as a solution for the task.",
        "type": "NarrativeText"
    },
    {
        "element_id": "259099a2-bd65-4949-b19e-b76e9557eb15",
        "metadata": {},
        "text": "If there is a task \u201cGo home\u201d and the distance to home is 3km Figure 2] and there exists a method walk-to and this method has a recondition that the distance is less than 5km, then a substation to the task \u201cGo home\u201d can be made with this method instance.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2ba24a48-ed18-4509-b558-d6c7d9364238",
        "metadata": {},
        "text": "Tf (to \u2014 from) < 5km",
        "type": "NarrativeText"
    },
    {
        "element_id": "c380337b-7db5-4a9e-a4ca-cd04874317bd",
        "metadata": {},
        "text": "Figure 2: HTN Method",
        "type": "Title"
    },
    {
        "element_id": "e9409a0d-b3fd-4b20-884b-97494582c200",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "a635d0c2-917d-47e7-b83a-f679c0e02365",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "8a78c721-67c3-476f-b15c-211ded8f3efd",
        "metadata": {},
        "text": "Interactive and Adaptable Media 297",
        "type": "Title"
    },
    {
        "element_id": "60fe50b5-decc-410b-88e5-9a5edf9066ab",
        "metadata": {},
        "text": "If the distance is larger than 5km another method instance needs to be substituted [Figure 3].",
        "type": "NarrativeText"
    },
    {
        "element_id": "ff5fb10c-a3ec-456d-bf31-ab943cccdd4b",
        "metadata": {},
        "text": "Go-to (from, to)",
        "type": "Title"
    },
    {
        "element_id": "ab86432f-7577-4da9-8c3c-02c5ac4580e4",
        "metadata": {},
        "text": "If(to - from) < 5km If(to \u2014 from) < 200km",
        "type": "NarrativeText"
    },
    {
        "element_id": "e6746495-cda8-44d2-a4e9-864099c00cc0",
        "metadata": {},
        "text": "Figure 3: HTN Method 2",
        "type": "Title"
    },
    {
        "element_id": "fc3e09b7-3504-4d7a-9d3c-6ccb85116bd7",
        "metadata": {},
        "text": "An STN planning domain is a set of operations O and a set of methods M. A STN planning problem is a 4-tuple of the initial state So, the task network w called initial task network and the STN domain. A plan 7 = (aj,...,@,) is a solution for a planning problem if there is a way to decompose w into 7 if m is executable and each decomposition is applicable in the appropriate state of the world. The algorithm that is capable to decompose these networks into plans is called Total-forward-decomposition (TFD) [9] or Partial-forward-decomposition (PFD). However there are cases where one does not want to use a forward-decomposition procedure. HTN planning is generalization of STN planning that gives the planning procedure more freedom about how to construct the task networks.",
        "type": "NarrativeText"
    },
    {
        "element_id": "4e70b662-e7e1-46e0-aa80-9cdd90fbe4cd",
        "metadata": {},
        "text": "In order to provide this freedom, a bookkeeping mechanism is needed to represent constraints that the planning algorithm has not yet enforced. The bookkeeping is done by representing the unenforced constraints explicitly in the task network.",
        "type": "NarrativeText"
    },
    {
        "element_id": "2b75547a-7c80-4000-9a21-d2a4926eb85c",
        "metadata": {},
        "text": "The HTN generalizes the definition of a task network in STN. A task network is the pair w = (U,C) where U is a set of task nodes and C is a set of constraints. Each constraint in C specifies a requirement that must be satisfied by every plan that is a solution to a planning problem.",
        "type": "NarrativeText"
    },
    {
        "element_id": "00068a75-7719-492c-a1b0-c0edf2d90180",
        "metadata": {},
        "text": "The definition of a method in HTN also generalizes the definition used in STN planning. A HTN plan is a 4-tuple of name, task, subtasks, and constraints. The subtasks and the constraints form the task network. The HTN planning domains are identical to STN planning domains except they use HTN methods instead of STN methods.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a4b2da99-78dd-468d-ab0d-42af35d4aeea",
        "metadata": {},
        "text": "Compared to classical planners the primary advantage of HTN planners is their sophisticated knowledge representation and reasoning capabilities. They can represent and solve a variety of non-classical planning problems; with a good set of HTNs to guide them, they can solve classical planning problems orders of magnitude more quickly than classical or neoclassical planners. The primary disadvantage of HTN is the need of the domain author to write not only a set of planning operators but also a set of methods.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0e61d950-cc1d-4b65-90ae-2600f7cf20a8",
        "metadata": {},
        "text": "3.2.2. HTN Planning in building Game Trees",
        "type": "Title"
    },
    {
        "element_id": "d430f21b-e040-4964-bda1-9a3aad2c7166",
        "metadata": {},
        "text": "For a HTN planning algorithm to be adapted to build game trees we need to define the domain (set of HTN methods and operators) which is the domain of the game. This is in some sense a knowledge representation of the rules of the game, the game environments and possible strategies of game play.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f506ea21-a249-42e4-a2c1-aba86e128182",
        "metadata": {},
        "text": "In this domain the game rules as well as known strategies to tackle specific task are defined. The implementation of Game Tree building with HTN is called Tignum2 [9]. This implementation uses a _ procedure similar to forward- decomposition, but adapted to build up a game tree rather than a",
        "type": "NarrativeText"
    },
    {
        "element_id": "41bdfc35-c392-4367-bff9-a5002fd37eb2",
        "metadata": {},
        "text": "plan. The branches of the game tree represent moves generated by the methods. Tignum2 applies all methods applicable to a given state of the world to produce new states of the world and continues recursively until there are no applicable methods that have not already been applied to the appropriate state of the world.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0cd7a262-3ff8-421a-8fa4-eaadd15c17c2",
        "metadata": {},
        "text": "In the task network generated by Tignum2, the order in which the actions will occur is determined by the total-ordering constraints. By listing the actions in the order they will occur, the task network can be \u201cserialized\u201d into a game tree [Figure 4] [Figure 5].",
        "type": "NarrativeText"
    },
    {
        "element_id": "3d6a79ce-3f78-437b-ba9c-59053d7f227d",
        "metadata": {},
        "text": "Play",
        "type": "Title"
    },
    {
        "element_id": "c2d5c778-f5a7-41af-81fb-d0d2ac741844",
        "metadata": {},
        "text": "= = S",
        "type": "UncategorizedText"
    },
    {
        "element_id": "018a2d9e-15bb-47dd-a0f2-70f443b54082",
        "metadata": {},
        "text": "[scion st | action $12 | action 821 action 822] | action s23",
        "type": "UncategorizedText"
    },
    {
        "element_id": "402546b9-b8ca-4522-8e8a-6f9598206418",
        "metadata": {},
        "text": "\u00a5 Opponent Strategy 221 |",
        "type": "Title"
    },
    {
        "element_id": "1f96160c-0c2c-4862-a00d-1df9e1e14fdc",
        "metadata": {},
        "text": "Opponent Strategy 11",
        "type": "Title"
    },
    {
        "element_id": "07a510f3-b7d2-4c0b-b612-3cd1407cfc8a",
        "metadata": {},
        "text": "action ott",
        "type": "Title"
    },
    {
        "element_id": "925fb724-a288-441e-8180-25e84d450372",
        "metadata": {},
        "text": "Figure 5: Game Tree built from HTN",
        "type": "Title"
    },
    {
        "element_id": "df60ac5f-54c2-47c7-9c3d-5a147fb10c5c",
        "metadata": {},
        "text": "4. Case Based Reasoning in Game Strategies",
        "type": "ListItem"
    },
    {
        "element_id": "85e86f62-f152-495d-9330-50dd6062ccfe",
        "metadata": {},
        "text": "4.1 Case Based Reasoning",
        "type": "Title"
    },
    {
        "element_id": "48632a79-c1e1-4e96-8d4a-ebd8a829a960",
        "metadata": {},
        "text": "Case-based reasoning (CBR) is a well established subfield of Artificial Intelligence (AI), both as a mean for addressing AI problems and as a basis for standalone AI technology.",
        "type": "NarrativeText"
    },
    {
        "element_id": "b9057f4d-526d-4ad6-a4f7-d976352178ed",
        "metadata": {},
        "text": "Case-based reasoning is a paradigm for combining problem- solving and learning that has became one of the most successful applied subfield of AI of recent years. CBR is based on the intuition that problems tend to recur. It means that new problems are often similar to previously encountered problems and, therefore, that past solutions may be of use in the current situation [10].",
        "type": "NarrativeText"
    },
    {
        "element_id": "8b83eb3b-f2b4-4773-8614-ee6d18d6f98f",
        "metadata": {},
        "text": "CBR is particularly applicable to problems where earlier cases are available, even when the domain is not understood well enough for a deep domain model. Helpdesks, diagnosis or cla i systems have been the most successful areas of application, e.g., to determine a fault or diagnostic an illness from observed attributes, or to determine whether or not a certain treatment or repair is necessary given a set of past solved cases [11].",
        "type": "NarrativeText"
    },
    {
        "element_id": "50f08572-38c9-4074-97de-6597e99ed118",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "d9e2930d-b69d-4ece-ac50-77e19c024a9b",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "21359686-7d04-452e-93c5-aa09a26342e1",
        "metadata": {},
        "text": "298 DIMEA 2008",
        "type": "UncategorizedText"
    },
    {
        "element_id": "638ee793-2247-4c6f-8fa0-425d70fc848f",
        "metadata": {},
        "text": "Central tasks that all CBR methods have to deal with are [12]: \"to identify the current problem situation, find a past case similar to the new one, use that case to suggest a solution to the current problem, evaluate the proposed solution, and update the system by learning from this experience. How this is done, what part of the process that is focused, what type of problems that drives the methods, etc. varies considerably, however\".",
        "type": "NarrativeText"
    },
    {
        "element_id": "27692a62-81c5-4a2a-affa-f5c2e315f2fd",
        "metadata": {},
        "text": "While the underlying ideas of CBR can be applied consistently across application domains, the specific implementation of the CBR methods \u2014in particular retrieval and similarity functions\u2014 is highly customized to the application at hand.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3f41665a-edcc-4302-94c2-4fa57e3ed78b",
        "metadata": {},
        "text": "4.2 CBR and Games",
        "type": "Title"
    },
    {
        "element_id": "436bf400-c8ed-4d97-8e09-0be290f75e26",
        "metadata": {},
        "text": "Many different implementations of CBR exist in games. CBR technology is nicely suited for recognizing complex situations much easier and more elegant than traditional parameter comparison or function evaluation. There are especially evident cases in real time strategies where different attack and defense of global strategies are nicely defined by CBR datasets and later used in the running games. Also intelligent bots behavior is also another typical example. Depending on the number of enemy bots the layout of the terrain and position of human players the CBR system finds the closest CBR case and employs that strategy against the human players which in prior evaluation was proved to be highly efficient.",
        "type": "NarrativeText"
    },
    {
        "element_id": "05134054-2672-4b20-9919-5ec129db2cd2",
        "metadata": {},
        "text": "5. Game Trees with AI Planning \u2014 Tic-tac-toe",
        "type": "ListItem"
    },
    {
        "element_id": "360542ea-b2fb-4ba9-af0f-0f61520ba663",
        "metadata": {},
        "text": "In order to show the expressive power of AI Planning in defining strategies for games, and the use of these plans to build Game Trees I implemented an algorithm that builds Game Trees for the Tic-Tac-Toe game.",
        "type": "NarrativeText"
    },
    {
        "element_id": "086fc049-9fbd-4d4f-a3e2-4eb5ff4077e0",
        "metadata": {},
        "text": "The game tree of Tic-Tac-Toe shows 255,168 possible games of which 131,184 are won by X (the first player), 77904 are won by O and the rest 46,080 are draw [13]. All these games can be derived from building a complete Game Tree.",
        "type": "NarrativeText"
    },
    {
        "element_id": "201073b1-98c4-4fec-9d31-5d4f1621c0c4",
        "metadata": {},
        "text": "Even though it is possible to build a complete game tree of Tic-tac-toe it is definitely not an optimal solution. Many of the moves in this tree would be symmetrical and also there are a many moves that would be illogical or at least a bad strategy to even consider.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3da13427-68d8-44ca-9759-2fa147403c85",
        "metadata": {},
        "text": "So what strategy should X (the first player) choose in order to win the game?",
        "type": "NarrativeText"
    },
    {
        "element_id": "4c0bb89b-5a11-490e-b32c-8c3708a71a8d",
        "metadata": {},
        "text": "There are few positions that lead to certain victory. These positions involve simultaneous attack on two positions so the other player could not defend, basically the only trick in Tic-Tac- Toe.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c6ab369d-90b3-4823-ae6c-06f24cdcb2d1",
        "metadata": {},
        "text": "x| |x x |x| x| | x [x] |X] | | | | | | | x",
        "type": "UncategorizedText"
    },
    {
        "element_id": "011f838a-daf0-472e-a05e-e08bd1735d2f",
        "metadata": {},
        "text": "Figure 6: Tic-tac-toe winning strategy positions Position | leads to victory if the two of the three fields: top middle, bottom left corner and bottom right corner are free [Figure 6].",
        "type": "NarrativeText"
    },
    {
        "element_id": "cf4be35a-b98f-4e2f-9fc8-5868cc944a27",
        "metadata": {},
        "text": "Position 2 lead to victory if two of the three fields: top right comer, bottom right corner and bottom middle are free [Figure ].",
        "type": "NarrativeText"
    },
    {
        "element_id": "01138d2a-60a1-4643-a0cb-5ecdba28eaf0",
        "metadata": {},
        "text": "And in the third position if the two of center, middle top and middle left are available the position is a certain victory.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5af8c412-cba2-4879-b608-e74c4471f8a5",
        "metadata": {},
        "text": "There are many different arrangements of the player\u2019s tokens that give equivalent positions as these three positions. By using planning we do not need to consider all possible layouts but just consider these three similar to what a human would consider.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d41df988-6891-49aa-a118-2d262d0d6414",
        "metadata": {},
        "text": "The game starts from an empty table.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6055cc47-5446-4a3f-9e6b-941ac49fee1e",
        "metadata": {},
        "text": "The two relevant strategies that would lead to these positions are to take one corner or to take the center [Figure 7].",
        "type": "NarrativeText"
    },
    {
        "element_id": "369e65df-f5ef-484c-976c-4134c59626b2",
        "metadata": {},
        "text": "Figure 7: Tic-tac-toe Two starting moves",
        "type": "NarrativeText"
    },
    {
        "element_id": "834ebf3c-e2b9-449c-b0a5-154adaa61e81",
        "metadata": {},
        "text": "The center position as we can see in the simulation results lead to a bigger number of victorious endings but it is also a straight forward strategy with obvious defense strategy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d15caed8-d366-40c5-8ca3-07b25ce03e0c",
        "metadata": {},
        "text": "At this point we need to consider the moves of the opponent. If we take the left branch the opponent moves can be a center, a comer or a middle field. We also need to differentiate with a move to a corner adjacent with our like top left or bottom right or across the center to bottom right [Figure 8].",
        "type": "NarrativeText"
    },
    {
        "element_id": "8080a073-f7f7-4d92-8d0e-aa56d1b52cd2",
        "metadata": {},
        "text": "x|_|O x|_| x | | ID",
        "type": "UncategorizedText"
    },
    {
        "element_id": "88de9de4-7633-41f6-96de-80a24206f882",
        "metadata": {},
        "text": "Figure 8: Tic-tac-toe opponent response to corner move",
        "type": "NarrativeText"
    },
    {
        "element_id": "9958f48d-59bd-49d5-af0b-98453e530b52",
        "metadata": {},
        "text": "|_| | | |O",
        "type": "UncategorizedText"
    },
    {
        "element_id": "496c4419-dacd-4652-bca9-2c3180550822",
        "metadata": {},
        "text": "In cases one and two, we have a clear path to executing strategy 3 so we need to capture the diagonally opposite field. And as for the third case the best way to go is to capture the center and go for strategy 1 or 2 depending of the opponent\u2019s next move.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e78c0a7f-c52d-4e56-a732-98962376386d",
        "metadata": {},
        "text": "x O x X x x Se) Figure 9: Tic-tac-toe move 2 after corner opening",
        "type": "UncategorizedText"
    },
    {
        "element_id": "8008ee35-8a5e-44e9-a0db-3bcf7be5ca4c",
        "metadata": {},
        "text": "The first move leads to certain victory, O will have to go to the center and X will achieve strategy 3 [Figure 9]. The second move is a possible way to strategy 3 if O makes a mistake in the next loop, so X goes to the opposite corner. For the third case since O is playing a valid strategy the only move that leaves a possible mistake from O would be to take the center and wait for O to go to the middle and then achieve strategy 1 or 3 which will be a symmetric situation to the one that we will find if we branched with the center.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5ee0fe02-0e31-4616-8d3d-da6c2baae415",
        "metadata": {},
        "text": "oe) Xx Xx",
        "type": "Title"
    },
    {
        "element_id": "15098d49-3a1f-4e03-8302-fe80611664e6",
        "metadata": {},
        "text": "| JO |",
        "type": "UncategorizedText"
    },
    {
        "element_id": "60d5a457-1685-4afb-b901-7cf959946abd",
        "metadata": {},
        "text": "Figure 10: Tic-tac-toe opponent response to center move",
        "type": "NarrativeText"
    },
    {
        "element_id": "3ca566e9-9070-4d67-a4dc-204be4ccac20",
        "metadata": {},
        "text": "If we go back to the second branch [Figure 10], a possible way for the second player to engage is corner or middle. The first",
        "type": "NarrativeText"
    },
    {
        "element_id": "f20bf35c-da4b-4bb2-810c-37e51dd87d4a",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "5475d9cd-8382-4c1b-ab7d-59a84cf60a1d",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "7d7495c5-d747-435a-8aee-cf04e5defcd3",
        "metadata": {},
        "text": "Interactive and Adaptable Media 299",
        "type": "Title"
    },
    {
        "element_id": "d0fc4f93-8d0e-4958-8e43-adaa76f81cfe",
        "metadata": {},
        "text": "move is a valid strategy for O and can be meet with a opposite corner move from X to try a mistake from O in the future exactly the same as in the third case above from the previous branch, and another move would be go to the middle where X eventually achieves strategy | or 2.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e6217be8-9b2c-413e-b862-092a0b6c8447",
        "metadata": {},
        "text": "x |_| x |O} x x oO",
        "type": "Title"
    },
    {
        "element_id": "b6d395d6-bb27-485e-8871-a2a20c5626de",
        "metadata": {},
        "text": "Figure 11: Tic-tac-toe Move 2 after center opening",
        "type": "Title"
    },
    {
        "element_id": "cbbdb458-1175-48ea-83d4-d7de1ec1600e",
        "metadata": {},
        "text": "The fist move will lead to win if O moves to the middle or a draw if it goes for the corners [Figure 11]. In the second case O has to block the lower left corner which leaves X to go for the middle left or corner left which are strategy 1 and 2.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c6b90101-5740-42de-9c0e-18ee2d80419d",
        "metadata": {},
        "text": "To sum the strategies for the planning, first we have center or comer strategy for the beginning. Then for the center we try to get the corners with the particularly the one opposite to the one O holds. If the center is empty for the second strategy we go for it or we go for the opposite corner. After this point we either block the opponent or try to implement strategies 1, 2 or 3 which lead to victory.",
        "type": "NarrativeText"
    },
    {
        "element_id": "651fd05f-daf3-4b1b-9c8b-b961fa420cff",
        "metadata": {},
        "text": "Plan 1: Take center",
        "type": "Title"
    },
    {
        "element_id": "ca57f51e-e5da-4fa6-bc9f-887c2c9122fa",
        "metadata": {},
        "text": "Preconditions: Center empty",
        "type": "Title"
    },
    {
        "element_id": "b89d41d3-9001-4c1a-a8e9-e46a987d9a7d",
        "metadata": {},
        "text": "Plan 2: Take corner",
        "type": "Title"
    },
    {
        "element_id": "1385b992-54db-45b2-82dd-514802256022",
        "metadata": {},
        "text": "Preconditions: All corners empty",
        "type": "NarrativeText"
    },
    {
        "element_id": "d83fecf4-674a-4902-8e40-a920025a83e0",
        "metadata": {},
        "text": "Plan 3: Take corner after center",
        "type": "NarrativeText"
    },
    {
        "element_id": "ad364988-1192-434c-82e8-2bf53552e0ea",
        "metadata": {},
        "text": "Preconditions: We have center take corner opposite to the one the opponent has",
        "type": "NarrativeText"
    },
    {
        "element_id": "d3954710-0e5e-44fb-bb65-512a1c517905",
        "metadata": {},
        "text": "Plan 4: Take diagonal corner",
        "type": "NarrativeText"
    },
    {
        "element_id": "2b6eadd5-0c34-4288-9e4c-ab7960c748ce",
        "metadata": {},
        "text": "Preconditions: We have a corner, the opponent has the ce-nter and the corner opposite to the one we have is free.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7a52298c-9253-48f3-a4fc-ae6f597af923",
        "metadata": {},
        "text": "Plan 5: Block",
        "type": "Title"
    },
    {
        "element_id": "9f439cda-21a0-4a10-80f9-41ce33936f4f",
        "metadata": {},
        "text": "Precondition: The opponent has tree tokens in a row, colu-mn or di agonal",
        "type": "NarrativeText"
    },
    {
        "element_id": "c059d5b0-095e-4a3d-bc0f-af57f112a2c0",
        "metadata": {},
        "text": "Plan 6: Win",
        "type": "Title"
    },
    {
        "element_id": "4841d712-3f1e-4652-907b-f38a57237f1c",
        "metadata": {},
        "text": "Preconditions: We have two tokens in a row, column or dia-gonal a nd the third place is free",
        "type": "NarrativeText"
    },
    {
        "element_id": "03bb5333-11ba-4a2b-94ed-87449a14a939",
        "metadata": {},
        "text": "Plan 7: Tie",
        "type": "Title"
    },
    {
        "element_id": "07301dfb-c52a-424e-9e27-7c4a8dc125b7",
        "metadata": {},
        "text": "Preconditions: lf all places are taken, it's a tie.",
        "type": "NarrativeText"
    },
    {
        "element_id": "0e6fbbd6-f4fe-41e0-969f-9ef38ae9c2ea",
        "metadata": {},
        "text": "5.1 Hierarchical Task Network",
        "type": "Title"
    },
    {
        "element_id": "8cf4d32a-8316-44ed-8d1f-0232723ee7bd",
        "metadata": {},
        "text": "Top level task is Play [Figure 12]. This is a complex task and can be derived into: Win, Block, Tie or Search for Plan. The Search for plan is derived to both Plan | and Plan 2 or Plan 3 and Plan 4, which later leads to a call for the opponent\u2019s move and a recursive call to Play.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7a3d0982-f19d-4ce2-8bc1-af347ceca537",
        "metadata": {},
        "text": "Take comer after center",
        "type": "NarrativeText"
    },
    {
        "element_id": "74d0e581-5966-4e4d-8578-c91508cc5727",
        "metadata": {},
        "text": "Take diagonal comer Play cpponent",
        "type": "Title"
    },
    {
        "element_id": "1059714a-224e-4562-a23c-73f51483620d",
        "metadata": {},
        "text": "Figure 12: Tic-tac-toe HTN",
        "type": "Title"
    },
    {
        "element_id": "135a0412-5bd6-4bd2-bfe6-c5ecd11c1cb8",
        "metadata": {},
        "text": "This HTN when executed will result with plans for possible game scenarios. By creating nodes from each position and linking them with branches with the move of the player we create a game tree for the Tic-tac-toe game over which we can run the minimax algorithm.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ba33b747-5f2d-43fd-a3a5-885d1b6e62ff",
        "metadata": {},
        "text": "This set up with 7 plans with 3 target strategies creates a tree for Tic-tac-toe which considers all possible moves for the second player with only 457 games, 281 of which X wins 176 are draw and 0 where the second opponent wins. This is a significant reduction over the 255, 168 possible games with a complete game tree. These reductions can be very useful for devices with limited computing capabilities but also we prove a very important point that planning can be very efficient if designing meaningful game trees by applying reasoning very similar to human player reasoning.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e43bda30-1c5e-4818-9cb9-4118d810bcba",
        "metadata": {},
        "text": "Further improvements to the game tree are also possible if the opponents moves are also planned, in other words if we drop all the meaningless and symmetrical moves of the opponent.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7b139803-a24f-415b-be56-596582762475",
        "metadata": {},
        "text": "6. Game AI in Monopoly",
        "type": "ListItem"
    },
    {
        "element_id": "4c55ed00-938e-4162-b5d9-f8d89bfcc2bc",
        "metadata": {},
        "text": "6.1 Overview of the AI Implementation",
        "type": "Title"
    },
    {
        "element_id": "e97f67e5-98f5-41b8-b65a-a0618b1bc374",
        "metadata": {},
        "text": "The AI agent is responsible for the moves of the artificial players in the game. The core principle of the AI agent is building a Game Tree with all the sensible moves that all the players would make from the current point of time forward. Then using the minimax algorithm the agent selects the move that in the future would bring the computer player most favorable game position with the highest probability. Building a Game Tree in this game that would be big enough to consider sufficient number of moves is obstructed by the vastness of possible moves in combination with all the possible random landings of the dice. The number of nodes of the game tree exponentially grows at each level. To tackle this problem the AI agents incorporates two already iscussed technologies: Case Based Reasoning and AI Planning.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c92a2c44-9f05-442d-9174-e114b6aa56ba",
        "metadata": {},
        "text": "The technologies are employed in the following manner. First the agent searches the CBR database to find the case with the argest similarity with the current state of the board. This case is associated with a playing strategy. The strategy consists of goal that the planner needs to build plans for, and the plans consist of consecutive player moves that bring the player to that goal. This way only moves that are part of that strategy are considered, those eing a small fraction of the overall possible moves the number of edges of the game tree at each level decreases immensely. At each level of the game tree the model considers the moves of a single player. After the strategies of the AI player are considered the response to those strategies needs to be considered y the opponent(s). The move of the opponent(s) depends of the robability distribution of the dice as well as the strategy of the layer. A more general strategy needs to be implemented for the opponent\u2019s (human player) moves since we cannot be aware of the expertise of the opponent. This general strategy would bring more plausible moves than the focused strategy of the AI player.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f0408b9b-5d95-4a58-b78b-5e69ef0bc4e7",
        "metadata": {},
        "text": "After covering all opponents the agent comes back to deducting a feature move of the computer player by using the CBR selected plan strategy. After creating several loops of strategies and reaching a reasonable size of a Game Tree taking into account the memory limits and the rapidly decreasing probabilities that the move is possible due to the distribution of the dice the building of the Game Tree stops. Then the minimax algorithm searches the Game Tree and decides on the most favorable move for the AI player using the minimax algorithm. The process is repeated each time the AI player is up.",
        "type": "NarrativeText"
    },
    {
        "element_id": "05a517d4-d812-4028-91c2-fc0d480060a3",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "7744e120-984b-4d98-b528-b0e2dc409f89",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "59a5df9f-6131-466e-a7af-e389021a6cb4",
        "metadata": {},
        "text": "300 DIMEA 2008",
        "type": "UncategorizedText"
    },
    {
        "element_id": "e5c43ddd-5892-479b-9b88-ca71bc45143c",
        "metadata": {},
        "text": "Buying, auctioning and trading game moves are always accompanied by return of investment calculations in making the plans. These calculations represent adaptation of the more general planning associated with the cases in the CBR database. These adaptations are necessary due to the fact that the cases do not identically correspond to the situation on the table. In addition calculating the game position value of each node of the game tree is done by heuristic functions that incorporate economic calculations of net present value, cash, and strategic layout and so on. For example railroads in monopoly are known to be strategically effective because they bring constant income even though the income can be smaller than building on other properties.",
        "type": "NarrativeText"
    },
    {
        "element_id": "998842cf-8f62-4b69-b1be-29b47c5d8eb9",
        "metadata": {},
        "text": "6.2 Details on the CBR Implementation",
        "type": "Title"
    },
    {
        "element_id": "8dd0daee-da7f-4643-93ea-acb305f9c593",
        "metadata": {},
        "text": "The implementation of the CBR is by using the JColibri2 platform. JColibri2 is an object-oriented framework in Java for building CBR systems that is an evolution of previous work on knowledge intensive CBR [14].",
        "type": "NarrativeText"
    },
    {
        "element_id": "f79541ca-95f2-4b17-86b1-fdf8a097a66f",
        "metadata": {},
        "text": "For this implementation we need to look into three particular classes of the JColibri2 platform. The StandardCBRApplication, Connector, CBRQuery. For a JColibri2 implementation the StandardCBRApplication interface needs to be implemented.",
        "type": "NarrativeText"
    },
    {
        "element_id": "854b9886-c332-40f1-be74-2a57a97c0c06",
        "metadata": {},
        "text": "The CBR cycle executed accepts an instance of CBRQuery. This class represents a CBR query to the CBR database. The description component (instance of CaseComponent) represents the description of the case that will be looked up in the database. All cases and case solutions are implementing \u2014 the CaseComponent interface.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e8c7dbf7-f198-439f-876e-cbb94fead1a3",
        "metadata": {},
        "text": "The JColibri2 platform connects to the CBR database via a Connector class. Each connector implements all the necessary methods for accessing the database, retrieval of cases, storing and deletion of cases. This implementation uses a custom XML structure for holding the CBR cases. Since the game will not update the CBR database only read it, a XML solution satisfies the needs. The XML file to a certain extent is similar to the XML representation of the board. We are interested in finding one CBRCase that is the most similar case to the situation in the game at the time of the search. This procedure is done in the cycle method of the CBRApplication. The JColibri2 CBR comparison is done by Nearest Neighbor (NN) search method.",
        "type": "NarrativeText"
    },
    {
        "element_id": "394226af-306d-47e1-a4b1-fd72d624473e",
        "metadata": {},
        "text": "JColibri2 offers implementations for NN search algorithms of simple attributes. These implementations are called local similarities. For complex attributes like in our case global customized similarity mechanisms need to be implemented.",
        "type": "NarrativeText"
    },
    {
        "element_id": "8621c2e3-e775-4dd8-87ab-45b020a18f57",
        "metadata": {},
        "text": "The MonopolyDescription class [Figure 13] is basically a serialization of the GameState. It holds all the information about the state of the board, the players, their amount of cash etc.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ac2a1e55-edba-493a-9913-faa39b89259d",
        "metadata": {},
        "text": "\u00abinterfaces \u00a9 CaseComponent jcolibri.cbrcore",
        "type": "NarrativeText"
    },
    {
        "element_id": "bcb9b3d4-1e4b-4d47-b86b-920f269276b5",
        "metadata": {},
        "text": "\u00a9 getidattributed)",
        "type": "NarrativeText"
    },
    {
        "element_id": "79ebe984-f59e-48c0-986f-1425c60c5b25",
        "metadata": {},
        "text": "A if | simplement\u00bb __|_<implement\u00bb",
        "type": "Title"
    },
    {
        "element_id": "5fdbd9c6-20cf-4215-aa9c-7f7f14d8a3e5",
        "metadata": {},
        "text": "\u2018G MonopolySolution \u00ae MonopolyDescription 2 id String {4p board: Board 4 it String @ =getidAttributed) \u00a9 setDomain() \u00a9 getldattributed) @ setState() @ setBoard() \u00a9 setTaskListo)",
        "type": "NarrativeText"
    },
    {
        "element_id": "d2ad8fb0-eaa9-4c0f-bd08-ffed7ca6566c",
        "metadata": {},
        "text": "Figure 13: Class diagram of the Monopoly Case component models",
        "type": "Title"
    },
    {
        "element_id": "48efafdb-bd43-4984-b190-11633077cd55",
        "metadata": {},
        "text": "On the other hand the MonopolySolution class holds the three particular attributes that are needed for the planning, the planning Domain, State and TaskList.",
        "type": "NarrativeText"
    },
    {
        "element_id": "e611457f-0a6f-421a-a013-30bda6490eaa",
        "metadata": {},
        "text": "The game is implemented by using the Model-View- Controller software development pattern. The controller is responsible for implementing the game rules and handling all of the events in the game like roll of dice, input commands for trading, auctioning and etc from the players. The View layer is responsible for displaying the board and all of the input widgets on to the game screen, and the models are data structures representing the game state [Figure 14].",
        "type": "NarrativeText"
    },
    {
        "element_id": "14399200-4a8c-417d-aa17-56d441c2a87f",
        "metadata": {},
        "text": "\u00a9 GameModel",
        "type": "Title"
    },
    {
        "element_id": "03fbd157-d396-4959-823f-ec2ede236a48",
        "metadata": {},
        "text": "4 board: Board 4 currentPlayer: Player",
        "type": "Title"
    },
    {
        "element_id": "430b48ed-d458-407c-b3ec-f18099874f5e",
        "metadata": {},
        "text": "\u00a9 Board \u00a9 playerMove: PlayerMove 4 players: ArrayList=Player=",
        "type": "NarrativeText"
    },
    {
        "element_id": "ae3e7ca4-688e-4e86-9b1b-dc8f19eaaf84",
        "metadata": {},
        "text": "\u00a9 Field 9, name: String \u00a9, type: String \u00a9 orientation: String",
        "type": "Title"
    },
    {
        "element_id": "3c6f8350-e508-48f2-8228-3d58c38be6c7",
        "metadata": {},
        "text": "4 fields: ArrayListeField>",
        "type": "Title"
    },
    {
        "element_id": "4deb3fbf-b2e3-42ba-9468-f785bc6b7636",
        "metadata": {},
        "text": "& Gamentodel) \u00a9 addPlayer() \u00a9 getBoard()",
        "type": "NarrativeText"
    },
    {
        "element_id": "42d8dd56-76cd-461f-968e-46e7cbae6d5c",
        "metadata": {},
        "text": "\u00a9 getPlayerMoves() \u00a9 getPlayers() \u00b0 \u00b0",
        "type": "NarrativeText"
    },
    {
        "element_id": "ea56c504-f778-402d-a7c6-c8c0a611e6c6",
        "metadata": {},
        "text": "\u00a9 addFielag, \u00a9 getAlFields\u00a2,",
        "type": "UncategorizedText"
    },
    {
        "element_id": "1a9a57dd-3638-4c99-9b8a-5be321a35a81",
        "metadata": {},
        "text": "& Field, \u00a9 getOriertation() \u00a9 setOrientation()",
        "type": "NarrativeText"
    },
    {
        "element_id": "fa003367-ae2a-49e9-a9f7-8294481dbe58",
        "metadata": {},
        "text": "nextMove() setintalSteteg)",
        "type": "Title"
    },
    {
        "element_id": "3cc03005-e183-4389-9b58-a6c3709f8db0",
        "metadata": {},
        "text": "\u00a9 Contract @Tax \u00a9 Chance \u00a9 CommunityChest",
        "type": "Title"
    },
    {
        "element_id": "d7ae26a4-6ebd-4839-a839-dc5c4a95909f",
        "metadata": {},
        "text": "6, mortage: int 0, tax int \u00a9 owner: Player 4, value: int",
        "type": "Title"
    },
    {
        "element_id": "586c596a-d77b-4596-b65c-1a8b3f8b398a",
        "metadata": {},
        "text": "& chanced & Communtychest()",
        "type": "NarrativeText"
    },
    {
        "element_id": "c4787ce0-95ab-45d6-a31d-78b760c8db1b",
        "metadata": {},
        "text": "& Tax)",
        "type": "Title"
    },
    {
        "element_id": "04584397-ff7d-462d-b996-1b1895c355a0",
        "metadata": {},
        "text": "& Contract) \u00a9 getOwnerd @ setOwner()",
        "type": "NarrativeText"
    },
    {
        "element_id": "fcc05ba8-f636-4f9e-b766-1d72a298522e",
        "metadata": {},
        "text": "@ Land \u00a9 RailRoad",
        "type": "Title"
    },
    {
        "element_id": "3805afea-eb6f-4ddd-a13e-78e6274f674a",
        "metadata": {},
        "text": "\u00a9 buildings: String 4 incomet: int 4, bulldpriced: int \u20186 income2: int 4, bulldpricet: int 4, income int 4, incomet: int 4, income? int 4, incomes: int +, incomed: int 4, incomes: int",
        "type": "NarrativeText"
    },
    {
        "element_id": "753132d7-9ad0-4de2-adf2-9764a6d5454b",
        "metadata": {},
        "text": "\u00a9 Utilities",
        "type": "Title"
    },
    {
        "element_id": "27b2c211-025c-489b-9eda-bd55156239d0",
        "metadata": {},
        "text": "4 incomet: int",
        "type": "Title"
    },
    {
        "element_id": "5d5a30dd-ba71-4f02-b0a5-1203995883a1",
        "metadata": {},
        "text": "4 income2: int 6 incomes: int",
        "type": "Title"
    },
    {
        "element_id": "11d57dae-50fb-4376-9dd6-9904d9c6162d",
        "metadata": {},
        "text": "6 incomes: int \u20ac unitieso",
        "type": "Title"
    },
    {
        "element_id": "7791e088-fcc7-4888-b15b-bf26c7f39d71",
        "metadata": {},
        "text": "& RaiRoady)",
        "type": "Title"
    },
    {
        "element_id": "ea71bfff-731a-4226-a699-860a350d5dc4",
        "metadata": {},
        "text": "& Lande) \u00a9 getBuikings() \u00a9 setBuikings()",
        "type": "NarrativeText"
    },
    {
        "element_id": "9f027500-02cf-48db-bec1-e391f9e91353",
        "metadata": {},
        "text": "Figure 14: Class diagram of the Monopoly models",
        "type": "Title"
    },
    {
        "element_id": "65f68833-fd18-433b-985e-0030b6e782cb",
        "metadata": {},
        "text": "6.2.1 Complex Similarity representation in CBR",
        "type": "Title"
    },
    {
        "element_id": "65aee6b8-3ad0-4a78-9953-0e45ec19f439",
        "metadata": {},
        "text": "The similarity measurement part of the Nearest Neighbor algorithm JColibri2 is implemented by implementing the LocalSimiralrityFunction and the GlobalSimiralityFunction interface. A local similarity function is applied to simple attributes by the NN algorithm, and a global similarity function is applied to compound attributes. In the case of our implementation the attributes of the MonopolyDescription are compound attributes describing the state of the board, number of players, amount of cash for every player and etc. Since MonopolyDescription is a custom CaseComponent a global similarity function needs to be implemented to accurately find the distance between different CBR cases.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ea8752d9-3367-4ec8-82a2-537e4d8d0ac3",
        "metadata": {},
        "text": "The similarity mechanism is inseparable core element of the CBR system. This mechanism represents how the CBR decides which strategy is best suited for the particular situation by",
        "type": "NarrativeText"
    },
    {
        "element_id": "c8e41b9e-4e4e-4d22-8237-f986c07b3b4f",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "9ee16495-141b-4fc3-b8a9-87813eff4098",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "497dc5ca-d51f-45a4-8d6f-7884a493a4d3",
        "metadata": {},
        "text": "Interactive and Adaptable Media 301",
        "type": "Title"
    },
    {
        "element_id": "9111f565-5cf3-47e0-bbe9-e8ed4db71a98",
        "metadata": {},
        "text": "calculating the distance or similarity to other cases in the database.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f8a2dcf2-7b2e-45d7-a5b8-25d1e8e7ed35",
        "metadata": {},
        "text": "For the monopoly implementation we need to consider several basic strategies. Monopoly is based on investing in properties and receiving revenues from those investments. One of the basic strategies of the game is to build a set of properties that will bring constant income larger than the one of the opponents. So in time the opponents will have to declare bankruptcy. But on the other hand over investment can lead to too stretched resources with low income that will eventually drove the player to bankruptcy. To decide on these two we need a clear separation into two groups of cases in the CBR database. The first group of cases will represent a situation on the board where the player has significant income per loop formed of one or more color group properties, maybe railroads, some buildings on them and so on. It is important to note that in this case the player is better situated than his opponents so he only needs to survive long enough to win the game. In the other group of cases either the opponent is not well positioned on the board or its opponents are better situated. In this case further investments are necessary to improve the situation so the player can have a chance of winning in the long run.",
        "type": "NarrativeText"
    },
    {
        "element_id": "57af835e-aa24-49b1-bf8a-105883a77f26",
        "metadata": {},
        "text": "[hese metrics can be owning color groups, valuing groups of railroads, evaluating the other opponents as well, and considering the amount of cash. As it is obvious in monopoly the number of streets is not as nearly as important as the combination of streets the player owns. It is also important to note that one CBR case does not hold only a single strategy in place, but its solution can have multiple different strategic goals. For example one CBR case might simultaneously say buy this land to form a color group but also trade some other unimportant property to increase cash amount.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3e480709-8a2d-4b48-8a0c-f76015346789",
        "metadata": {},
        "text": "The cases do not represent all possible combinations of board positions. They are only representation of typical game scenarios. The CBR Case solutions do not give exact instructions in general but rather strategic goals. For example one CBR Solution might say trade the streets that you only have one of each for the ones that you have two of that color already. Then the planner based on the situation on the board needs to decompose this high level task to a low level operations. Like offer \"Mediterranean Avenue\" for \"Reading Railroad\" and offer $50. The exact amounts and actual streets are left to the planer to evaluate.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5866063d-76cd-4f74-9d29-cf11beb6596a",
        "metadata": {},
        "text": "The monopoly CBR database is currently in development on a monopoly clone game called Spaceopoly. The cases are architected based on human player experience and knowledge. There is a plan of making a number of slightly different strategies that differ on the style of playing and then running simulation tests that would determine the particular validity of each database as well as validity of certain segments of the strategy or even particular cases in the database.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a85f36a8-3fbb-442e-85fa-5747fd452b9f",
        "metadata": {},
        "text": "The actual execution of the strategies will not differ from strategy to strategy since the plan execution is more related to the structure and rules of the game than to the actual playing strategy.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f3ae146b-73d1-4872-813a-13a11e95cd62",
        "metadata": {},
        "text": "6.3 Details on the Planning Implementation",
        "type": "Title"
    },
    {
        "element_id": "b183ae45-5a3a-442f-93cd-2cff4bc91b3f",
        "metadata": {},
        "text": "For the purpose of planning this implementation uses a modification of the JSHOP2 planner. The Java Simple Hierarchical Ordered Planner 2 is a domain independent HTN planning system [15].",
        "type": "NarrativeText"
    },
    {
        "element_id": "36bdf17d-20ca-4af0-8e0b-f316307779f4",
        "metadata": {},
        "text": "JSHOP2 uses ordered task decomposition in reducing the HTN to list of primitive tasks which form the plans. An ordered task decomposition planner is an HTN planner that plans for tasks in the same order that they will be executed. This reduces the complexity of reasoning by removing a great deal of uncertainty about the world, which makes it easy to incorporate substantial expressive power into the planning algorithm. In addition to the usual HTN methods and operators, the planners can make use of axioms, can do mixed symbolic/numeric conditions, and can do external function calls.",
        "type": "NarrativeText"
    },
    {
        "element_id": "46a105bc-defc-4252-be8b-c858d0fdbc89",
        "metadata": {},
        "text": "In order for the JSHOP2 planer to generate plans it needs tree crucial components: Domain, State and Tasks. The Domain defines all the functionalities that the particular domain offers. These are simple and complex tasks. The complex tasks also called methods create the hierarchy with the fact that they can be evaluated by simple tasks of other complex tasks. This is how a hierarchical structure of tasks is formed. The problem reduction is done by reducing the high level complex tasks to simpler until all the tasks are primitive. The list of primitive tasks forms the plan.",
        "type": "NarrativeText"
    },
    {
        "element_id": "a463964b-3c9a-478f-a69b-5f537a7af088",
        "metadata": {},
        "text": "The State represents the state of the system. It is a simple database of facts that represent the state of the system. The State is necessary to determine the way the problems or tasks are reduced to their primitive level. The reduction is done by satisfying different prerequisites set in the methods; these prerequisites are defined in the state. The Tasks are high level tasks or methods defined in the Domain. The planner based on the State and the goals selects one or more high level tasks that need to be reduced to plans [Figure 15].",
        "type": "NarrativeText"
    },
    {
        "element_id": "21dc8455-7024-4434-a07c-b6b9529b3434",
        "metadata": {},
        "text": "\u2014\u2014\u2014>}",
        "type": "ListItem"
    },
    {
        "element_id": "e4aa5d2f-10c2-4aa0-aed0-5c541031d604",
        "metadata": {},
        "text": "State Plan |",
        "type": "Title"
    },
    {
        "element_id": "4731f7cc-1552-44a6-8aea-d111c59373b5",
        "metadata": {},
        "text": "Figure 15: Diagram of a Planner",
        "type": "Title"
    },
    {
        "element_id": "973ed544-5552-4dd1-9d10-efcd464c77e6",
        "metadata": {},
        "text": "Core Planner",
        "type": "Title"
    },
    {
        "element_id": "65261dd9-520d-47c0-ac66-2046253eb8c3",
        "metadata": {},
        "text": "The plans then generate the game moves. The number of moves generated by the plans is just a fraction of the possible moves at that point. This reduces the game tree providing the opportunity to generate smaller and deeper game trees and making more efficient decisions in general.",
        "type": "NarrativeText"
    },
    {
        "element_id": "69f99f56-7cf4-4e7c-8fe2-b2904e87f4f2",
        "metadata": {},
        "text": "7. Conclusion",
        "type": "ListItem"
    },
    {
        "element_id": "18ca2d48-f524-47d5-b80c-efa9f1ec82a2",
        "metadata": {},
        "text": "Even though the results from the CBR database are not complete at this time partial strategies are implemented as cases and recognized during game play by the CBR system. These smaller local strategies coupled with more global higher level strategies that are particularly important at the beginning of the game would form a complete CBR database and represent a knowledge engineered style of playing of the AI player.",
        "type": "NarrativeText"
    },
    {
        "element_id": "daba924d-0d28-42c0-adbb-def98cd2fe29",
        "metadata": {},
        "text": "The AI Planning approach is a proven method by the tic-tac- toe experiment and is suitable for implementing the strategies associated with the CBR cases.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1a9de5a3-4e36-44eb-b929-21e24daec12d",
        "metadata": {},
        "text": "This approach in general benefits from both technologies, CBR as well as AI Planning and comprises an elegant solution. Even though AI Planning can be enough as a single technology for some simpler problems like tic-tac-toe the complexity of Monopoly would mean that the Planner would have to incorporate",
        "type": "NarrativeText"
    },
    {
        "element_id": "6c137b0d-07e3-4fa7-8099-fcced65eb146",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "a147ad8d-60b1-48d4-8499-e08d79919e83",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    },
    {
        "element_id": "475db30c-21ff-4b7d-b0b7-3d8f9cf69026",
        "metadata": {},
        "text": "302 DIMEA 2008",
        "type": "UncategorizedText"
    },
    {
        "element_id": "69532577-c1bb-4dff-8ea3-9a279b7938fa",
        "metadata": {},
        "text": "large and complex domain and a very big state model. The CBR application helps reduce this complexity by focusing the planning on smaller domain of the game. Basically the CBR reduces the overall goal of the play (wining the game) to smaller more concrete goals suitable to the particular state of the game, thus reducing the need for global planning strategies and complex planning domain.",
        "type": "NarrativeText"
    },
    {
        "element_id": "ff60548d-cba1-4cd1-98b3-b845a9e35466",
        "metadata": {},
        "text": "Furthermore this symbiosis of technologies gives way for more precise and finely tuned strategies which can be difficult to include into global plan for the whole game. One simple example for the Monopoly game would be this: Sometimes it\u2019s better to stay in jail because rolling double increases the probability of landing on some field (two, four, six, eight, ten or twelve steps from the jail) that can be of great importance to the rest of the game. These and similar small local strategies can be easily recognized by similar cases in the CBR database.",
        "type": "NarrativeText"
    },
    {
        "element_id": "f8298544-6ed4-4b55-a96f-6f9941062465",
        "metadata": {},
        "text": "In other words the system is flexible enough so that new strategies can be incorporated easily missing strategies can be also recognized by the distance metrics as well as wrong assumptions in the strategies can be easily recognized.",
        "type": "NarrativeText"
    },
    {
        "element_id": "634d8d16-8e8b-4b61-8cfe-b080e9228d6e",
        "metadata": {},
        "text": "One other important property of the system is that is highly configurable. The game its self can be diversely different depending on the configuration of the board. Even though the platform is restricted to Monopoly type of games, changing the layout and values of the fields effectively brings completely different properties of the game. In addition the CBR database represents the entire experience of the AI Player. It can be filled with rich set of strategies or even configured with different flavors of difficulties of play, this of course coupled with the domain of the planner which can differ from a case to a case as well.",
        "type": "NarrativeText"
    },
    {
        "element_id": "5de8298b-d9ea-4275-8f80-b370f22e336e",
        "metadata": {},
        "text": "8. Future Work",
        "type": "ListItem"
    },
    {
        "element_id": "1bab002e-e743-42c3-bff9-1e54fa400d46",
        "metadata": {},
        "text": "Further exploration of this technology would go towards complete implementation of an AI aware agent for monopoly. Initial results from the local cases with more specific strategies show CBR as a capable tool for representing expertise in playing the game. Completing the more general strategies and coupling them with the planning domain will give precise results on the benefits from this architecture.",
        "type": "NarrativeText"
    },
    {
        "element_id": "1d8b9ea3-cddc-49ab-8d37-3627b3c2aa2c",
        "metadata": {},
        "text": "There is also need for exploring the planning of strategies of opponents. This task is to some extent different because we cannot always expect the opponent to select the best move we think. In the Tic-tac-toe example all possible moves of the opponent were taken into consideration, if we used the same planner for the opponent only tie games would result from the game tree. In other words mistakes of the players also need to be considered.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c6cb6e59-4692-411f-9c06-f1a40cb0bec3",
        "metadata": {},
        "text": "The CBR Platform brings other functionalities well worth of exploring as well. The revision stage of the JColibri2 platform is basically capable of fine tuning strategies or even developing new strategies for the games. A well written underlying AI planning model with a capable feedback of the game tree evaluation back to the CBR revision capability can be an interesting concept in automatic experience acquisition for the AI model.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d1a097e3-f4d4-4f58-8a74-b7550f772c54",
        "metadata": {},
        "text": "There are also many other fields were combined CBR and planning approach can be incorporated into a problem solution. This combination is analogous in a big extent to a human way of",
        "type": "NarrativeText"
    },
    {
        "element_id": "9660b12e-0c36-43b4-8dca-d8505323ffa0",
        "metadata": {},
        "text": "reasoning. People in addition to logic of reasoning in situations with lack of information rely to planning strategies and prior experience, exactly the intuition behind CBR \u2014 AI Planning architecture.",
        "type": "NarrativeText"
    },
    {
        "element_id": "d5571bd0-0d0e-4648-a907-609ff34c624f",
        "metadata": {},
        "text": "9. ACKNOWLEDGMENTS",
        "type": "ListItem"
    },
    {
        "element_id": "4f1d6efe-fd69-4c27-b286-75a675bde012",
        "metadata": {},
        "text": "We would like to thank Prof. Sofia Tsekeridou for her involvement in the valuable discussions we had on the topic of CBR.",
        "type": "NarrativeText"
    },
    {
        "element_id": "19968c54-8fa3-4935-b01b-9955febc42d6",
        "metadata": {},
        "text": "10. REFERENCES 1] Minimax. Wikipedia. [Online] [Cited: April 23, 2008.] http://en.wikipedia.org/wiki/Minimax.",
        "type": "ListItem"
    },
    {
        "element_id": "0db5ac30-ba93-4ab8-8513-2e8030368923",
        "metadata": {},
        "text": "2] Von Neumann, J: Zur theorie der gesellschaftsspiele Math. Annalen. 100 (1928) 295-320",
        "type": "NarrativeText"
    },
    {
        "element_id": "a9922202-064e-4895-aac2-439a3db11e23",
        "metadata": {},
        "text": "3] Automated Planning. Wikipedia. [Online] [Cited: April 23, 2008.] http://en.wikipedia.org/wiki/Automated_planning.",
        "type": "NarrativeText"
    },
    {
        "element_id": "7a95e63c-6dab-4621-b19b-9f114354b651",
        "metadata": {},
        "text": "4) Sanchez-Ruiz, Antonio, et al. Game Al for a Turn-based Strategy Game with Plan Adaptation and Ontology-based retrieval.",
        "type": "ListItem"
    },
    {
        "element_id": "97ecda48-1fd7-46cc-b2e0-7b9b667d0785",
        "metadata": {},
        "text": "5] K. Erol, J. Hendler, and D. Nau (1994). Semantics for hierarchical task-network planning. Technical Report TR-94- 31, UMIACS.",
        "type": "NarrativeText"
    },
    {
        "element_id": "9622ce22-1e4b-457c-98fc-e0c9565d68c5",
        "metadata": {},
        "text": "6] Smith, S. J. J. and Dana S. Nau, T. A. Throp. A Planning approach decrarer play in contract bridge. Computational Intelligence. 1996, Vol. 12, 1.",
        "type": "NarrativeText"
    },
    {
        "element_id": "c2eefa90-fdad-4b05-a739-64b022aacc6e",
        "metadata": {},
        "text": "7) One Jump Ahead: Challenging Human Supremacy in Checkers. J.Schaeffer. s.1. : Springer-Verlag, 1997. 8] IBM. How Deep Blue works. [Online] 1997. [Cited: April",
        "type": "ListItem"
    },
    {
        "element_id": "8dbc9f5a-bb5e-49de-a0b4-b8f1317783fd",
        "metadata": {},
        "text": "23, 2008.] http://www. research.ibm.com/deepblue/meet/html/d.3.2.html",
        "type": "NarrativeText"
    },
    {
        "element_id": "e51090bb-9376-420a-bbcb-8f196e504db1",
        "metadata": {},
        "text": "9] Ghallab, Malik, Nau, Dana and Traverso, Paolo. Automated Planning theory and practice. s.1. : Morgan Kaufmann Publishers, May 2004. ISBN 1-55860-856-7.",
        "type": "NarrativeText"
    },
    {
        "element_id": "3c9775a6-5e30-4b0f-b4f4-638e6d3dc206",
        "metadata": {},
        "text": "10] Case Based Reasoning. Experiences, Lessons and Future. Leake, David. s.]. : AAAI Press. MIT Press., 1997.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6c7a347b-44d0-4b24-b7e8-b14ee0d49342",
        "metadata": {},
        "text": "11] Applying case-based reasoning: techniques for enterprise systems. Watson, I. San Francisco, CA, USA : Morgan Kaufmann Publishers Inc., 1998.",
        "type": "NarrativeText"
    },
    {
        "element_id": "571b3908-be8c-446a-88db-d1b8cb28ac37",
        "metadata": {},
        "text": "12] Plaza, A. Aamodt and E. Case-based reasoning: Foundational issues, methodological. AJ Communications. 1994, 7(i).",
        "type": "UncategorizedText"
    },
    {
        "element_id": "3546b7e5-0922-4767-9ed2-c73b0a5ec867",
        "metadata": {},
        "text": "13] Tic-tac-toe. Wikipedia. [Online] [Cited: April 23, 2008.] http://en. wikipedia.org/wiki/Tic-tac-toe.",
        "type": "Title"
    },
    {
        "element_id": "19bd51fd-82f1-4b8f-b421-dbe3b0a1b545",
        "metadata": {},
        "text": "14] Diaz-Agudo, B. and Gonzalez-Calero, P. A. An architecture for knowledge intensive CBR systems. Advances in Case-Based Reasoning \u2014 (EWCBR\u201900). New York : Springer-Verlag, Berlin Heidelberg, 2000.",
        "type": "NarrativeText"
    },
    {
        "element_id": "6a08af1a-2d75-42c9-b2f4-b62e65ce6048",
        "metadata": {},
        "text": "15] Ilghami, Okhtay and Nau, Dana S. A General Approach to Synthesize Problem-Specific Planners. 2003.",
        "type": "UncategorizedText"
    },
    {
        "element_id": "17066f13-19e0-40bd-97b6-4f0750cf6496",
        "metadata": {},
        "text": "3rd International Conference on Digital Interactive Media in Entertainment and Arts",
        "type": "Title"
    },
    {
        "element_id": "8eb97be3-f5fa-4d56-b072-84661915c93d",
        "metadata": {},
        "text": "",
        "type": "PageBreak"
    }
]