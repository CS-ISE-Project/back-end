{
    "title": "Generating Diverse Code Explanations using the GPT3 Large Language Model",
    "authors": [
        "Stephen MacNeil",
        "Andrew Tran",
        "Dan Mogil",
        "Seth Bernstein",
        "Erin Ross",
        "Ziheng Huang"
    ],
    "institutes": [
        "Temple University Philadelphia, PA, USA",
        "University of CaliforniaSan Diego La Jolla, CA, USA"
    ],
    "keywords": [
        "large language models",
        "natural language processing",
        "code explanations",
        "computer science education"
    ],
    "abstract": "Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide highquality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing errorspecific feedback [10, 16]. However, these ap proaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Githubs Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs potential to support learning by explain ing numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.",
    "permissions": "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. ICER 2022, August 711, 2022, Lugano and Virtual Event, Switzerland 2022 Copyright held by the owner/author(s). ACM ISBN 9781450391955/22/08. https://doi.org/10.1145/3501709.3544280",
    "content": "To understand the types of explanations GPT3 [2] can generate, we issued over 700 prompts across numerous code snippets. An example prompt and resulting explanation is shown in Figure 1. We discovered eight explanation types and Figure 2 includes three explanation types to illustrate the explanatory power of GPT3. The additional types include: 1) tracing the execution of code, 2) fixing bugs and explaining how they were fixed, 3) generating analogies to real world settings, 4) listing relevant programming concepts, and 5) predicting the console output. Figure 1: A prompt and explanation based on analogy. 2.1 Analyzing and explaining time complexity Instructors rate time complexity as the most difficult programming topic [17]. However, understanding time complexity is important [6, 13] because it facilitates decisionmaking so students choose an appropriate algorithm for a given problem. This use case shows GPT3 can identify and explain time complexity. 2.2 Identifying common mistakes made by beginner programmers Commonality exists in how students solve programming prob lems [15] and the mistakes they make [1, 11]. Pedagogical tech niques, such as the muddiest point highlight these common and most confusing concepts [3, 14]. GPT3 can automatically create a checklist of common mistakes students might make regarding a given code snippet."
}