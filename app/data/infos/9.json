{
    "publication_date": "07-08-2022",
    "title": "Generating Diverse Code Explanations using the GPT-3 Large Language Model",
    "authors": [
        "Stephen MacNeil",
        "Andrew Tran",
        "Dan Mogil",
        "Seth Bernstein",
        "Erin Ross",
        "Ziheng Huang"
    ],
    "institutes": [
        "Temple University Philadelphia, PA, USA",
        "University of CaliforniaSan Diego La Jolla, CA, USA"
    ],
    "keywords": [
        "large language models",
        "natural language processing",
        "code explanations",
        "computer science education"
    ],
    "abstract": "Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these ap- proaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Githubs Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs potential to support learning by explain- ing numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.",
    "content": "1. Introduction\n\n2. USE CASES\nTo understand the types of explanations GPT-3 [2] can generate, we issued over 700 prompts across numerous code snippets. An example prompt and resulting explanation is shown in Figure 1. We discovered eight explanation types and Figure 2 includes three explanation types to illustrate the explanatory power of GPT-3. The additional types include: 1) tracing the execution of code, 2) fixing bugs and explaining how they were fixed, 3) generating analogies to real world settings, 4) listing relevant programming concepts, and 5) predicting the console output. Figure 1: A prompt and explanation based on analogy.\n\n2.1 Analyzing and explaining time complexity\nInstructors rate time complexity as the most difficult programming topic [17]. However, understanding time complexity is important [6, 13] because it facilitates decision-making so students choose an appropriate algorithm for a given problem. This use case shows GPT-3 can identify and explain time complexity.\n\n2.2 Identifying common mistakes made by beginner programmers\nCommonality exists in how students solve programming prob- lems [15] and the mistakes they make [1, 11]. Pedagogical tech- niques, such as the muddiest point highlight these common and most confusing concepts [3, 14]. GPT-3 can automatically create a checklist of common mistakes students might make regarding a given code snippet."
}