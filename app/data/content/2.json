{
    "url": "https://drive.google.com/file/d/1rjGk1mEFXoavUZs1Az1RuV_61a7hRkR-/view?usp=drive_link",
    "publication_date": "03-08-2023",
    "title": "Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model",
    "authors": [
        "Shivangi Sachan",
        "Khushbu Doulani",
        "Mainak Adhikari"
    ],
    "institutes": [
        "Department of CSE IIIT Lucknow",
        "Vardhaman College of Engineering"
    ],
    "keywords": [
        "Dataset",
        "KNN",
        "Gaussian Naive Bayes",
        "LSTM",
        "SVM",
        "Bidirectional LSTM",
        "GRU",
        "Word-Embeddings",
        "CNN"
    ],
    "abstract": "The emergence of novel types of communication, such as email, has been brought on by the development of the internet, which radically concentrated the way in that individuals communicate socially and with one another. It is now establishing itself as a crucial aspect of the communication network which has been adopted by a variety of commercial enterprises such as retail outlets. So in this research paper, we have built a unique spam-detection methodology based on email-body sentiment analysis. The proposed hybrid model is put into practice and preprocessing the data, extracting the proper- ties, and categorizing data are all steps in the process. To examine the emotive and sequential aspects of texts, we use word embed- ding and a bi-directional LSTM network. this model frequently shortens the training period, then utilizes the Convolution Layer to extract text features at a higher level for the BiLSTM network. Our model performs better than previous versions, with an accuracy rate of 97\u201398%. In addition, we show that our model beats not just some well-known machine learning classifiers but also cutting-edge methods for identifying spam communications, demonstrating its superiority on its own. Suggested Ensemble models results are examined in terms of recall, accuracy, and precision",
    "content": "introduction over the past few a clear surge of both the amount of mers as well as spam this is likely due to a fact that the investment necessary for engaging in the spamming industry is relatively as a result of we currently have a system that identifies every email as which has caused major ditures in the investment of defense systems emails are used for online crimes like and algorithms that are based on machine learning are now the most effective and often used approach to the recognition of which is defined as a fraudulent attempt to acquire private information by masquerading as a worthy party in electronic has rapidly advanced past use of simple techniques and the tactic of casting a wide spear phishing uses a variety of sophisticated techniques to target a single other researchers used decision and svm to compare the performance of supervised ml algorithms for spam identification spam emails clog up cipients inboxes with unsolicited which frustrate them and push them into the attackers planned traps as a spam messages unquestionably pose a risk to both email users and the internet in users may occasionally read the entire text of an unsolicited message that is delivered to the target users inboxes without realizing that the message is junk and then choosing to avoid building a framework for email spam detection is the aim of this in this we combine the network with the cnn and gru cnn layers are used to speed up training time before the and more advanced textual istics are extracted with the use of this network in comparison to the straight lstm in less gated recurrent neural works are then added because they train more quickly and perform better for language to evaluate and investigate various machine learning algorithms for predicting email and develop a hybrid classification algorithm to filter email spam before employing an ensemble classification algorithm to forecast to put an innovative technique into practice and compare it to the current method in terms of various ensemble a successful machine learning combines a group of learners rather than a single learner to forecast unknown target and stacking are the four main types of ensemble learning to increase an integrated method and the combining of two or three algorithms are also extraction of features takes a long it can be challenging to extract all of the crucial information from a short over the span associated with this august india sachan et we utilize bidirectional large memories in conjunction with convolutional neural networks to come up with an innovative method to the detection of bagging and boosting approaches were widely preferred in this contribution and paper organization is as section describes literature section describe motivation for this research section sketches procedure of details section present experimental dataset description and evaluation and section summarizing outcomes of the related work email is indeed the second most frequently utilized internet cation as well as the third most common method of claims one cybercriminals exploit it in a number of including as sending obscene or abusive adding viruses to snatching the private information of and posing it to a broad spam letters made up of all email traffic in march we examine three main types of lawful emails in our first are fake which are sent to manipulate recipients to submit sensitive the ond as being use of harassing emails to threaten suspicious emails that describe illegal activities belong to the third many researchers have earlier contributed massively to this the researcher claims there is some proof that suspicious emails were sent before to the events of when it comes to data there are also convinced approaches and technologies like that are even though their efficiency of the are together is adversely a hidden which itself is essential for is the top layer of the we use oversampling methods for this minority class because of the absence of sampling techniques can help with but they have an impact on simulation oversampling causes data to be randomly which affects test data because dividing data may result in dersampling may result in the loss of some strong in order to advance email it is crucial to provide datasets on criminal garg et which revealed that spam in an email was detected in percent of business spam was established as an obstacle for email recognizing spam and getting rid of it were the primary as spam can be may lead to other internet sites being which can offer harmful and can feature those who are not lar with their content using to select the each mail transmission protocol requires precise and effective email a machine learning comparison is our study has suggested that innovative deep learning outperforms learning algorithms like svm and current studies on the classification of emails use a variety of machine learning with a few of them focusing on the study of the sentiments consisted of within email the lack of datasets is a significant obstacle to email there are few publicly accessible thus researchers must use these datasets to test their potheses or gather data on their describe supplied outlier detection models to enhance the iiot artificial neural gaussian and rf ensemble techniques were performed to forecast class and the outputs were input into a classifying unit to increase a method for phishing detection was presented by the authors in to classify phishing they employed they categorize spam and phishing they enhanced phishing email classifiers with more accurate predictions by extracting they showed some effective machine ing spam filtering when the pca method is it will lower the number of features in the the collected features go through the pca algorithm to reduce the number of the pca method is used to make a straightforward representation of the information which illustrates the amount of variability there is in the the authors of presented the fuzzy method for classifying spam to stop they implemented a membership threshold a methodology to identify beled data was put forth by the authors of and applied motive analysis to the enron data they divided the data into categories that were and they grouped the data using an unsupervised ml technique and then classified it using the supervised ml techniques svm and and colleagues implemented deep semantic analysis and categorization of data using a forensic for multiclass email sefaced employs a gated recurrent neural network based on long memory different random weight tializations affect lstms et experiments on rough set email spam ing show that it is feasible to significantly boost coverage without decreasing accuracy according to xia et sms spam has been identified using machine learning model such as naive bayes support vector machines long selective memory machines and convolutional neural networks including every instance of a method for categorizing et using adaboost and stochastic gradient descent algorithms for filtering with r and orange software spam orange software was used to create the which included adaboost and the majority of researchers focused on email spam classification ods because spam can be filtered in the early stages of there are widely used word bag which believes that documents are merely unordered collections of is the foundation for these kumaresan explains svm with a cuckoo search algorithm was used to extract textual features for spam renuka and visalakshi made use of svm spam email followed by selecting features using latent semantic indexing here we have used labeled dataset to train the hybrid we used for feature extraction and textual features for spam detection were extracted using svm and a cuckoo search for filtering out the spam combining the integrated strategy to the pure svm and nb overall accuracy is really accurate detection for spam email has been proposed using the negative selection algorithm and particle swarm pso is used in this instance to improve the effectiveness of the semantic analysis and classification of emails through informative selection of features and ensemble ai model august india motivation and novelty email is most common form of communication between people in this digital many users have been victims of spam and their personal information has been the email classification technique is employed to identify and filter junk and emails prior to reach a existing email classification methods result in irrelevant emails the loss of valuable keeping these constraints in the following contributions are made in this feature extraction is a lengthy extracting every important feature from text is in this we show how to employ gru with lutional neural networks and to find used and gated recurrent ral networks to examine the sentimental and sequential way of email applied cnn before the training time can be sped this network can also extract more advanced textual features faster than the network alone when combined with the gru we use enorn corpora datasets and compute and to assess how well the suggested technique our model outperforms several chine learning techniques as well as more contemporary methods for spam message proposed system architecture and model is a valuable tool for communicating with other email allows the sender to efficiently forward millions of advertisements at no this scheme is now being used in a variety of as a a massive amount of redundant emails is known as spam or junk many people are confused about the emails in their each learning sequence is given ward as well as backward to two different lstm networks that are attached to the same outputs layer in order for bidirectional lstms to this indicates that the has detailed sequential information about all points before and following each point in a specific in other we concatenate the outputs from both the forward and the backward lstm at each time step rather than just encoding the sequence in the forward each encoded form now comprehends the words that come before and after this is a problem for the internet the agram depicts various stages that aid in the prediction of email because data is messy and contains unnecessary mation and data preprocessing is critical in natural language processing the major preprocessing steps are picted nlp tokenization tokenization of documents into words follows predefined the tokenization step is carried out in python with spacy stop words removal stop words appear infrequently or frequently in the but they are less significant in terms of as a these are removed to improve data text normalization a lexicon form or order may they must all be changed to their root word to be correctly lemmatization and stemming are the two methods that can be used for when a final few characters are removed to create a shorter even if that form has no the procedure is known as lemmatization is a mixture of based an and it retains the context of a term while changing it back to its feature extraction feature extraction which transforms the initial text into its features so that it may be used for modeling after being cleaned up and before predicting we use a specific way to give weights to specific terms in our while it is simple for a computer to process we choose to represent individual words in such we choose word idf is the count of documents containing the term divided by the total number of and occurrence is the amount of instances a word appears in a we derive characteristics based on and we use equations to derive \ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 \ud835\udc61\ud835\udc53 \ud835\udc51\ud835\udc53 \ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 \ud835\udc61\ud835\udc53 \ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 \ud835\udc47 \ud835\udc53 \ud835\udc47\ud835\udc3c\ud835\udc51\ud835\udc53 log \ud835\udc41 a neural approach is the method that is utilized for this goal as the the following referred to as shows how handles word context through the use of here letter d stands for the display of a set of while the letters w and or represent paired word context that originated from a larger collection of set \ud835\udc43 \ud835\udc43 august india sachan et helps to improve on the typical which requires a massive sparse feature vector to score every word individually to represent this same entire this perception is sparse because the vocabulary is and each word or document is defined by a massive using a word word embedding needs to be converted terms into real value feature there are two basic issues with standard feature engineering techniques for deep data is represented using sparse and the second is that some of the meanings of words are not taken into similar phrases will have values in embedding vectors that are almost the input length in our proposed study is set to for our suggested if the texts seemed to be integer encoded with value systems between and the vocabulary distance would be our data is encoded as and the input and output dimensions are both set to the embedding layer outcome will be used in successive layers and for bilstm and gru machine learning model within the scope of the we are using the subsequent chine learning to examine and compare the overall efficacy of our suggested support vector gaussian logistic k nearest and random forest convolution network the popular rnn model generally performs well but takes too long to train the model incorporating the textual sequential when a layer is added after the rnn the learning duration is considerably feature extraction is another additionally possible using the convolutional in the convolution layer looks for combinations of the various words or paragraphs in the document that involve the we use features with dimensions and a size for for this the relu activation function is after the largest pooling layers with a pooling size of are put on the data in order to obtain bilstm network with gru recurrent neural network technique of text sentiment ysis is particularly and frequently recurrent neural networks surpass conventional neural cause it can remember the information from earlier time steps thanks to its a state vector is combined with an data to create a new state the resulting state vector uses the present to recollect past the rnn is straightforward and is based on the following \u210e\ud835\udc61 tanh \ud835\udc66\ud835\udc61 \ud835\udc4a\u210e\ud835\udc66\u210e\ud835\udc61 the vanilla not very good at remembering previous in addition to rnn struggles with diminishing gradient a kind of rnn is a long recall network solves a vanishing gradient descent problem and learns lstm was actually created to address the problem of lstm has the unique ability to the cell state is the lstm central with only a small amount of linear the cell state follows the sequence essentially unmodified from beginning to gate of an lstm is also under the command of these information is safely inserted to or eliminated from the cell the following equations are used by the lstm model to update each \ud835\udc53\ud835\udc61 \ud835\udf0e \ud835\udc4a\ud835\udc53 \ud835\udc4f\ud835\udc53 in this xt denotes and ht is the hidden state at the t time the following is the revised cell state \ud835\udc56t \ud835\udf0e \ud835\udc36\ud835\udc47 tanh \ud835\udc36\ud835\udc61 \ud835\udc53\ud835\udc61 \ud835\udc56\ud835\udc61 \ud835\udc36\ud835\udc47 we may compute the output and hidden state at t time steps using the multiplication operator \ud835\udc5c\ud835\udc61 \ud835\udf0e \u210e\ud835\udc61 \ud835\udc5c\ud835\udc61 tanh due to the reality it only considers all prior contexts from the present lstm does have a few as a result of it may accept data from preceding time steps through lstm as well as in order to avoid this further ments are carried out with the help of a bidirectional recurrent neural birnn can handle two pieces of formation from both the front and the is created by combining the and as a operating lstm has advantages such as cell state storage so that birnn have way to acknowledge from the context before and as a quence of it provides the with the advantages of an lstm with feedback for the next remembering dependencies is a significant new benefit of the which is a feature will be based on the call we forecast the probability of email content as and suspicious emails using as an input to the softmax activation which is a weighted sum of the dense to regulate the information gru employs the multiplying function and logistic sigmoid the gru has hidden states of storage memory and does not have distinct memory cells or units for state the and b which stand for and are crucial variables that must be calculated during the creation of the gru for training the word embedding known as the glove vector is they made it clear that gru is the superior model when there is a large amount of training data for textual groups and word embedding is and gru is required so as to compensate for the deletion of the and in our the embedding maximum sequence and lexicon size were used to start the lstm embedding layer in three separate lstm the input vector was modified to make it appropriate for such a prior sequences are returned by lstm the of the lstm layer must be set to false when the subsequent state is free of the gated semantic analysis and classification of emails through informative selection of features and ensemble ai model august india quantity of learning parameters must be taken into a lstm layer was set and different lstm unit combinations were more because it has more the model made with bilstm will take longer to bidirectional lstm is the name of a particular kind of recurrent neural network that is primarily used for the processing of natural it is able to use data from both in contrast to regular it enables input flow in both it is an effective instrument for demonstrating the logical relationships between words and and this involves both the forward and backward directions of the in bilstm works by adding one extra layer of causing the information flow to travel in the other it only denotes that the input sequence runs in reverse at the next lstm tiple including and are then applied to the results of the two lstm the gated design of and gru networks solves the disappearing gradient and exploding a good way to handle more long sequences is to use and gru gru works well with datasets that have in two to three the complicated model learns the long sequence of email text we have used word bidirectional lstm and gru networks as our three building blocks to separate email messages based on their sentiment and sequential we succinctly demonstrate below why these blocks help identify email we have used the sequence to sequence lstm as the current block in the networks since it can retrieve both the previous and next sequences from the more so than a straightforward lstm it can also recognize and extract text sentiment and sequential we extract the more complex and advanced teristics for network using convolutional network which is the second block after the takes a long time to extract hence one of the reasons for using this block is to reduce the overall training experimental evaluation experimental setup we divided the information into training and testing groups of we divided the remaining of the percent training data into test data for the and evaluate the efficacy of the suggested method using the pythonic packages as tensorflow and scikit dataset description email spam detection is the foundation of this research the dataset includes normal emails from the enron deceptive emails from phished email harassment emails chosen from hate and the offensive only the content of the email body is used for all header including and are and word embedding are used to extract characteristics from the email sage and classify this is publicly the presented model is implemented using and several including and are used to examine the evaluation metrics and results classifier performance is assessed using metrics such as and four terms make up a confusion matrix that is used to calculate these true positives are positive values that have been rately assigned the positive the negative values that are accurately identified as negative are known as true negatives true negative values are those that can be accurately fied as being negative positive readings that have been mistakenly labeled as tive are known as false negatives assess the efficacy of the suggested model is listed accuracy reveals how frequently the ml model was overall accuracy \ud835\udc47\ud835\udc43 \ud835\udc47\ud835\udc43 \ud835\udc39\ud835\udc43 \ud835\udc39\ud835\udc41 the accuracy of the model gauges how effectively it can predict a specific precision \ud835\udc47\ud835\udc43 \ud835\udc47\ud835\udc43 \ud835\udc39\ud835\udc43 recall tells us how often the model was able to ognize a specific recall \ud835\udc47\ud835\udc43 \ud835\udc47\ud835\udc43 \ud835\udc39\ud835\udc41 model accuracy precision recall gaussian nb random forest knn svm lstm proposed ensemble table differet score on test data and recall metrics are in the given table where six different classifiers are gaussian dom and propose ensemble hybrid model have been used in this in the and gru architectures which enable sequence cnn strands for feature extraction on data input which are combined with it requires less time training and a higher expandable any bottlenecks are created by predictions and the increasing number of distinct units of this model is useful for dealing with classifications that consist of two or more than two so suggested ensemble out of these six produces more accurate august india sachan et figure performance analysis comparative analysis a ability to fit new data is measured by the validation whereas its ability to fit training data is determined by the training the two main variables that decide whether in which learning is efficient or not are validation loss and training lstm and suggested ensemble hybrid models have equivalent loss and in this we are contrasting the lstm with the proposed model and in terms of their respective validation accuracies and the accuracy was at its highest after epochs of operation when it achieved an accuracy of roughly while minimizing model figure lstm model training and validation accuracy figure lstm model training and validation loss figure ensemble model training and validation accuracy figure ensemble model and validation loss semantic analysis and classification of emails through informative selection of features and ensemble ai model august india in this proposed ensemble hybrid train accuracy is validation accuracy is and lstm has train accuracy of and validation accuracy is so based on figures and indicate the validation loss for lstm and the proposed ensemble hybrid model to be and and figures and show the validation accuracy to be and lstm and the proposed hybrid model used ensemble artificial with the proposed hybrid model outperforming the we decide on dense architecture as the final model for identifying the text messages as spam or nonspam based on and the aforementioned the loss and accuracy over epochs are more stable than and the proposed classifier has a straightforward conclusion the model is composed of four networks and we may train the model more quickly by using the convolutional layer followed by the and then the bilstm the bidirectional lstm network also has properties that we can we have used a bidirectional gru network to memorize a contextual meaning and sequential which proves the performance accuracy to roughly",
    "references": [
        "[1] Rayan Salah Hag Ali and Neamat El Gayar. 2019. Sentiment analysis using unla- beled email data. In 2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE). IEEE, 328\u2013333. ",
        "[2] Ali Shafigh Aski and Navid Khalilzadeh Sourati. 2016. Proposed efficient algo- rithm to filter spam using machine learning techniques. Pacific Science Review A: Natural Science and Engineering 18, 2 (2016), 145\u2013149. ",
        "[3] Huwaida T Elshoush and Esraa A Dinar. 2019. Using adaboost and stochastic gradient descent (sgd) algorithms with R and orange software for filtering e-mail spam. In 2019 11th Computer Science and Electronic Engineering (CEEC). IEEE, 41\u201346. ",
        "[4] Weimiao Feng, Jianguo Sun, Liguo Zhang, Cuiling Cao, and Qing Yang. 2016. A support vector machine based naive Bayes algorithm for spam filtering. In 2016 IEEE 35th International Performance Computing and Communications Conference (IPCCC). IEEE, 1\u20138. ",
        "[5] Pranjul Garg and Nancy Girdhar. 2021. A Systematic Review on Spam Filtering Techniques based on Natural Language Processing Framework. In 2021 11th Inter- national Conference on Cloud Computing, Data Science & Engineering (Confluence). IEEE, 30\u201335. ",
        "[6] Adam Kavon Ghazi-Tehrani and Henry N Pontell. 2021. Phishing evolves: Ana- lyzing the enduring cybercrime. Victims & Offenders 16, 3 (2021), 316\u2013342. ",
        "[7] Radicati Group et al. 2015. Email Statistics Report 2015\u20132019. Radicati Group. Accessed August 13 (2015), 2019. ",
        "[8] Maryam Hina, Mohsin Ali, and Javed. 2021. Sefaced: Semantic-based forensic analysis and classification of e-mail data using deep learning. IEEE Access 9 (2021), 98398\u201398411. ",
        "[9] Maryam Hina, Mohsin Ali, Abdul Rehman Javed, Fahad Ghabban, Liaqat Ali Khan, and Zunera Jalil. 2021. Sefaced: Semantic-based forensic analysis and classification of e-mail data using deep learning. IEEE Access 9 (2021), 98398\u2013 98411. ",
        "[10] Weicong Kong, Zhao Yang Dong, Youwei Jia, David J Hill, Yan Xu, and Yuan Zhang. 2017. Short-term residential load forecasting based on LSTM recurrent neural network. IEEE transactions on smart grid 10, 1 (2017), 841\u2013851. ",
        "[11] T Kumaresan and C Palanisamy. 2017. E-mail spam classification using S-cuckoo search and support vector machine. International Journal of Bio-Inspired Compu- tation 9, 3 (2017), 142\u2013156. ",
        "[12] Nuha H Marza, Mehdi E Manaa, and Hussein A Lafta. 2021. Classification of spam emails using deep learning. In 2021 1st Babylon International Conference on Information Technology and Science (BICITS). IEEE, 63\u201368. ",
        "[13] Tomas Mikolov and Geoffrey Zweig. 2012. Context dependent recurrent neural network language model. In 2012 IEEE Spoken Language Technology Workshop (SLT). IEEE, 234\u2013239. ",
        "[14] Sarwat Nizamani, Nasrullah Memon, Mathies Glasdam, and Dong Duong Nguyen. 2014. Detection of fraudulent emails by employing advanced feature abundance. Egyptian Informatics Journal 15, 3 (2014), 169\u2013174. ",
        "[15] V Priya, I Sumaiya Thaseen, Thippa Reddy Gadekallu, Mohamed K Aboudaif, and Emad Abouel Nasr. 2021. Robust attack detection approach for IIoT using ensemble classifier. arXiv preprint arXiv:2102.01515 (2021). ",
        "[16] Justinas Rastenis, Simona Ramanauskait\u02d9e, Justinas Janulevi\u010dius, Antanas \u010cenys, Asta Slotkien\u02d9e, and K\u0119stutis Pakrijauskas. 2020. E-mail-based phishing attack taxonomy. Applied Sciences 10, 7 (2020), 2363. ",
        "[17] Karthika D Renuka and P Visalakshi. 2014. Latent semantic indexing based SVM model for email spam classification. (2014). ",
        "[18] Shuvendu Roy, Sk Imran Hossain, MAH Akhand, and N Siddique. 2018. Sequence modeling for intelligent typing assistant with Bangla and English keyboard. In 2018 International Conference on Innovation in Engineering and Technology (ICIET). IEEE, 1\u20136. ",
        "[19] Tara N Sainath, Oriol Vinyals, Andrew Senior, and Ha\u015fim Sak. 2015. Convolu- tional, long short-term memory, fully connected deep neural networks. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). Ieee, 4580\u20134584. ",
        "[20] Anuj Kumar Singh, Shashi Bhushan, and Sonakshi Vij. 2019. Filtering spam messages and mails using fuzzy C means algorithm. In 2019 4th International Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU). IEEE, 1\u20135. ",
        "[21] Kristina Toutanova and Colin Cherry. 2009. A global model for joint lemmati- zation and part-of-speech prediction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. 486\u2013494. ",
        "[22] Tian Xia. 2020. A constant time complexity spam detection algorithm for boosting throughput on rule-based filtering systems. IEEE Access 8 (2020), 82653\u201382661. ",
        "[23] Yan Zhang, PengFei Liu, and JingTao Yao. 2019. Three-way email spam filtering with game-theoretic rough sets. In 2019 International conference on computing, networking and communications (ICNC). IEEE, 552\u2013556. Received 15 April 2023 187"
    ]
}