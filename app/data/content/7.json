{
    "url": "dummy",
    "title": "Large Language Model Augmented Narrative Driven Recommendations",
    "authors": [
        "Sheshera Mysore",
        "Andrew McCallum",
        "Hamed Zamani"
    ],
    "institutes": [
        "University of Massachusetts Amherst USA",
        "University of Massachusetts Amherst USA",
        "University of Massachusetts Amherst USA"
    ],
    "keywords": [],
    "abstract": "Narrativedriven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describ ing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural languagebased conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical useritem interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from useritem interactions with few shot prompting and train retrieval models for NDR on synthetic queries and useritem interaction data. Our experiments demon strate that this is an effective strategy for training smallparameter retrieval models that outperform other retrieval and LLM baselines for narrativedriven recommendation.",
    "content": "introduction recommender systems personalized to users are an important com ponent of several industryscale platforms these sys tems function by inferring users interests from their prior inter actions on the platform and making recommendations based on these inferred while recommendations based on historical permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first copyrights for components of this work owned by others than the must be abstracting with credit is to copy or to post on servers or to redistribute to requires prior specific permission a request permissions from recsys september singapore copyright held by the publication rights licensed to acm isbn interactions are users soliciting recommendations often start with a vague idea about their desired target items or may desire recommendations depending on the context of often missing in historical interaction data in these it is common for users to solicit recommendations through long form narrative queries describing their broad interests and information access tasks like these have been studied as narrative driven recommendations for items ranging from books and movies to points of interest bogers and koolen note these narrative requests to be common on discussion forums and several there is a lack of support for these complex natural language queries in current with the emergence of conversational interfaces for information access support for complex ndr tasks is likely to become in this recent work has noted an increase in complex and subjective natural language requests com pared to more conventional search interfaces the emergence of large language models with strong lan guage understanding capabilities presents the potential for fulfilling such complex requests this work explores the potential for repurposing historical useritem recommendation tra ditionally used for training collaborative filtering with llms to support given a users with items and their accompanying text documents \ud835\udc37\ud835\udc62 selected from a useritem interaction dataset we prompt a parameter to author a synthetic narrative query \ud835\udc5e\ud835\udc62 based on \ud835\udc37\ud835\udc62 since we expect the query \ud835\udc5e\ud835\udc62 to be noisy and not fully representative of all the user \ud835\udc37\ud835\udc62 is filtered to retain only a fraction of the reviews based on a languagemodel assigned likelihood of \ud835\udc5e\ud835\udc62 given a user doc a pretrained lm based retrieval model is finetuned for retrieval on the synthetic queries and filtered our which we refer to as follows from the observation that while narrative queries and suggestions are often made in online discussion and could serve as training the number of these posts and the diversity of domains for which they are available is significantly smaller than the size and diversity of passively gathered useritem interaction while bogers and koolen note nearly narrative requests for books on the librarything discussion a publicly available useritem interaction dataset for goodreads contains interactions with nearly books by users we empirically evaluate mint in a publicly available test collec tion for point of interest pointrec to train data augmentation with interaction recsys september singapore zamani figure an example narrative query soliciting point of interest the query describes the users preferences and the context of their figure the format of the prompt used in mint for generating synthetic narrative queries from interaction with a large language our ndr we generate synthetic training data based on interaction datasets from models trained with mint significantly outperform several baseline models and match the performance of significantly larger llm baselines autoregressively generating code and synthetic datasets are related work data augmentation for information a line of recent work has explored using language models to generate synthetic queries for data augmentation to train models for information trieval tasks given a document collection of a language model is used to create synthetic queries for the document an optional filtering step cludes noisy and a or a is trained for the retrieval while earlier work of ma et train a custom query generation model on more recent work has leveraged large language models for question generation in generating synthetic this work indicates the effectiveness of smaller parameter llms to for generating synthetic queries in simpler tasks and finds larger models parameters and to be necessary for harder tasks such as argument retrieval similar to this we explore the generation of synthetic queries with llms for a retrieval like this we demonstrate a data augmentation method for creating effective training data from sets of user documents found in recommendation datasets rather than individual other work in this space has also explored training more efficient vector models from synthetic queries instead of more expensive models and generating queries with a diverse range of intents than the ones available in implicit feedback datasets to enhance item retrievability besides creating queries for retrieval concurrent work of leszczynski et has also explored the creation of thetic conversational search datasets from music recommendation datasets with the synthetic queries and user documents are then used to train retrieval models for conversational our work resembles this in creating synthetic queries from sets of user items found in recommendation interaction it differs in the task of creating tive queries for our work also builds on the recent perspective of radlinski et who make a case for natural language user profiles driving recommenders narrative requests tie closely to natural language user our work presents a step toward these while our work explores data augmentation from item interactions for a ndr prior work has also explored data augmentation of the graph for training collaborative filtering this work has often explored mentation to improve recommendation performance for minority or users and has leveraged tive models and text similarity models for augmenting the complex queries in information with the advent of performant models for text focus on complex and interactive information access tasks has seen a resurgence ndr presents an example of this ndr was first formalized in bogers and koolen for the case of book dation and subsequently studied in other domains bogers and koolen systematically examined narrative requests posted by users on discussion they defined ndr as a task ing item recommendation based on a narrative query and item while this formulation resembles personalized search and recommendation the length and complexity of requests differentiate these from other work has also demonstrated the effectiveness of initial recommendations from collaborative filtering approaches large language model augmented narrative driven recommendations recsys september singapore figure mint readily available interaction datasets commonly used to train collaborative filtering models for this is done by authoring narrative queries for sets of items liked by a user with a large language the data is filtered with a smaller language model and retrieval models are trained on the synthetic queries and user based on the narrative query more recent work of afzali et formulate the ndr task without access to the prior interactions of a user while also noting the value of contextual cues contained in the narrative in our we focus on this latter mulation of given the lack of focus on effectively using the rich narrative queries in most prior we demonstrate the usefulness of data augmentation from llms and interaction datasets lacking narrative besides a range of work has explored more and interactive query formulations for information these resemble queries in arguello et define the tip of tongue retrieval a search task where user queries describe the rich context of items while being unable to recall item metadata mysore et formulate an aspect conditional example task where results must match specific aspects of a long natural language and a vibrant body of work has explored conversational critiquing of recommenders where ural language feedback helps tune the recommendations received by users method problem setup in our we define recommendation to be a ranking where given a narrative query \ud835\udc5e made by a user a ranking system \ud835\udc53 must generate a ranking \ud835\udc45 over a collection of items we assume access to a interaction dataset i consisting of user interactions with items we assume the items \ud835\udc51\ud835\udc56 to be textual documents like reviews or item while we assume there to be any overlap in the users making narrative queries or the collection of items c and the interaction dataset we assume them to be from the same broad proposed method our proposed for a dataset of abundantly available i into training data for retrieval models by using llms as query ation models to author narrative queries d retrieval models are trained on the synthetic dataset d ure narrative queries from to author a narrative query \ud835\udc5e\ud835\udc62 for a user in we make use of the parameter model as our query generation model we include the text of interacted items in the prompt for and instruct it to author a narrative query to improve the coherence of generated queries and obtain correctly formatted we manually author narrative queries for topically diverse users based on their interacted items and include it in the prompt for the same three few shot examples are used for the whole dataset and the three users were chosen from generating narrative queries based on user interactions may also be considered a form of summarization for generating a natural language user profile filtering items for synthetic since we expect user items to capture multiple aspects of their interests and generated queries to only capture a subset of these we only retain some of the items present in before using it for training trieval for we use a language model to pute the likelihood of the query given each user \ud835\udc43\ud835\udc3f\ud835\udc40 and only retain the top \ud835\udc40 highly scoring item for this sults in \ud835\udc40 training samples per user for our ndr retrieval in our we use with ters for computing and follow sachan et for computing \ud835\udc43\ud835\udc3f\ud835\udc40 note that our use of \ud835\udc43\ud835\udc3f\ud835\udc40 represents a likelihood model classically used for search and recently shown to be an effective unsupervised method when used with large language models training retrieval we train and encoder models for ndr on the generated synthetic dataset monly used models in search are commonly used as scalable rankers from a large collection of on the other allow a richer interaction between query and item and are used as for both we use a transformer language model ture with a model similar to bert models embed the query and item independently into high dimensional q\ud835\udc62 d\ud835\udc56 and rank items for the user based on the minimum distance between recsys september singapore zamani q\ud835\udc62 and embeddings are obtained by averaging token embeddings from the final layer of and the same model is used for both queries and models input both the query and item and output a score to be used for ranking \ud835\udc60 where \ud835\udc53cr is parameterized as w\ud835\udc47 dropout w\ud835\udc47 we train our model with a margin ranking l\ud835\udc35\ud835\udc56 \ud835\udc62 d with randomly pled negatives \ud835\udc51 and \ud835\udeff our are trained with a l\ud835\udc36\ud835\udc5f \ud835\udc62 \ud835\udc52\ud835\udc60 for negative example items are randomly sampled from ranks from our trained at test we retrieve the top items with our trained and them with the we evaluate both these components in experiments and refer to them as and experiments and results we evaluate mint on a publicly available test collection for ndr and present a series of experimental setup we perform evaluations on an ndr dataset for recommendation pointrec pointrec contains realistic narrative queries words obtained from discussion forums on reddit and items pooled from baseline the items are annotated on a graded relevance scale by discussion forum members and further dated by the dataset the item collection c in pointrec contains pois with metadata and noisy text snippets describing the poi obtained from the bing search for test time we only rank the candidate items in the city and request category of the query available in pointrec this follows prior practice to exclude clearly irrelevant items we use interaction datasets from yelp to generate synthetic queries for note also that we limit our evaluations to pointrec since it presents the only publicly manually and candidate pooled test collection for to our other datasets for ndr use document lections that are no longer publicly accessible contain sparse and noisy relevance judgments due to them being determined with automatic rules applied to discussion threads lack pooling to gather candidates for judging relevance or lack realistic narrative queries we leave the development of more robust test collections and evaluation methods for ndr to future implementation we describe important details for mint and leave finer details of the model and training to our code to sample user interactions for generating synthetic queries from the yelp we exclude pois and users with fewer than ten reviews to ensure that users were regular users of the site with well represented this follows common prior practice in preparing interaction datasets for use then we retain users who deliver an average rating greater than and with this desirably biases our data to users who commonly describe their likings than it also retains the users whose interests are summarizable by in the yelp this results in retained randomly selected users are chosen for generating thetic narrative for these a single randomly selected sentence from of their reviews is included in the prompt to \ud835\udc41\ud835\udc62 after generating synthetic some items are filtered out we exclude of the items for a this results in about training samples for training and these decisions were made ally by examining the resulting datasets and the cost of authoring the expense of generating \ud835\udc5e\ud835\udc62 was about usd we compare and els against several standard and performant retrieval model these span supervised unsupervised and llm a standard unsupervised sparse retrieval baseline based on term overlap between query and with strong generalization performance across tasks and domains a model for retrieval with weakly pervised pairs a strong bert model initialized with and trained on billion supervised pairs aggregated from ous domains a on supervised pairs from a stage approach that retrieves items with a contriver and the top items with a model using a model with parameters this may be seen as an unsupervised grounded a cently proposed approach which autoregressively ates ten items using an llm prompted with the narrative query and generates tions grounded in c by retrieving the nearest neighbors for each generated item using a we include one example of a narrative query and recommended items in the prompt to the we run this baseline three times and report average performance across we report ndcg at and and recall at and our reported results should be considered lower bounds on realistic performance due to the judged documents at \ud835\udc58 in our test collections results table presents the performance of the proposed method compared against bold numbers indicate the and superscripts indicate statistical significance computed with at \ud835\udc5d we first note the performance of baseline we see outperformed by a transformer model trained for this mirrors prior work we see supervised models trained on similar sage and pairs form a weakly supervised model by smaller the grounded llm outperforms all dicating strong generalization and mirroring prior results examining the mint we first note that the mint sees statistically significant improvement compared to large language model augmented narrative driven recommendations recsys september singapore table performance of the proposed for recommendation on the superscripts denote statistically significant improvements compared to specific baseline pointrec model parameters map mrr llm and outperforms the best baselines by on sion measures and on recall we see a model trained for underperform indicating the challenge of the ndr trained on orders of magnitude lesser data than sees improved performance indicating the quality of data obtained from also performs at par with a llm while offering the inference efficiency of a we see outperform the baseline and grounded llm by on precision measures and on recall measures demonstrating the value of mint for training ndr ablations in table we ablate various design choices in different choices result in different training sets for the bienc and crenc note that in reporting ablation performance for we still use the performant model for obtaining tive examples for training and without quality negative we found crenc to result in much poorer no item since synthetic queries are unlikely to resent all the items of a mint excludes user items which have a low likelihood of being generated from the document without this we expect the training set for training retrieval models to be larger and in table we see that excluding this step leads to a lower performance for bienc and indicating that the quality of data obtained is important for llm for mint relies on using an expensive rameter instructgpt model for we investigate the efficacy for generating\ud835\udc5e\ud835\udc62 for with a parameter gpt model we use an identical setup to the llm for in table we see that training on the synthetic narrative queries of the smaller llm results in worse models ten underperforming the baselines in table this indicates the inability of a smaller model to generate complex narrative queries while conditioning on a set of user this necessity of a larger llm for generating queries in complex retrieval tasks has been observed in prior work llm for item we find a smaller llm to result in poor quality data when used to generate narrative queries ditioned on here we simplify the text generation task using a llm to generate queries for individual items this experiment also mirrors the setup for generating synthetic queries for search tasks we use shot examples and ple one item per user for generating given the lower cost of using a smaller we use all users in our yelp dataset rather than a smaller random from table we see that this results in higher quality queries than using smaller llms for erating narrative queries from the resulting bienc model underperforms the indicating the value of generating complex queries conditioned on multiple items as in mint for we see that crenc approaches the performance of that this approach uses the performant for sampling negatives and first stage we leave further exploration of using small parameter llms for data augmentation for ndr models to future conclusions in this we present a data augmentation method for the recommendation mint historical interaction datasets for ndr by using a rameter large language model to author narrative queries while conditioning on the text of items liked by we evaluate and models trained on data from mint on the publicly available pointrec test collection for point of interest we demonstrate that the ing models outperform several strong baselines and ablated models and match or outperform a llm directly used for ndr in a mint also presents some given our use of historical interaction datasets for generating synthetic training data and the prevalence of popular interests in these datasets tailed interests are unlikely to be present in the generated thetic in causing retrieval models to likely see poorer performance on these our use of llms to generate thetic queries also causes the queries to be repetitive in likely causing novel queries to be poorly these limitations may be addressed in future recsys september singapore zamani table mint ablated for different design choices on pointrec ablation map mrr no item filtering llm for qgen llm for item queries no item filtering llm for qgen llm for item queries besides other avenues also present rich future while mint leverages a llm for generating synthetic smaller parameter llms may be explored for this purpose perhaps by training dedicated qgen mint may also be expanded to explore more active strategies for sampling items and users for whom narrative queries are authored this may allow more cient use of large parameter llms while ensuring higher quality training the generation of synthetic queries from sets of documents may be explored for a broader range of retrieval tasks beyond ndr given its promise to generate larger training sets a currently underexplored given the lack of test collections for ndr and the effectiveness of llms for authoring narrative queries from fruitful future work may also explore the creation of datasets in a setup to robustly evaluate models for acknowledgments we thank anonymous reviewers for their invaluable this work was partly supported by the center for intelligent tion nsf grants and the office of naval research contract number an amazon alexa prize and the chan zuckerberg initiative under the project scientific knowledge base any findings and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect those of the",
    "references": [
        "[1] Jafar Afzali, Aleksander Mark Drzewiecki, and Krisztian Balog. 2021. POINTREC: A Test Collection for NarrativeDriven Point of Interest Recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR 21). As sociation for Computing Machinery, New York, NY, USA, 24782484. https: //doi.org/10.1145/3404835.3463243 ",
        "[2] Jaime Arguello, Adam Ferguson, Emery Fine, Bhaskar Mitra, Hamed Zamani, and Fernando Diaz. 2021. Tip of the Tongue KnownItem Retrieval: A Case Study in Movie Identification. In Proceedings of the 6th international ACM SIGIR Conference on Human Information Interaction and Retrieval. ACM. https://dlnext.acm.org/ doi/10.1145/3406522.3446021 ",
        "[3] Toine Bogers, Maria G\u00e4de, Marijn Koolen, Vivien Petras, and Mette Skov. 2018. What was this Movie About this Chick? A Comparative Study of Relevance Aspects in Book and Movie Discovery. In Transforming Digital Worlds: 13th Inter national Conference, iConference 2018, Sheffield, UK, March 2528, 2018, Proceedings 13. Springer, 323334. ",
        "[4] Toine Bogers, Maria G\u00e4de, Marijn Koolen, Vivien Petras, and Mette Skov. 2019. Looking for an amazing game I can relax and sink hours into...: A Study of Relevance Aspects in Video Game Discovery. In Information in Contemporary Society: 14th International Conference, iConference 2019, Washington, DC, USA, March 31April 3, 2019, Proceedings 14. Springer, 503515. ",
        "[5] Toine Bogers and Marijn Koolen. 2017. Defining and Supporting NarrativeDriven Recommendation. In Proceedings of the Eleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys 17). Association for Computing Machinery, New York, NY, USA, 238242. https://doi.org/10.1145/3109859.3109893 ",
        "[6] Toine Bogers and Marijn Koolen. 2018. Im looking for something like...: Combining Narratives and Example Items for Narrativedriven Book Recommen dation. In Knowledgeaware and Conversational Recommender Systems Workshop. CEUR Workshop Proceedings. ",
        "[7] Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira. 2022. InPars: Unsupervised Dataset Generation for Information Retrieval. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR 22). Association for Computing Machinery, New York, NY, USA, 23872392. https://doi.org/10.1145/3477495. 3531863 ",
        "[8] Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayani Kundu, Ramya Ramanathan, and Eric Nyberg. 2023. InParsLight: CostEffective Unsu pervised Training of Efficient Rankers. arXiv:2301.02998 ",
        "[9] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are FewShot Learners. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ran zato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 18771901. https://proceedings.neurips.cc/paper_files/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64aPaper.pdf ",
        "[10] Chris Buckley and Ellen M. Voorhees. 2004. Retrieval Evaluation with Incomplete Information. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Sheffield, United Kingdom) (SIGIR 04). Association for Computing Machinery, New York, NY, USA, 2532. https://doi.org/10.1145/1008992.1009000 ",
        "[11] DongKyu Chae, Jihoo Kim, Duen Horng Chau, and SangWook Kim. 2020. AR CF: Augmenting Virtual Users and Items in Collaborative Filtering for Addressing ColdStart Problems. In Proceedings of the 43rd International ACM SIGIR Con ference on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR 20). Association for Computing Machinery, New York, NY, USA, 12511260. https://doi.org/10.1145/3397271.3401038 ",
        "[12] Lei Chen, Le Wu, Kun Zhang, Richang Hong, Defu Lian, Zhiqiang Zhang, Jun Zhou, and Meng Wang. 2023. Improving Recommendation Fairness via Data Augmentation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW 23). Association for Computing Machinery, New York, NY, USA, 10121020. https://doi.org/10.1145/3543507.3583341 ",
        "[13] Li Chen, Zhirun Zhang, Xinzhi Zhang, and Lehong Zhao. 2022. A Pilot Study for Understanding Users Attitudes Towards a Conversational Agent for News Recommendation. In Proceedings of the 4th Conference on Conversational User Interfaces (Glasgow, United Kingdom) (CUI 22). Association for Computing Machinery, New York, NY, USA, Article 36, 6 pages. https://doi.org/10.1145/ 3543829.3544530 ",
        "[14] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instructionfinetuned language models. arXiv preprint arXiv:2210.11416 (2022). ",
        "[15] Zhuyun Dai, Vincent Y Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith Hall, and MingWei Chang. 2023. Promptagator: Fewshot 782",
        "[16] Abhinandan S. Das, Mayur Datar, Ashutosh Garg, and Shyam Rajaram. 2007. Google News Personalization: Scalable Online Collaborative Filtering. In Pro ceedings of the 16th International Conference on World Wide Web (Banff, Alberta, Canada) (WWW 07). Association for Computing Machinery, New York, NY, USA, 271280. https://doi.org/10.1145/1242572.1242610 ",
        "[17] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, and Dasarathi Sampath. 2010. The YouTube Video Recommendation System. In Proceedings of the Fourth ACM Conference on Recommender Systems (Barcelona, Spain) (RecSys 10). Association for Computing Machinery, New York, NY, USA, 293296. https: //doi.org/10.1145/1864708.1864770 ",
        "[18] Lukas Eberhard, Simon Walk, Lisa Posch, and Denis Helic. 2019. Evaluating NarrativeDriven Movie Recommendations on Reddit. In Proceedings of the 24th International Conference on Intelligent User Interfaces (Marina del Ray, California) (IUI 19). Association for Computing Machinery, New York, NY, USA, 111. https: //doi.org/10.1145/3301275.3302287 ",
        "[19] Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2022. Precise ZeroShot Dense Retrieval without Relevance Labels. arXiv preprint arXiv:2212.10496 (2022). ",
        "[20] Negar Hariri, Bamshad Mobasher, and Robin Burke. 2013. QueryDriven Context Aware Recommendation. In Proceedings of the 7th ACM Conference on Recom mender Systems (Hong Kong, China) (RecSys 13). Association for Computing Machinery, New York, NY, USA, 916. https://doi.org/10.1145/2507157.2507187 ",
        "[21] Seyyed Hadi Hashemi, Jaap Kamps, Julia Kiseleva, Charles LA Clarke, and Ellen M Voorhees. 2016. Overview of the TREC 2016 Contextual Suggestion Track.. In TREC. ",
        "[22] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bo janowski, Armand Joulin, and Edouard Grave. 2022. Unsupervised Dense Infor mation Retrieval with Contrastive Learning. Transactions on Machine Learning Research (2022). https://openreview.net/forum?id=jKN1pXi7b0 ",
        "[23] Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, and Rodrigo Nogueira. 2023. InParsv2: Large Language Models as Efficient Dataset Generators for Information Retrieval. arXiv:2301.01820 ",
        "[24] Marijn Koolen, Toine Bogers, Maria G\u00e4de, Mark Hall, Iris Hendrickx, Hugo Huurdeman, Jaap Kamps, Mette Skov, Suzan Verberne, and David Walsh. 2016. Overview of the CLEF 2016 Social Book Search Lab. In Experimental IR Meets Mul tilinguality, Multimodality, and Interaction, Norbert Fuhr, Paulo Quaresma, Teresa Gon\u00e7alves, Birger Larsen, Krisztian Balog, Craig Macdonald, Linda Cappellato, and Nicola Ferro (Eds.). Springer International Publishing, Cham, 351370. ",
        "[25] Megan Leszczynski, Ravi Ganti, Shu Zhang, Krisztian Balog, Filip Radlinski, Fernando Pereira, and Arun Tejasvi Chaganty. 2023. Generating Synthetic Data for Conversational Music Recommendation Using Random Walks and Language Models. arXiv:2301.11489 ",
        "[26] Xin Liu, Yong Liu, Karl Aberer, and Chunyan Miao. 2013. Personalized Pointof Interest Recommendation by Mining Users Preference Transition. In Proceedings of the 22nd ACM International Conference on Information & Knowledge Manage ment (San Francisco, California, USA) (CIKM 13). Association for Computing Ma chinery, New York, NY, USA, 733738. https://doi.org/10.1145/2505515.2505639 ",
        "[27] Yiding Liu, TuanAnh Nguyen Pham, Gao Cong, and Quan Yuan. 2017. An Experimental Evaluation of PointofInterest Recommendation in LocationBased Social Networks. Proc. VLDB Endow. 10, 10 (jun 2017), 10101021. https://doi. org/10.14778/3115404.3115407 ",
        "[28] Federico L\u00f3pez, Martin Scholz, Jessica Yung, Marie Pellat, Michael Strube, and Lucas Dixon. 2021. Augmenting the useritem graph with textual similarity models. arXiv preprint arXiv:2109.09358 (2021). ",
        "[29] Xing Han Lu, Siva Reddy, and Harm de Vries. 2023. The StatCan Dialogue Dataset: Retrieving Data Tables through Conversations with Genuine Intents. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, Dubrovnik, Croatia, 27992829. https://aclanthology.org/2023.eaclmain.206 ",
        "[30] Kai Luo, Scott Sanner, Ga Wu, Hanze Li, and Hojin Yang. 2020. Latent Linear Critiquing for Conversational Recommender Systems. In The Web Conference. ",
        "[31] Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. 2021. Zeroshot Neural Passage Retrieval via Domaintargeted Synthetic Question Generation. In Proceedings of the 16th Conference of the European Chapter of the Associa tion for Computational Linguistics: Main Volume. Association for Computational Linguistics, Online, 10751088. https://doi.org/10.18653/v1/2021.eaclmain.92 ",
        "[32] Sheshera Mysore, Tim OGorman, Andrew McCallum, and Hamed Zamani. 2021. CSFCube A Test Collection of Computer Science Research Articles for Faceted Query by Example. In Thirtyfifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). https://doi.org/10.48550/arXiv. 2103.12906 ",
        "[33] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 2773027744. https://proceedings.neurips.cc/paper_files/paper/2022/file/ b1efde53be364a73914f58805a001731PaperConference.pdf ",
        "[34] Andrea Papenmeier, Dagmar Kern, Daniel Hienert, Alfred Sliwa, Ahmet Aker, and Norbert Fuhr. 2021. Starting Conversations with Search Engines Interfaces That Elicit Natural Language Queries. In Proceedings of the 2021 Conference on Human Information Interaction and Retrieval (Canberra ACT, Australia) (CHIIR 21). Association for Computing Machinery, New York, NY, USA, 261265. https: //doi.org/10.1145/3406522.3446035 ",
        "[35] Gustavo Penha, Enrico Palumbo, Maryam Aziz, Alice Wang, and Hugues Bouchard. 2023. Improving Content Retrievability in Search with Controllable Query Generation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW 23). Association for Computing Machinery, New York, NY, USA, 31823192. https://doi.org/10.1145/3543507.3583261 ",
        "[36] Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon, and Ben Wedin. 2022. On Natural Language User Profiles for Transparent and Scrutable Rec ommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR 22). Association for Computing Machinery, New York, NY, USA, 28632874. https://doi.org/10.1145/3477495.3531873 ",
        "[37] Nils Reimers and Iryna Gurevych. 2019. SentenceBERT: Sentence Embeddings using Siamese BERTNetworks. In Proceedings of the 2019 Conference on Em pirical Methods in Natural Language Processing. Association for Computational Linguistics. https://arxiv.org/abs/1908.10084 ",
        "[38] Stephen Robertson and Hugo Zaragoza. 2009. The Probabilistic Relevance Framework: BM25 and Beyond. Found. Trends Inf. Retr. 3, 4 (apr 2009), 333389. https://doi.org/10.1561/1500000019 ",
        "[39] Jon SaadFalcon, Omar Khattab, Keshav Santhanam, Radu Florian, Martin Franz, Salim Roukos, Avirup Sil, Md Arafat Sultan, and Christopher Potts. 2023. UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers. arXiv:2303.00807 [cs.IR] ",
        "[40] Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wentau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022. Improving Passage Retrieval with ZeroShot Question Generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 37813797. https://aclanthology. org/2022.emnlpmain.249 ",
        "[41] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. MPNet: Masked and Permuted Pretraining for Language Understanding. In Advances in Neural Information Processing Systems, Vol. 33. https://proceedings.neurips.cc/paper_ files/paper/2020/file/c3a690be93aa602ee2dc0ccab5b7b67ePaper.pdf ",
        "[42] Jaime Teevan, Susan T. Dumais, and Eric Horvitz. 2005. Personalizing Search via Automated Analysis of Interests and Activities. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Salvador, Brazil) (SIGIR 05). Association for Computing Machinery, New York, NY, USA, 449456. https://doi.org/10.1145/1076034.1076111 ",
        "[43] Mengting Wan and Julian McAuley. 2018. Item Recommendation on Monotonic Behavior Chains. In Proceedings of the 12th ACM Conference on Recommender Systems (Vancouver, British Columbia, Canada) (RecSys 18). Association for Computing Machinery, New York, NY, USA, 8694. https://doi.org/10.1145/ 3240323.3240369 ",
        "[44] Haonan Wang, Chang Zhou, Carl Yang, Hongxia Yang, and Jingrui He. 2021. Controllable Gradient Item Retrieval. In Web Conference. ",
        "[45] Qinyong Wang, Hongzhi Yin, Hao Wang, Quoc Viet Hung Nguyen, Zi Huang, and Lizhen Cui. 2019. Enhancing Collaborative Filtering with Generative Aug mentation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD 19). As sociation for Computing Machinery, New York, NY, USA, 548556. https: //doi.org/10.1145/3292500.3330873 ",
        "[46] Jiajing Xu, Andrew Zhai, and Charles Rosenberg. 2022. Rethinking Personalized Ranking at Pinterest: An EndtoEnd Approach. In Proceedings of the 16th ACM Conference on Recommender Systems (Seattle, WA, USA) (RecSys 22). Association for Computing Machinery, New York, NY, USA, 502505. https://doi.org/10. 1145/3523227.3547394 ",
        "[47] Yuxin Ying, Fuzhen Zhuang, Yongchun Zhu, Deqing Wang, and Hongwei Zheng. 2023. CAMUS: AttributeAware Counterfactual Augmentation for Minority Users in Recommendation. In Proceedings of the ACM Web Conference 2023 (Austin, TX, USA) (WWW 23). Association for Computing Machinery, New York, NY, USA, 13961404. https://doi.org/10.1145/3543507.3583538 ",
        "[48] Hamed Zamani, Johanne R Trippas, Jeff Dalton, and Filip Radlinski. 2022. Con versational information seeking. arXiv preprint arXiv:2201.08808 (2022). ",
        "[49] Jie Zou, Yifan Chen, and Evangelos Kanoulas. 2020. Towards QuestionBased Recommender Systems. In Proceedings of the 43rd International ACM SIGIR Confer ence on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR 20). Association for Computing Machinery, New York, NY, USA, 881890. https://doi.org/10.1145/3397271.3401180 783"
    ]
}