{
    "url": "https://drive.google.com/file/d/1YJCgV7h1q7FZOHjHriaooh1yHCFJjTb6/view?usp=drive_link",
    "publication_date": "27-03-2023",
    "title": "The Programmers Assistant: Conversational Interaction with a Large Language Model for Software Development",
    "authors": [
        "Steven I. Ross",
        "Fernando Martinez",
        "Stephanie Houde",
        "Michael Muller",
        "Justin D. Weisz"
    ],
    "institutes": [
        "IBM Research AI Cambridge, MA, USA",
        "IBM Argentina La Plata, Buenos Aires, Argentina",
        "IBM Research AI Yorktown Heights, NY, USA"
    ],
    "keywords": [
        "code-fluent large language models",
        "foundation models",
        "conversational interaction",
        "human-centered AI"
    ],
    "abstract": "Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the models responses. We developed a prototype system \u2013 the Programmers Assistant \u2013 in order to explore the utility of conversational interactions grounded in code, as well as software engineers receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.",
    "content": "introduction software development is a highly skilled task that requires and creativity many techniques have been developed to enhance the productivity of software such as advanced code repositories knowledge repositories sites and pair programming practices collaborative software engineering is especially given that professional software development is rarely a solo activity and relevant knowledge and expertise are typically distributed widely within an organization many efforts have focused on incorporating collaborative technologies into software development environments the pioneering work of rich and waters on the programmers apprentice presented a novel concept of a knowledgeable automated assistant in an artificial collaborative partner that could help software engineers with writing designing software and creating requirements at the ai technologies and computing resources were not sufficient to fully implement their in the intervening an increase in computational the availability of large corpora of language and code and the development of deep neural networks have made new approaches to achieving their goals worth models leveraging the transformer architecture have been developed to perform software engineering such as translating code between languages generating documentation for code and generating unit tests for code talamadupula and allamanis et for recently developed foundation models large language models that can be adapted to multiple tasks and which exhibit emergent behaviors for which they have not been explicitly trained have also proven to be capable with source iui march australia ross et while the intent of training llms such as and was to give them mastery of natural it quickly became apparent that the presence of code in their training corpora had given them the ability to generate code based on natural language descriptions the codex model was then produced by tuning on a large corpus of source code leading to the development of copilot a tool that helps software engineers by autocompleting code as it is being experimentation with copilot has shown its ability to perform additional such as explaining generating and translating code between languages although autocompletion interfaces are useful and valuable when the system can discern the there are many instances where that is for the developer may have a good idea of what they want to but may be unclear on what or even algorithms to they may even have general programming questions that need to be answered before they are able to write any in this we seek to understand whether modern ments in foundation models large language models that have been on source code data are sufficient to support a conversational agent that can act as an assistant in the software development we developed the assistant to explore the capabilities that conversational interaction could enable and the extent to which users would find tional assistance with programming tasks desirable and we hypothesize that a conversational system may provide a flexible and natural means for interacting with a conversational interaction could enable users to pursue their tions in a multiple exchange dialog observed by barke et that allows them to ask questions and refine their a conversational programming assistant could ask the user clarifying or disambiguating questions to help it arrive at the best it could also provide multiple types of assistance to the user beyond simply generating code such as engaging in general discussion of programming topics or ing users improve their programming skills observed in other studies of automating technologies our paper makes the following contributions to the iui we provide empirical evidence that a conversational gramming assistant based on a foundation model provides valuable assistance to software engineers in a myriad of by answering general gramming by generating by enabling the model to exhibit emergent and by enabling users to ask questions that depend upon their conversational and code we show how different interaction models direct and search provide complementary types of support to software engineers with tradeoffs tween the focus and the relevance of port to their code the provenance of that and their ability to ask we motivate the need to further understand how to design ai systems that enhance the joint mance of the related work we discuss three areas of related work that have either motivated our study of conversational programming assistance or provided the technical foundations for we begin by briefly summarizing rich and visionary work on the tice followed by summarizing work on foundation models and evaluations of how these models pact software we discuss conversational interaction and how it might be employed to provide more flexible and sophisticated assistance to software the apprentice our work is inspired by the vision laid out by rich and waters which describes an artificial agent that can act as an intelligent sistant for software engineers by providing catching and handling routine details throughout the software development the apprentice relied on a knowledge base of which are structured versions of what are known today as software design patterns it used a brid reasoning system capable of reasoning based on frames and a plan along with general purpose logical although natural language interaction was the original prototype implementation ultimately used a stylized command we view our work as a conceptual successor to the as it enables the natural language interaction that the apprentice foundation models and evaluations of programming assistance generative models based on the transformer architecture have recently been applied to the domain of software fluent large language models are capable of generating code from natural language descriptions translating code from one guage to another generating unit tests and even ating documentation for code these models are probabilistic and as do not always produce perfect results code that is free of syntax or logical weisz et found that software engineers are still interested in using such models in their and that the imperfect outputs of these models can even help them produce code via collaboration new tools based on llms are actively being github is described as ai pair it is optimized for the code autocompletion use given a starting snippet such as a or partial copilot completes the copilot is based on the openai codex model a billion parameter sion of on code samples from million public software repositories on empirical evaluations of the assistant iui march australia this model have shown although the quality of its outputs is quite those outputs may still be problematic echoing the results from weisz et evaluations of lot have found that it increases feelings of productivity and that almost a third of its proposed code completions were accepted by in a contrasting vaithilingam et found that while most participants expressed a preference to use copilot in their daily it did not necessarily improve their task completion times or success in a study by kalliamvakou developers working with copilot were able to implement a web server in javascript faster than developers who did not use a grounded theory analysis of how programmers interact with copilot found that their interactions varied depending upon whether they were accelerating tasks that they already knew how to do or if they were exploring solutions to problems that they were less sure autocompletion was effective when developers were operating in and relied on the model to produce short completions that could be verified in the interaction was more developers would communicate with copilot by typing comments and seeing what copilot generated in they would modify their comments to explore other ways of prompting a the comments used to prompt the model would be deleted after the relevant code was indicating that their value was largely in driving a yet context dialog with the model to coerce it to produce the desired results through an iterative refinement in this we fully commit to a conversational style of interaction with a llm and assess the value it provides to conversational interaction and analysis conversational using natural language to act with technology has had a long research history starting in the with approaches like eliza and continuing to today with large language based conversational systems such as meena and bot these systems are intended to address the problem of with a goal of realistically engaging in but not particularly in a or chatbots are typically built with frameworks such as the microsoft bot google and ibm watson they operate using dialogue trees and use natural language processing to detect conversational intents and extract contextual this structure enables the creation of special but fairly limited and conversational there have been several recent attempts to investigate sational programming kuttal et conducted a wizard of oz study in which a pair programmer was replaced with a conversational and they found that can act as fective pair programming the pact system is a chatbot that assists programmers adjusting to new programming pact is structured as a discrete system based on a neural machine translation but it maintain a conversational conversation conversation is a form of interaction between people that enables robust conversation analysis is a method for understanding the natural structure of human conversational it catalogs different patterns of conversational acts and how they are utilized by interlocutors in order to attain a wide variety of conversation ysis has been adapted to describe patterns of interactions between humans and artificial conversational agents in order to aid in the design of chatbots we apply techniques from conversation analysis in our study of conversational programming the assistant in order to explore conversational programming we created a functional prototype system called the our shown in figure combines a code editor with a chat the code editor was implemented using the microsoft monaco embedded in a react the chat user interface was implemented using the to drive the conversational we employed codex model accessed through its web we developed our prototype as a lightweight coding ment in order to examine the user experience of interacting with a conversational our work was exploratory in and thus we did not have specific design goals for the prototype beyond integrating a code editor with a we also did not attempt to target the prototype for a specific class of users novices or or use cases writing code learning a new programming as we wanted any value provided by conversational assistance to emerge from our user we also did not implement the ability to run or debug code in our prototype as we wanted to explore the nature of the conversational tion rather than having users focus extensively on the production of working when designing how users would interact with the we decided that it should be available on demand and not monitor the work in progress or give unsolicited suggestions or in keeping with the conversational agent interaction model proposed by ross et this approach was supported by feedback from prospective users who were cerned about the assistant providing criticism of unfinished efforts in progress or distracting them while they we force initiative onto the user and only have the assistant respond to their in this the assistant can provide help when requested without undesirable interruptions that can distract or interfere with the when a user interacts with the we keep track of their selection state in the code if a user sends a message to the assistant without any code selected in the then that message with the prior conversational is passed directly to the if a user sends a message to the assistant with new code iui march australia ross et selected in the editor code that previously selected when they sent their last then that code is appended to the message before being communicated to the the model may produce multiple types of responses to a we treat each type of response differently in the responses that do not contain code are always rendered in the chat ui responses containing short code snippets are rendered inline in the chat ui responses containing longer code snippets show the code in a window with a proxy entry in the chat transcript that allows users to display the code window after it has been text in the response remains in the chat the assistant never directly modifies the contents of the source any code the user desires to transfer from the chat takes place via figure shows a screenshot of a sample in which the user asks a question that results in an inline then requests an explanation of some code in the and then quests further figure shows an example conversation that resulted in the generation of a longer code shown in a popup this example shows how the assistant produced an incomplete followed by criticism from the user regarding the missing and resulting in an apology and the generation of a complete supporting conversational interaction we enabled codex to conduct a conversational interaction by ing it with a conversational transcript and a request to produce the next conversational the prompt establishes a pattern of conversation between a user and a programming assistant named it provides several examples of socrates responding to eral coding generating code in response to a and accepting code as it establishes a convention for delimiting code in the making it easy to parse for display in the it also establishes an interaction style for the directing it to be and and to present its sponses in a because of the possibility that the model might produce erroneous answers or incorrect code discussed in weisz et we felt it was important that the assistant convey a sense of uncertainty to encourage users to not accept its results uncritically to avoid as observed in moroz et study of copilot and discussed more ally in ashktorab et as well as automation bias we present the full text of the prompt used for the assistant in appendix architecture ui design the assistant communicates with the codex api via a proxy server that forwards requests from the react the proxy also access to conform to the and it logs ui events from the client and ui use of responses was encoded into the llm output token probabilities from the llm were not utilized to influence the in a to address inconsistencies in the style or formatting of code generated by the proxy server reformats all code segments using the black code formatter before transmitting them to the client the client maintains the transcript of the ongoing each time the user sends a message in the the client constructs a new prompt for the model by concatenating the initial the chat and the new and makes a quest for the model to complete the this completion request also specifies a stop sequence of tokens to prevent the model from generating both sides of the conversation what the model thinks the next utterance might be after the given the limitation on context length tokens for both the prompt and model we silently older exchanges in the chat transcript when constructing the prompt to ensure that our completion request remains within the entire conversational history remains visible to the user in the the client ui provides a loose coupling between the source code editor and the chat users can hide the chat pane when they wish to focus solely on their and with it when they desire code selected in the editor is included in the conversation in order to couple the code context with the buttons are provided in the ui to copy code responses from the assistant to the handling model limitations while developing the and in early pilot we experienced some quirks and shortcomings of the model and our approach to using it for conversational one limitation stemmed from the fact that the model sometimes duced incorrect responses code with syntax incomplete responses code that was missing irrelevant sponses responses not related to the or stantial responses because of the probabilistic nature of model the model would times produce a more correct or appropriate we added the ability for users to either by asking in the chat or by clicking a button in the ui this feature removes the last response from the context presented to the model and then the model with an increased although it is possible for transformer models such as codex to produce multiple possible responses to a single we only request a single response in order to speed up response time as well as to preserve the token budget for conversational the feature provides an alternate way to produce a wider variety of during pilot we noticed that the assistant sometimes happened to generate the same response to unrelated in these the assistant tended to get in a pattern of repeating the same response and was unable to resume normal to avoid this we automatically execute a is a parameter in a generative model that specifies the amount of variation in the generation higher temperatures result in greater variability in the the assistant iui march australia a b h g f e c d figure the the user interface provides a code editor on the left and a chat pane on the right the button allows users to ask the assistant to generate an alternate response to the most recent the button resets the conversational context for the but maintains the chat transcript in the in this we show the assistant introduce itself to the user the user asks a general programming question for which the assistant provides an inline code response the user then asks a question about code selected in the editor followed by a series of operation in the background when we see identical consecutive responses from the we noticed that the accumulation of conversational text sometimes resulted in the assistant becoming fixated on some portion of the earlier for it might respond to a question with portions of the prompt or of earlier and become less responsive to newer to address this we introduced a accessible via the chat or by clicking a button in the ui that resets the context to the original forgetting the rest of the conversational we preserve the chat transcript in the but delineate the break in the memory with an annotation in the chat these annotations are added both for and sample conversation we provide a real sample conversation with the assistant in listing this conversation begins with the assistant greeting the user the user asks a general python programming question to which the assistant responds with a remark and a code snippet the user next asks a question that depends on their previous question and the response to which the assistant provides another code snippet satisfying the the user then switches topics and asks the assistant to write a fibonacci function and the assistant again responds with a remark will give it a line and a block of the user then asks how the function works and the assistant provides an adequate description iui march australia ross et figure code long code responses are presented in a window with a button to copy the code and close the this code can be from the chat transcript by clicking the proxy icon the user asks the assistant to the function in a different way again leveraging the ability to ask the assistant produces an alternative implementation that conforms to the request the user follows up with a question that depends on multiple past utterances and sponses in the chat transcript and the assistant produces a relevant response the conversation closes with the user thanking the assistant and the assistant acknowledging their gratitude listing a conversation with the code presented by the assistant is listed in bold my name is socrates your programming what can i help you with how do i get a list of the keys in a python i think you would do something like what if i just wanted to iterate over i think you would do something like for key in write a function that returns the nth value in the fibonacci i will give it a def if n return elif n return return how does this the fibonacci sequence is defined by the recurrence relation this function implements that recurrence can this be done without the assistant iui march australia i think how about def for i in return which version is i think the recursive version is more elegant but the iterative version is more you empirical study of conversational programming assistance we conducted an empirical user study of the tant to assess whether conversational assistance provides value in a software engineering our inquiry focused on the user experience and value of conversational interactions grounded in we therefore designed a qualitative study to investigate tudes toward a conversational programming do people enjoy interacting what kinds of questions do they and how does the experience compare to other forms of gramming support such as searching the we note that prior studies conducted quantitative examinations of the use of llms in code our study is akin to weisz et qualitative examination of software attitudes toward working with models that may fail to produce working code to address our we deployed the tant within our organization a global technology company and invited people to try it out and give us feedback on their we invited people with varying levels of programming skill in order to obtain a wide range of feedback on the kinds of use cases for which the tool could provide tasks we set up the assistant as a playground environment that participants could try out with a few sample programming we created a tutorial to orient participants to the its and how to interact with we also created four programming challenges focused on writing ing and writing tests for we designed these challenges to expose participants to a broad range of the for each of these we explicitly did not evaluate metrics such as the the quality of their or the time taken to produce as the focus of our study was to understand the utility of conversational we selected python as the language used for the tutorial and challenges because of its general popularity and the fact that it was by our underlying llm all participants were first introduced to the assistant through a the tutorial walked each historical we note that our study was completed before the public release of chatgpt which has subsequently demonstrated the application of conversational assistance for programming tasks participant through sample interactions to give them a feeling for what the assistant could do and how to interact with the tutorial demonstrated how to ask how to request code to be and how to evaluate existing it did not cally cover how to generate documentation or unit tutorial instructions were provided within the code we include the specific text used for the tutorial in appendix programming after completing the ticipants unlocked four programming two of the lenges involved coding problems a queue class and writing code to create a scatterplot of data in a csv one involved umenting a given function implementation of a graph search and one involved writing unit tests for a given tion the greatest common divisor of two although the assistant was visible and available for we provided no specific requirement that it actually be used to complete the after participants completed their solution to a they submitted it by clicking a button in the the code editor used in the assistant was not a ide and did not provide syntax checking or the ability to or debug due to these participants were asked to submit their solutions when they felt they had completed the challenge to their own participants to recruit participants for our we posted internal ments in various communications channels focused on software our advertisements stated that we were evaluating a conversational programming but were kept deliberately vague in order to minimize the impact on expectations of the our advertisement yielded a pool of potential in order to recruit a diverse we used a screening survey that asked about their job their familiarity with and recency of use of and their availability to participate in our we accepted participants into the study on a rolling selecting participants to capture a range of programming experiences and ensure balanced gender we conducted periodic views to determine whether we were learning something new from each participant or if we had reached the point of saturation we stopped collecting data after running participants as we were no longer observing any new behaviors or gleaning any new the assistant implementation and configuration were held constant over the course of the no changes to the ui design or llm prompt were our participants had the following job software software data machine learning systems test business and gender variant and preferred not to python participants had years of python had had less than and were not familiar with iui march australia ross et recency of python participants had written python code within the past within the past within the past and had not written python code within the past we provide full demographic information for individual pants in appendix procedure participants completed the study on their own independently and without each participant was provided with a web link to a survey that described the nature of the study and the tasks that they would be expected to they were then directed to the assistant to complete the tutorial and the four programming when participants indicated they were finished with the they were directed to a final complete sessions generally required about an hour of though some participants spread their effort across a longer period of time and across multiple participants were compensated for their time at a rate equivalent to us measures we collected a variety of data in our study from three we employed three surveys in the a study survey to collect demographic a survey to gauge expectations of the conversational user and a survey to assess actual user we describe these survey questions in the relevant context of our and we provide a complete listing of all survey instruments in appendix event the assistant was instrumented to collect data on the event logs vided timestamped records of interaction including conversational the use of the and and use of conversation from the event we extracted versational transcripts between each participant and the results data analysis we collected a wealth of data in our survey responses from three surveys per containing written ments in survey and instances of different types of ui including conversational in the event we also for each counts or durations for different metrics from the event in our we deliberately exclude the portion of our data collected during the tutorial we exclude this data because that activity was guided by the tutorial not by our own our final sample consists of did not enforce that participants actually complete all of the all participants but one did submit solutions to all of the refer to a followed by the as a conversational including conversational exchanges in the event no survey data was our primary analysis of this data is as our pants provided us with a rich source of interesting feedback and insights in their where we supplement this data with quantitative data from the survey and the event as well as chat transcript data from the versation in this we triangulate across our three data using the survey data as a when we quote either from their qualitative survey responses or the conversational we reproduce their words exactly as including cal and potential trigger and we only make minor clarifying edits where delineated by square in order to set the context for our we first describe how we used reflexive thematic analysis to analyze responses to the survey we then describe our analysis of the conversation logs and our development of a coding guide based on conversation analysis and moore and natural conversation framework thematic analysis of qualitative survey we ducted a reflexive thematic analysis to analyze the responses to our seven survey we followed the process described by braun and clarke in which researchers immerse themselves in the generate codes for material that seems and then iteratively group and refine codes through collaborative discussion in order to identify four authors performed on the survey through these codes were grouped and consolidated into a single which were then to the data by two after another round of these authors identified a set of some themes had clear parallels to quantitative survey questions or event log and thus represented clear instances where we were able to gulate across data other themes surprised we structure our presentation of the results based on these grouped into three different aspects of the user expectations and utility of conversational and patterns of interaction and mental conversation analysis via the natural conversation in order to understand the content and structure of the conversations that took place between our participants and the we turned to the natural conversation framework we developed a codebook for the event beginning with different categories of utterances from the nine ncf categories expression of welfare and welfare report appeared twice in our book to distinguish cases in which the utterance was made by the human participant the other ncf categories were split to provide nuanced detail about the for we distinguished three different kinds of ncf depending upon whether they were stated as requests for action commands of action a function or expressions of desire we also added additional the assistant iui march australia interlocutor orientation codes human social expression of self small welfare welfare report task asks asserts capability command of expression of fies request for requests requests explanation meta ui chat context copy erroneous includes includes extraneous missing paste pasted code in spelling start try again assistant appears claims grants request grants request offers provided wrong requests requests response includes spews garbage table event log our codebook contained unique applied separately to participant utterances and assistant responses codes in bold were applied to both participant and assistant human codes were classified as demonstrating either a social or task orientation to the codes to identify such as utterances that included utterances that referenced selected utterances that plicitly or explicitly referenced earlier portions of the or ui activities such as and invocations of and we classified a subset of the codes based on whether they represented a task or social orientation toward the we list our codes in table but note that not all of them ended up being relevant to our when coding conversational we applied individual codes at the level of each conversational we allowed multiple codes to be applied to each utterance to account for utterances that performed multiple functions greeting and in order to ensure consistency in how our codebook was two authors coded a sample of the conversational achieving a satisfactory level of reliability \ud835\udefc where agreement was conservatively defined as having all of the same codes applied to both utterances in a conversational expectations and experience pilot testing of the assistant suggested that software engineers would be skeptical of a conversational programming assistant and its ability to provide useful our study revealed for most their actual experience after using the tool was better than they had participants were surprised at the quality of the responses and they appreciated how its integration with the code editor reduced the amount of context switching they needed to do in the some participants struggled with the code selection although others appreciated the ability to ask questions related to selected all of our participants engaged with the assistant while working on the despite there being no requirement to do participants submitted solutions to all four and one only mitted solutions for one of the four participants spent an average of minutes engaged with the as measured by the amount of time the assistant window was in participants made an average of utterances to the on of their utterances contained a code the average latency per was seconds we saw a rate of acceptance of generated where we considered code to be accepted if the participant performed a copy immediately after the code was this acceptance rate is much higher than the acceptance rate reported for copilot we believe one reason we observed a higher acceptance rate is because completion suggestions are generated whereas the suggestions are generated upon when copying generated code from the participants most often copied the entirety of the generated and only in of cases did they copy a smaller portion of user experience expectations changed prior to running our we had reason to believe that participants would be skeptical of a conversational programming before veloping the we showed potential users mockups of a program editor with an integrated chatbot these prototypes elicited uniformly negative people told us about their frustrating experiences with conventional chatbots and raised doubts about the and value of a conversational programming this skepticism vated us to develop the assistant in order to evaluate whether the conversational as powered by a would be better than people had during pilot we received feedback that the assistant provided a much better conversational experience compared to previous experiences with in designing our we felt it important to first gauge expectations of a conversational interaction around and then measure their experience after the time includes additional time added by our proxy server to ensure our mance to the api rate iui march australia ross et we developed a short inventory of six scale items to measure user experience of code the scale was administered once before participants were exposed to the assistant after they had been briefed that they would interact with an ai and once after completing the programming the items were presented with the appropriate do you expect you find the will be easy to will understand your will provide high quality will help you to write better will help you to write code more will be enjoyable to each item was rated on a scale of not at all a little somewhat a great deal a factor analysis revealed the items on this scale measured a single which we identify as user experience \ud835\udefc we computed two scores of user experience for each a ux score computed as the average of their six expectation scale and a ux score computed as the average of their six experience scale we found that participants had lower initial expectations for their experience with a conversational programming assistant task ux m of than their experience actually was ux m of a paired sample shows that this difference was \ud835\udc5d \ud835\udc51 measured another participants had ux ratings that were higher than their task demonstrating a significant shift in attitudes toward conversational programming the ux ratings alone fail to capture anced expectations of the assistant and the reasons for their shifted attitudes after using participants expressed a variety of tions of the assistant before using including that it would be easy to use and produce correct responses understand the problem and what is being asked of it not interfere with their flow state produce imperfect or questionable puts improve with feedback provide generic and unhelpful answers or only answer basic questions and produce responses quickly expected be frustrated very quickly and that what think would be relatively common questions would be responded to with unhelpful have very good experiences with i think need to spend more time in reviewing and fixing the suggestions than in writing the code myself from had a more balanced that do some tasks really but others will not be as after interacting with the many ticipants commented on how the experience was better than they because it to be able to handle complex and a great felt it was and who were both initially reported having a positive for absolutely exceeded all my in scale items were modeled from scales published in weisz et table ai that measured constructs including ease of use response quality the production of code and the ability to write code more rapidly we added additional items to cover the constructs of request understanding and and we cast all items on a scale of all aspects that i could have imagined and provided a more quantitative was emphatic in their was blown away how well it allowing me to structure how i want the code to look and work and just giving me the thing i asked many participants described a sense of surprise in their was surprised by how well it understood their was surprised at how well the programmer assistant was able to understand my requests and generate good it understood major concepts and was able to explain it to me in a clear and it was also able to understand and write functional it even was able to help me review my i was also surprised at how well it could understand the context of what i was asking in questions when i did not specify exactly what i was talking but rather referencing our prior conversation does that was surprised that they liked the conversational interaction when they expected that they i like the chatbot interaction and that i would prefer something like the tool seen in those demos but after using the chatbot seeing the easy to it derstands i felt it like a i like this kind of quality of in order to gauge the quality of responses produced by the we examined the requests made by participants in the for the vast majority the assistant produced a correct sponse request in other the response was incorrect provided wrong correct but incomplete grants request or the assistant understand claimed ignorance of the subject claims or produced another type of response appears spews participants also reported experiencing this variability in the quality of the some participants described how the assistant provided and ity that were felt it was to see the quality of the and even explored the capabilities outside the scope of the challenges and found that it could handle those as was surprising the quality of the code and the ability to answer all my questions although i think the challenges may be biased towards what the assistant is able to it was a great experience because i asked many other things and it was able to answer of the assistant and some participants did run into for documentation ation did not perform very questioned the accuracy of the knowledge encoded in the the model need to be it said latest python version is but google says in some participants needed to ask their question multiple the assistant iui march australia times to get a good need to ask many times if you want to get an answer and also a detailed was annoying when i asked it to try again and it would give me the same struggled seem to handle multiple sentences perhaps offered the most scathing makes mistakes often enough to be not very despite the production of other participants felt that the assistant was still reported minor tweaks were normally needed to correct any described how the assistant able to completely solve their but provided a useful was only one hickup i noticed where when i asked it to memoize fibonacci it but it dropped the building blocks on my lap for me to finish so that was that was like minutes of effort on my ui design participants made many comments on our specific ui design and the affordances provided not in our the integration between the chat pane and the code editor was with a interface between the code pane and the assistant that it really prior research by brandt et has shown how keeping developers focused in their ide improves and our participants expressed similar allows me to stay in one browser and hinted at how the interface might preserve their flow state by me from getting distracted when looking into an issue in another some aspects of our user interface were confusing to such as the mechanism for selecting code to be included in the conversational was a little confusing doing the selection part for it to tell me what a function it gave me code that was insanely easy to copy and other participants appreciated the code selection such as enjoyed the code selection and found that very easy to in the event we identified instances in which a participant unintentionally included selected code in the conversation when it needed extraneous instances in which a code selection was omitted when it was needed to provide context for the question and instances in which a participant code directly into the chat rather than selecting it in the editor code in although these cases represent a small fraction of the instances in which a code selection was required and included in the conversation their presence does indicate that more attention is needed to the interaction design of code another issue regarded the awareness of the and the feature was only used by who used it a total of times over the course of the some participants used it specifically when they got an answer which they saw as clearly while others used it to get a variety of possible answers before the feature was used even by participants who used it a total of despite our effort to surface these conversational features in the ui via shortcut they may not have been sufficiently noticeable or button is not so often times i forgot it by at least one participant was successful with these some point it had issue with challenge and i had to start just asking was not enough and i was getting always the same and not starting again solved the utility of conversational assistance our next set of themes concerns the utility provided by tional programming participants felt the assistant was highly valuable and desired to use it in their own they felt it would be most helpful for smaller or but able to provide a wide variety of types of the fact that the interaction model was conversational and grounded in code were valuable as was the ability for the assistant to bolster learning about programming topics through that participants did question whether they could trust and rely upon the echoing a similar theme discussed in weisz et value appropriate participants rated the value of the assistant highly of many participants asked questions such i have it in my editor or made comments would enjoy using it in the would love to be able have access to it for my and love to use this tool as part of my usual programming workflow if i some of the reasons why participants found it valuable are because it me remember how to do things in certain languages that normally i would just and helps me to avoid silly syntax errors and can when i cannot remember exact names and required we did not observe any differences in value ratings based on familiarity with or recency of using participants described a wide variety of tasks for which they felt the assistant would be these tasks included and tasks such as for chunks of or for participants also felt the assistant was useful for containable novel and coding several kinds of task assistance were reported as being such as explaining code implementing business logic in a ui understanding what code does and recalling language method and arguments felt that the assistant was helpful when recognizing a specific well known algorithm but not things you make participants also made recommendations for how to increase the value of the would blow me away though is if able to help with what i do most often which is to refactor and iterate on an existing and all desired more information on the data sources used to produce the requested to the assistant examine your code and make proactive suggestions for improving it in the requested the iui march australia ross et but cautioned would need to be taken to avoid becoming an annoyance or disrupting the flow of a coding in the we probed participants on how certain changes to the assistant would either or result in no change to its over of participants felt that the assistant would be more valuable if it operated in a proactive either by making improvement suggestions in the chat or as comments directly in the of participants felt that having more buttons in the ui for common features such as explaining or documenting code would make the tool more conversational interactions grounded in one of the challenges in interpreting comments about the utility of the assistant was in disentangling the extent to which value was derived from the quality of the underlying model versus the integration of conversation in a code participants felt that the chat interaction was of participants felt that eliminating the conversational interaction and making the assistant behave more like web search would crease its our analysis of the conversation transcripts revealed that of the utterances from ipants required historical conversational context context in order to be correctly we observe that participants did rely on conversational context in their in the of participants rated the importance of the ability to ask questions as being or great several participants specifically commented on the value of this conversational absolutely loved how you can straight up ask questions to the assistant without having to reiterate the original expressed a similar think the conversational context was someone just in communicating that a running conversation where my context is provided a similar tool was so helpful at answering questions i had about the code in the context of the code i am working i was also impressed with how well it was able to remember the context of our especially when i asked vague in some participants identified how a conversational interaction grounded in code was i think to the dev context could be very in of utterances included a relevant code selection showing that participants valued this contrasting with these felt that interacting with the assistant conversationally was and they employed a more direct really like the i converse with it like a chat i often told it what to do this as opposed to asking it what to do do i document this talking to it the way that was suggested in the tutorial seemed overly despite these individual differences in interaction envisioned that both interaction styles could be supported in the think both options should people should be able to input their queries like a search bar and also give their question as if in learning one specific benefit of the assistant identified by participants is its ability to help people improve their programming skills and reinforce knowledge for it can help users how to do things in certain such when i am using a language i used in a the assistant can also serve as an memory such as when use a lot of libraries that i always remember all of the matter how good as a you remember all the api of hundreds of libs or new learn new dev lang and new felt the assistant perfect for programmers of all and felt it could help them rapidly improve their python have wanted to learn the main concern how much time spent learning is needed before i could actually get some value out of learning i have a feeling this would cut that time down from weeks to a day or also identified the fact because the interactions with the assistant are it forces people to learn how to communicate to others about their conversation aspect promotes proper which would really stand to benefit budding programmers if they want to learn how to explain cepts more fluently in the future to their suggested that on programming assistance might have a detrimental effect to definitely a huge time but on it may cause new developers to skip learning the reference material themselves and discovering new things and sparking new many participants raised questions about whether they could trust the responses provided by the asked this question most the code be other participants raised similar such wondering how it validates if it can be trusted to always give a working and lack of source and context may raise doubts in the mind of the these issues of trust were exacerbated by the fact that the assistant did not allow participants to actually run their because of this participants had to rely on their own knowledge to judge the correctness of the is no way to evaluate if the sistant is giving you the right advise or not other than your own and had to trust that it was correct use my own prior the assistant iui march australia described the potential consequences of allowing the tant to write code for only thing that made me nervous was that it could have introduced a bug that immediately and given i write the i could have easily glossed over a mistake when reviewing especially if it is also the one writing the test despite our efforts to make the assistant respond in we did observe participants sometimes uncritically accept generated results that were clearly wrong or we did find behavioral evidence for listing building trust through explanations and tions what is a unit a unit test is a test of a single function or it is typically written by the programmer who wrote the def while b a return a how would i write a unit test for this i think you would do something like def assert assert assert assert what is a euclid function the euclid function is a function that computes the greatest common divisor of two is this a good unit test for a euclid function i believe that it is a good unit test for a euclid why it seems to me that it tests the edge cases of a and b being equal a being greater than and b being greater than thanks socrates this was helpful always happy to one way to address trust issues is for the assistant to provide further explanations and justifications that can calibrate a confidence in the such explanations could be requested though most participants did not attempt to do one participant did ask for such and we show a summary of their transcript in listing in this asked for a definition of a unit test an nation of the code being tested and justifications of the quality of the unit test we observe that the assistant is capable of producing explanations and justifications when patterns of interaction and mental models participants interacted with the assistant in a variety of ways with two main patterns of usage standing invoking the tant to solve the entire programming and breaking the challenge down into a set of smaller tasks and invoking the help for there were no clear differences in how participants with differing python experience approached the mental models of the assistant also although participants strongly saw the role of the assistant as being a their behaviors revealed that in many they actually treated it as a social in participants ascribed various mental capacities to the such as having the ability to and participants felt the assistant changed the nature of their work for some it enabled them to focus on the aspects of development because the assistant handled details or provided partial solutions for them to build many participants felt the assistant sped up their work and helped them remain focused on their participants drew comparisons between the assistant with other forms of programming support such as copilot and web they felt that the conversational style of interaction enabled them to discover emergent behaviors from the model that were unavailable from focus on code they also felt that the examples provided by the assistant were more readily usable within their own code compared to browsing for answers within search speeding up the coding some participants advocated for a anced approach to the design of programming assistance tools by incorporating multiple modes of interaction rather than fixating on a single interaction styles and assistant we observed that ticipants interacted with the assistant in strikingly different some participants would present the entire lenge description to the assistant and then work with the results it other participants approached the programming lenges in a piecemeal breaking them apart into a set of smaller then invoking the assistant to aid with each experience with python was not a determinant of how pants approached the programming but it did seem to impact how participants interacted with the less enced participants tended to ask the assistant basic questions such is a unit not familiar with and do i document a year of more rienced participants made detailed requests about specific python libraries or such a pandas dataframe with two columns and please use matplotlib to draw me a years of and a kutta algorithm for solving an ode with adaptive time years of another difference we observed in how people interacted with the assistant stemmed from their view on the role it played in their iui march australia ross et collaborative some such as treated it more as a tool by issuing commands rather than asking as quoted they converse with it like a chat described their interaction style found myself wanting to type search queries into not treating it as a person but as a search in anticipation that participants would have different tions to the assistant and its we asked a question on the task survey about the different kinds of roles the assistant might these roles generally fell into one of two a tool orientation a reference a content a problem and a social orientation a a an a participants rated the extent to which they viewed the assistant in each of these roles on a point scale of not at all a little somewhat or a great deal tool content generator reference guide collaborator problem solver advisor coach reviewer colleague role percentage of participants rating not at all a little somewhat a great deal figure role participants overwhelmingly felt that the role was of a tool orientation rather than a social the chart shows ratings distributions across different roles the assistant might sorted by the percentage of participants who rated the extent of that role as great the leftmost role is of a with of participants rating it as great following tool are content generator reference guide collaborator problem solver advisor coach reviewer and colleague we show ratings of the role in figure despite the fact that their attitudes toward the assistant ingly reflected a tool their behaviors reveal that many participants actually treated the assistant as a social scribed how felt it like a and told the could not have solved without your to which the assistant glad i could the literature on computers as social agents helps us interpret this result as it demonstrates how computers are often treated like people conversational agents can exacerbate this as they likely have been trained on amples of social they can also respond as social in the conversation we identified participants who acted with the assistant in a fashion social orientation codes in table twenty participants made at least one an extreme form of this action style can be seen in a snippet from transcript the participants with a social orientation did not generally differ in their role ratings from other except that they rated the assistant as more likely to be an advisor exact \ud835\udc5d or a reviewer exact \ud835\udc5d they did not differ in their ratings of the tool at least for some there seems to be a dissonance in their view of the role listing excerpt from interaction with the in which offers their thanks and thank been really nice to code with or to have you lol you i hope to see you on air soon i hope so congrats to you research you made a good glad you think sorry they made a good job you too thank see you next mental participants made a number of inferences about the assistant and its capacities for many participants talked about how the assistant possessed a level of of as well as and was amazed by the ability to a plain english request and interpret it ascribed intelligence to the was a lot smarter and trained i thought it one participant assumed that the assistant improving through another felt that the assistant was capable of understands the it can calculate the results of a function not all participants were convinced of the ability to questioned the wonder how far beyond boilerplate it can go and if it works for truly original impact of conversational assistance on work many participants discussed how the assistant shaped their work practices on the programming ticipants felt that the assistant me code and would up my because could focus on validating and improving the code it generated instead of having to write it all from remarked opens a whole new door for fast discussed how the assistant helpful in staying focused on the although for took time to get into tempo with the pointed out how the assistant would change the nature of their job could focus more on higher level aspects and therefore achieving better besides the the assistant iui march australia data science becomes a more level other participants discussed a work process in which the tant provided incomplete solutions the or draft of upon which they could aptly described this nice to copy well formulated challenges in natural language and have the code generator take its best stab at then edit to our hearts participants felt that human review of the responses was necessary because answers provided are generally not novel often look clunky and there may be some unnecessary basically the code would need to be also pointed out how code generator was good but you still have to really check discussed how they would turn to the assistant as a first source for and only if it able to help would they then turn to other support way i will use it i will first the assistant for most of my only in certain cases where assistant cant answer things i will turn up to official documentation or stack latency was a factor for interactive use of the assistant and participants noticed when the assistant took a long time to it took lot of like more than also felt response a little slow in chat mode i expect faster as discussed in section the assistant took an average of seconds to respond to a and participants did appreciate when the assistant produced rapid loved how quick it was able to pull up answers to questions i conversational interaction other interaction though our study was not intended to make comparative ations with the copilot we nonetheless asked participants whether they were familiar with and if to comment on how the two tools we also asked a similar question to compare the assistant with another popular form of programming searching the web a search engine like or a site like stack in discussing the differences tween these three we note that the primary differentiator is their interaction the interaction model for the assistant is clearly users ask questions in natural language and are provided with a response in natural language the interaction model of copilot is reminiscent of direct manipulation interfaces in which the actions in the user interface directly manipulate an object on the copilot automatically makes autocompletion suggestions as the user this completed code is directly placed in the source the work is contained entirely within the scope of the object on which they are working the source which is how direct manipulation interfaces in web users enter a separate search context a search engine accessed within a web type in a natural language and then forage amongst search results to identify relevant items of interest when a desirable item is users must translate it into their code environment via and possibly edit it to fit their existing we also note that the assistant and copilot both utilize the same underlying ai codex which means that the only difference between these tools is the user the extent to which codex was trained on data from related web sites is less but for the purposes of our we focus our discussion solely on the differences in their interaction participants reported various benefits and drawbacks of a versational interaction over a direct manipulation conversation very and much more natural using natural language with the in felt that use cases of assistant seem more many participants were surprised at the variety of tasks the assistant was capable of from writing unit tests and documentation to explaining what code did and even answering questions we note that the assistant utilizes the same underlying model as yet the tional interface was able to expose a wider variety of emergent behaviors from the multiple participants explored the limits of the knowledge and abilities beyond our programming for asked it questions about physics and ordinary differential equations as written by and was surprised by the of what it could asked it some physics and ode question and the though not included the key parts needed to write that probed the assistant on its knowledge of geography and was surprised when the assistant produced a correct asked something out of sw engineering domain and it replied also by correctly swering on my for some the ability to assess the sponse before committing to it by inserting code into their was a described how the paste boundary provided them with bit more control to ask specific questions about what i wanted and to assess before putting it in my other participants felt that the boundary was more think the main difference is the ability of copilot to suggest code while you what make it faster and easier to while using the you need to go to the ask the copy the an our comparison of direct and conversational action models is reminiscent of historical comparisons of and graphical user interfaces each modality was shown to have advantages and for interfaces can provide accessibility and productivity whereas graphical user interfaces provide greater discoverability some researchers explored ways to bridge the two interaction such as by developing gui wrappers for command line programs or by developing tools that converted gui activities into procedural descriptions our view is that similar bridges can be constructed between direct and conversational models of a interaction with an llm need not be constrained to a single interaction iui march australia ross et code rephrase the question if it was not understood by the and edit it to match your a large number of participants felt that the conversational action was faster than web search because of its ability to provide that can be exactly to your without having to through lots of to get what you in the assistant provided better that were more relevant to the and without having to through answers on your own or read or at many posts before finding the relevant despite these some participants felt that the assistant might not work well for specific and difficult problems on a bigger as compared to web felt that data the as as the other participants felt that the assistant lacked the and social that accompanies answers on like to see the different versions proposed on stack overflow and the commentary of what makes one tion better than another in a given some participants promoted a more balanced view that there a single mode of interaction superior to all felt that web search would be a fallback when the assistant failed to answer a described how search could be integrated with the conversational think both options should people should be able to input their queries like a search bar and also give their question as if in discussion value of conversational interaction we began our research by asking the question of whether temporary developments in llms could sufficiently support a conversational programming we believe that our work has demonstrated that they the assistant was viewed by our participants as a useful tool that provided real value so much so that many participants itly requested or expressed the desire to use it in their own how much of this value was derived from the model itself and its ability to produce responses to programming versus from ability to conduct extended conversational interactions grounded in their actual source we believe that both of these constituent aspects were many participants commented on their surprise and faction with the quality of the responses participants also valued the conversational interactions that they had with the in the event we saw dence that participants were leveraging conversational context to ask questions as well as leveraging code context by ing about their code selections many participants reported that they would find the tool less valuable if the sational interaction were removed sation seemed to provide unique value beyond other interaction models manipulation and because of its ness in the ui and its ability to surface emergent behaviors of the model we do not believe that these different interaction models are in competition and we agree with assessment that assistive tools can be built using a plethora of different interaction for use cases in which a model is known to produce results code autocompletion for a direct manipulation interface seems wholly appropriate as it would provide a erable and predictable way of invoking the model to produce a known type of direct manipulation interfaces may be less ideal for surfacing the emergent behaviors of a foundation model and thus natural language interaction may be more many popular such as and stable diffusion operate in a in which the user specifies a clicks a and gets our study demonstrates how the additional contextual layers of versational history and the provide additional value to the toward synergy the aim of ai is to people to and act in extraordinary by combining potent user experiences with embedded ai methods to support services that users building upon this rezwana and maher posit a creative interaction such as contribution and are the driving forces of the therefore the interaction model is a critical and essential component for effective they go on to note is relatively little research about interaction design in the which is reflected in a lack of focus on interaction design in many existing our study begins to address this while many systems examine casual tasks or experimental activities spoto and oleynik our focus was on the practice of our goal was to understand attitudes ward a conversational programming akin to wang et examination of data attitudes toward automated data science technologies we found despite an initial level of participants felt that a conversational assistant would provide value by improving their productivity further work is needed to assess the extent to which this type of assistance provides measurable productivity campero et conducted a survey of papers published in that examined the notion that a team can accomplish more by working together than either party could accomplish working they found mixed with no clear consensus emerging on how to design ai systems that can guarantee positive summarizing from their achieving substantial synergies among people and computers is harder than many people haps it new ways of configuring groups that include people and and perhaps it needs the assistant iui march australia more focused attention from researchers than it so we believe such evaluations of synergy should go beyond performance as implied by many of the uses cases listed by seeber et ai systems are often deployed in contexts that require longitudinal use such as product design game sign and engineering section we would expect that over time and through interaction with each teams would improve their performance through a mutual learning evidence for this process surfaced in our study when participants described how they could improve their programming skills by interacting with the assistant we assert that the learning should operate in both not only should people improve their programming but the model itself can also improve based on interactions with for when the assistant provides a code example to the and the user takes that example and edits those edits constitute feedback that can be used to further the in through longitudinal we believe that human and ai partners can create reciprocal representations of one another the human is likely to create a mental model of the and the ai may be engineered to develop a user model for each of its human users such a pair of models is often described as mutual theory of mind this type of capability raises the possibility of personalizing and adapting an assistant to the strengths and needs of individual with such an assistant that knows a user is learning a programming language could provide natural language tions alongside code whereas an assistant that knows a user is strongly skilled in a programming language might shorten or omit those users are likely to update their mental models of the ai with more we believe the space for exploring how these reciprocal models impact synergy is and we encourage additional work in this ai systems that are designed to combine and synergize the distinct skills of humans and ai models cannot ceed if they diminish the human skills upon which they ai systems develop new and plementary skills for both the human and ai constituents and we believe that mutual learning may address concerns that the wide deployment and use of ai systems will result in a of the workforce the design decisions that go into an interactive ai system have ethical our design attempts to augment the knowledge and skills by presenting help on couched in which leaves the user firmly in control and ultimately responsible for the work opportunities for future research our work highlights many interesting avenues for future ments that could be made to conversational assistants such as our as well as future centered research on conversational our work employed a model that was not cally designed to handle conversational the underlying llm for conversational such as what has been done with lamda is one opportunity to improve the another opportunity is to align the guage model to follow the desiderata proposed by askell et and described by ouyang et should help the user solve their honest fabricate information or mislead the and harmless should not cause or social harm to people or the glaese et propose a slightly different desiderata of instead of which may be more applicable to the software engineering as the ability to produce correct code and correct answers about code are both important properties of a conversational programming combining llms with approaches to establish ditional context for the such as alphacode has may also result in more capable these need not be limited to textual but could be conducted over priate semantic stores a knowledge and take advantage of explicit semantic reasoning resulting in an integration of symbolic and neural allowing for of the type shown in nye et could result in as well as better explanations and another avenue for improvement involves the prompt used to configure the assistant just as the prompt for each successive interaction is modified by the growth of the tional there is no requirement that the initial prompt be it too can be specialized to incorporate aspects of a user enabling the realization of a mutual theory of mind viding better ux affordances for visualizing and manipulating the active contexts code and conversation could provide users with more control over which information contributes to the generation of the our participants clearly indicated that they were interested in having an assistant that behaved more in contrast to our deliberate design of an assistant that never takes conversational a more proactive assistant would be able to interrupt or remind a user when necessary yet this characteristic raises many challenging how can we calibrate the threshold for such how can users tune the assistant to deliver only those interruptions that the they would find useful how can we help users to regain their prior context after dealing with an interruption should an assistant be used to persuade or nudge the user who should determine the and insistence of such persuasion attempts should users have the ability to moderate or defeat attempted or should those decisions be left to the we explored the different kinds of role orientations our participants had toward the assistant and found that participants varied in their views of it as a tool versus a social agent rator or we posit that effectiveness in working with an ai system may be influenced by their role and we encourage future research in this iui march australia ross et conclusion we developed a prototype the in order to assess the utility of a conversational assistant in a software engineering the assistant was implemented using a large language codex and was capable of generating both code and natural language responses to user we further used the prompting mechanism of the model to set up a conversational interaction in which the model uses the conversational plus the current in order to generate a in this users are able to ask questions in the chat that reference prior utterances and we incorporated the conversational assistant into a code editing enabling the conversation to be grounded in the context of the source we evaluated this system with participants with varied levels of programming and their quantitative and qualitative coupled with their usage of the demonstrated the and sometimes types of assistance it was able to many participants noted the high quality of the tional including the ability to produce explain answer general programming and even answer general knowledge participants felt this type of assistance would aid their and they drew meaningful contrasts between the conversational style of interaction with other tools that employ a direct manipulation or interaction our study motivates the use of conversational styles of action with large language models by showing how they enable emergent behaviors in a the assistant did not always generate perfect code or correct participants in our study had an overall positive perience working with it on a variety of programming we believe that our work takes us one step closer to realizing the vision of learning how to design systems that maximize the synergy in acknowledgments we would like to thank socrates for his tireless assistance during the user as well as for suggesting the title of this paper based on its",
    "references": [
        "[1] Rabe Abdalkareem, Emad Shihab, and Juergen Rilling. 2017. What Do Developers Use the Crowd For? A Study Using Stack Overflow. IEEE Software 34, 2 (2017), 53\u201360. https://doi.org/10.1109/MS.2017.31 ",
        "[2] Eleni Adamopoulou and Lefteris Moussiades. 2020. Chatbots: History, technol- ogy, and applications. Machine Learning with Applications 2 (2020), 100006. ",
        "[3] Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V. Le. 2020. Towards a Human-like Open-Domain Chatbot. ",
        "[4] Safinah Ali, Nisha Elizabeth Devasia, and Cynthia Breazeal. 2022. Escape! Bot: Social Robots as Creative Problem-Solving Partners. In Creativity and Cognition. 275\u2013283. ",
        "[5] Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. 2018. A survey of machine learning for big code and naturalness. ACM Computing Surveys (CSUR) 51, 4 (2018), 1\u201337. ",
        "[6] Irene Alvarado, Idan Gazit, and Amelia Wattenberger. 2022. GitHub Next | GitHub Copilot Labs. https://githubnext.com/projects/copilot-labs/ ",
        "[7] Hikari Ando, Rosanna Cousins, and Carolyn Young. 2014. Achieving saturation in thematic analysis: Development and refinement of a codebook. Comprehensive Psychology 3 (2014), 03\u2013CP. ",
        "[8] Craig Anslow, Stuart Marshall, James Noble, and Robert Biddle. 2013. Sourcevis: Collaborative software visualization for co-located environments. In 2013 First IEEE Working Conference on Software Visualization (VISSOFT). IEEE, 1\u201310. ",
        "[9] Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Naren- dra Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian Pan, Christine T Wolf, et al. 2021. AI-Assisted Human Labeling: Batching for Efficiency without Overreliance. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1 (2021), 1\u201327. ",
        "[10] Catherine A Ashworth. 1996. GUI Users have trouble using graphic conventions on novel tasks. In Conference Companion on Human Factors in Computing Systems. 75\u201376. ",
        "[11] Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. 2021. A general language assistant as a laboratory for alignment. arXiv preprint arXiv:2112.00861 (2021). ",
        "[12] Leif Azzopardi, Paul Thomas, and Nick Craswell. 2018. Measuring the utility of search engine result pages: an information foraging based measure. In The 41st International ACM SIGIR conference on research & development in information retrieval. 605\u2013614. ",
        "[13] Shraddha Barke, Michael B James, and Nadia Polikarpova. 2022. Grounded Copilot: How Programmers Interact with Code-Generating Models. arXiv preprint arXiv:2206.15000 (2022). ",
        "[14] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021). ",
        "[15] Joel Brandt, Mira Dontcheva, Marcos Weskamp, and Scott R Klemmer. 2010. Example-centric programming: integrating web search into the development environment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 513\u2013522. ",
        "[16] Virginia Braun and Victoria Clarke. 2022. Common challenges in Thematic Analysis and how to avoid them. Retrieved August 11 2022 from https://youtu. be/tpWLsckpM78 ",
        "[17] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Ka- plan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877\u20131901. https://proceedings.neurips.cc/paper/2020/ file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf ",
        "[18] Sallyann Bryant, Pablo Romero, and Benedict\" du Boulay. 2006. The Collabora- tive Nature of Pair Programming. In Extreme Programming and Agile Processes in Software Engineering, Pekka Abrahamsson, Michele Marchesi, and Giancarlo Succi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 53\u201364. ",
        "[19] Andres Campero, Michelle Vaccaro, Jaeyoon Song, Haoran Wen, Abdullah Almaatouq, and Thomas W Malone. 2022. A Test for Evaluating Performance in Human-Computer Systems. arXiv preprint arXiv:2206.12390 (2022). ",
        "[20] Gaetano Cascini, Yukari Nagai, Georgi V Georgiev, Jader Zelaya, Niccol\u00f2 Be- cattini, Jean-Fran\u00e7ois Boujut, Hernan Casakin, Nathan Crilly, Elies Dekoninck, John Gero, et al. 2022. Perspectives on design creativity and innovation research: 10 years later. , 30 pages. ",
        "[21] Stephen Cass. 2022. Top Programming Languages 2022. IEEE Spectrum (23 Aug 2022). https://spectrum.ieee.org/top-programming-languages-2022 ",
        "[22] Cristina Catalan Aguirre, Nuria Gonzalez Castro, Carlos Delgado Kloos, Carlos Alario-Hoyos, and Pedro Jos\u00e9 Mu\u00f1oz Merino. 2021. Conversational agent for supporting learners on a MOOC on programming with Java. (2021). ",
        "[23] Ana Paula Chaves and Marco Aurelio Gerosa. 2021. How should my chatbot interact? A survey on social characteristics in human\u2013chatbot interaction design. International Journal of Human\u2013Computer Interaction 37, 8 (2021), 729\u2013758. ",
        "[24] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sas- try, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W. Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin, S. Arun Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M. Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evalu- ating a Large Language Models Trained on Code. ",
        "[25] Li-Te Cheng, R.B. De Souza, Susanne Hupfer, John Patter- son, and Steven Ross. 2003. Building Collaboration into IDEs: Edit>Compile>Run>Debug>Collaborate? Queue 1, 9 (2003). 508",
        "[26] Carl Cook, Warwick Irwin, and Neville Churcher. 2005. A user evaluation of synchronous collaborative software engineering tools. In 12th Asia-Pacific Software Engineering Conference (APSEC05). IEEE, 6\u2013pp. ",
        "[27] Claudio Le\u00f3n de la Barra, Broderick Crawford, Ricardo Soto, Sanjay Misra, and Eric Monfroy. 2013. Agile Software Development: It Is about Knowledge Management and Creativity. In Computational Science and Its Applications \u2013 ICCSA 2013, Beniamino Murgante, Sanjay Misra, Maurizio Carlini, Carmelo M. Torre, Hong-Quang Nguyen, David Taniar, Bernady O. Apduhan, and Osvaldo Gervasi (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 98\u2013113. ",
        "[28] Uri Dekel and Steven Ross. 2004. Eclipse as a platform for research on in- terruption management in software development. In Proceedings of the 2004 OOPSLA workshop on Eclipse Technology eXchange (Vancouver, British Columbia, Canada), Michael G. Burke (Ed.). ACM, 12\u201316. ",
        "[29] Bobbie Eicher, Kathryn Cunningham, Sydni Peterson Marissa Gonzales, and Ashok Goel. 2017. Toward mutual theory of mind as a foundation for co-creation. In International Conference on Computational Creativity, Co-Creation Workshop. ",
        "[30] Stephen M Fiore, Eduardo Salas, and Janis A Cannon-Bowers. 2001. Group dynamics and shared mental model development. How people evaluate others in organizations 234 (2001). ",
        "[31] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. 1995. Design patterns: elements of reusable object-oriented software. Addison-Wesley. ",
        "[32] GitHub, Inc. 2022. GitHub copilot \u00b7 your AI pair programmer. Retrieved August 5, 2022 from https://github.com/features/copilot/ ",
        "[33] Amelia Glaese, Nat McAleese, Maja Tr\u0119bacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, So\u0148a Mokr\u00e1, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. 2022. Improving alignment of dialogue agents via targeted human judgements. https://arxiv.org/abs/2209.14375 ",
        "[34] Stephanie Glen. 2022. ChatGPT writes code, but wont replace devel- opers. TechTarget (14 12 2022). Retrieved 20-Jan-2023 from https: //www.techtarget.com/searchsoftwarequality/news/252528379/ChatGPT- writes-code-but-wont-replace-developers ",
        "[35] Samuel Holmes, Anne Moorhead, Raymond Bond, Huiru Zheng, Vivien Coates, and Mike McTear. 2018. WeightMentor: a new automated chatbot for weight loss maintenance. In Proceedings of the 32nd International BCS Human Computer Interaction Conference 32. 1\u20135. ",
        "[36] Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2020. Deep code comment generation with hybrid lexical and syntactical information. Empirical Software Engineering 25, 3 (2020), 2179\u20132217. ",
        "[37] Edwin L Hutchins, James D Hollan, and Donald A Norman. 1985. Direct manip- ulation interfaces. Human\u2013computer interaction 1, 4 (1985), 311\u2013338. ",
        "[38] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016. Summarizing source code using a neural attention model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2073\u20132083. ",
        "[39] Andreas Jedlitschka and Markus Nick. 2003. Software Engineering Knowledge Repositories. Springer Berlin Heidelberg, Berlin, Heidelberg, 55\u201380. ",
        "[40] Eirini Kalliamvakou. 2022. Research: Quantifying github copilots impact on developer productivity and happiness. https://github.blog/2022-09-07- research-quantifying-github-copilots-impact-on-developer-productivity- and-happiness/ ",
        "[41] Anna Kantosalo et al. 2019. Human-Computer Co-Creativity: Designing, Evalu- ating and Modelling Computational Collaborators for Poetry Writing. (2019). ",
        "[42] Sandeep Kaur Kuttal, Bali Ong, Kate Kwasny, and Peter Robe. 2021. Trade- Offs for Substituting a Human with an Agent in a Pair Programming Context: The Good, the Bad, and the Ugly. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI 21). Association for Computing Machinery, New York, NY, USA, Article 243, 20 pages. ",
        "[43] Lauramaria Laine. 2021. Exploring Advertising Creatives Attitudes Towards Human-AI Collaboration. (2021). ",
        "[44] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R\u00e9mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, and et al. 2022. Competition-level code generation with AlphaCode. https: //arxiv.org/abs/2203.07814 ",
        "[45] Yaosheng Lou and Qi Sun. 2021. Over-reliance on database: A case study of using web of science. Human Behavior and Emerging Technologies 3, 3 (2021), 454\u2013459. ",
        "[46] David Lyell and Enrico Coiera. 2017. Automation bias and verification complex- ity: a systematic review. Journal of the American Medical Informatics Association 24, 2 (2017), 423\u2013431. ",
        "[47] Wendy E Mackay and Anne-Laure Fayard. 1997. HCI, natural science and design: a framework for triangulation across disciplines. In Proceedings of the 2nd conference on Designing interactive systems: processes, practices, methods, and techniques. 223\u2013234. ",
        "[48] John E Mathieu, Tonia S Heffner, Gerald F Goodwin, Eduardo Salas, and Janis A Cannon-Bowers. 2000. The influence of shared mental models on team process and performance. Journal of applied psychology 85, 2 (2000), 273. ",
        "[49] Cade Metz. 2022. Meet GPT-3. It Has Learned to Code (and Blog and Ar- gue). (Published 2020). https://www.nytimes.com/2020/11/24/science/artificial- intelligence-ai-gpt3.html ",
        "[50] Robert J. Moore and Raphael Arar. 2019. Conversational UX Design: A Practi- tioners Guide to the Natural Conversation Framework. Association for Computing Machinery, New York, NY, USA. ",
        "[51] Ekaterina A Moroz, Vladimir O Grizkevich, and Igor M Novozhilov. 2022. The Potential of Artificial Intelligence as a Method of Software Developers Produc- tivity Improvement. In 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus). IEEE, 386\u2013390. ",
        "[52] Michael Muller, Stevean Ross, Stephanie Houde, Mayank Agarwal, Fernando Martinez, John Richards, Kartik Talamadupula, and Justin D Weisz. 2022. Drink- ing Chai with Your (AI) Programming Partner: A Design Fiction about Gener- ative AI for Software Engineering. HAI-GEN Workshop at IUI 2022: 3rd Work- shop on Human-AI Co-Creation with Generative Models (2022). https://hai- gen.github.io/2022/ ",
        "[53] Sandra R Murillo and J Alfredo S\u00e1nchez. 2014. Empowering interfaces for system administrators: Keeping the command line in mind when designing GUIs. In Proceedings of the XV International Conference on Human Computer Interaction. 1\u20134. ",
        "[54] Elizabeth D Mynatt and Gerhard Weber. 1994. Nonvisual presentation of graph- ical user interfaces: contrasting two approaches. In Proceedings of the SIGCHI conference on Human factors in computing systems. 166\u2013172. ",
        "[55] Alok Mysore and Philip J Guo. 2017. Torta: Generating mixed-media gui and command-line app tutorials using operating-system-wide activity tracing. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology. 703\u2013714. ",
        "[56] C. Nass and Y. Moon. 2000. Machines and Mindlessness: Social Responses to Computers. Journal of Social Issues 56, 1 (2000), 81\u2013103. ",
        "[57] Nhan Nguyen and Sarah Nadi. 2022. An Empirical Evaluation of GitHub Copi- lots Code Suggestions. In 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR). IEEE, 1\u20135. ",
        "[58] Martin Nordio, H Estler, Carlo A Furia, Bertrand Meyer, et al. 2011. Collaborative software development on the web. arXiv preprint arXiv:1105.0768 (2011). ",
        "[59] Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Witold Michalewski, Ja- cob Austin, David Bieber, David Martin Dohan, Aitor Lewkowycz, Maarten Paul Bosma, David Luan, Charles Sutton, and Augustus Odena. 2021. Show Your Work: Scratchpads for Intermediate Computation with Language Models. https://arxiv.org/abs/2112.00114. ",
        "[60] OpenAI. 2022. ChatGPT: Optimizing Language Models for Dialogue. OpenAI Blog (30 11 2022). Retrieved 20-Jan-2023 from https://openai.com/blog/chatgpt/ ",
        "[61] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. https://arxiv. org/abs/2203.02155 ",
        "[62] Peter Pirolli and Stuart Card. 1999. Information foraging. Psychological review 106, 4 (1999), 643. ",
        "[63] Larry Press. 1990. Personal computing: Windows, DOS and the MAC. Commun. ACM 33, 11 (1990), 19\u201326. ",
        "[64] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language Models are Unsupervised Multitask Learners. ",
        "[65] Alvin Rajkomar, Jeffrey Dean, and Isaac Kohane. 2019. Machine learning in medicine. New England Journal of Medicine 380, 14 (2019), 1347\u20131358. ",
        "[66] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125 (2022). ",
        "[67] B. Reeves and C.I. Nass. 1996. The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places. CSLI Publications. ",
        "[68] Mawarny Md Rejab, James Noble, and George Allan. 2014. Distributing Expertise in Agile Software Development Projects. In 2014 Agile Conference. 33\u201336. ",
        "[69] Jeba Rezwana and Mary Lou Maher. 2021. COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems.. In ICCC. 444\u2013448. ",
        "[70] Charles H. Rich and Richard C. Waters. 1990. The Programmers Apprentice. Addison-Wesley Publishing Company, Reading, MA. ",
        "[71] Peter Robe and Sandeep Kaur Kuttal. 2022. Designing PairBuddyA Conver- sational Agent for Pair Programming. ACM Transactions on Computer-Human Interaction (TOCHI) 29, 4 (2022), 1\u201344. ",
        "[72] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. 2022. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni- tion. 10684\u201310695. 509",
        "[73] Steven Ross, Elizabeth Brownholtz, and Robert Armes. 2004. A Multiple- Application Conversational Agent. In Proceedings of the 9th International Con- ference on Intelligent User Interfaces (Funchal, Madeira, Portugal) (IUI 04). Asso- ciation for Computing Machinery, New York, NY, USA, 319\u2013321. ",
        "[74] Steven Ross, Elizabeth Brownholtz, and Robert Armes. 2004. Voice User Interface Principles for a Conversational Agent. In Proceedings of the 9th International Conference on Intelligent User Interfaces (Funchal, Madeira, Portugal) (IUI 04). Association for Computing Machinery, New York, NY, USA, 364\u2013365. ",
        "[75] Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot, and Guillaume Lample. 2020. Unsupervised Translation of Programming Languages. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 20601\u201320611. ",
        "[76] Harvey Sacks. 1984. Notes on methodology. In Structures of Social Action: Studies in Conversation Analysis, John Heritage and J. Maxwell Atkinson (Eds.). Cambridge University Press, Cambridge, 2\u201327. ",
        "[77] Nithya Sambasivan and Rajesh Veeraraghavan. 2022. The Deskilling of Domain Expertise in AI Development. In CHI Conference on Human Factors in Computing Systems. 1\u201314. ",
        "[78] Harini Sampath, Alice Merrick, and Andrew Macvean. 2021. Accessibility of command line interfaces. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201310. ",
        "[79] Matthias Scheutz, Scott A DeLoach, and Julie A Adams. 2017. A framework for developing and using shared mental models in human-agent teams. Journal of Cognitive Engineering and Decision Making 11, 3 (2017), 203\u2013224. ",
        "[80] Isabella Seeber, Eva Bittner, Robert O Briggs, Triparna De Vreede, Gert-Jan De Vreede, Aaron Elkins, Ronald Maier, Alexander B Merz, Sarah Oeste-Rei\u00df, Nils Randrup, et al. 2020. Machines as teammates: A research agenda on AI in team collaboration. Information & management 57, 2 (2020), 103174. ",
        "[81] Shilad Sen, Werner Geyer, Michael Muller, Marty Moore, Beth Brownholtz, Eric Wilcox, and David R Millen. 2006. FeedMe: a collaborative alert filtering system. In Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work. 89\u201398. ",
        "[82] Ben Shneiderman. 2020. Human-centered artificial intelligence: Three fresh ideas. AIS Transactions on Human-Computer Interaction 12, 3 (2020), 109\u2013124. ",
        "[83] Ben Shneiderman. 2022. Human-Centered AI. Oxford University Press. ",
        "[84] Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage. arXiv preprint arXiv:2208.03188 (2022). ",
        "[85] Michael Skirpan and Casey Fiesler. 2018. Ad empathy: A design fiction. In Proceedings of the 2018 ACM Conference on Supporting Groupwork. 267\u2013273. ",
        "[86] Diomidis Spinellis. 2012. Git. IEEE Software 29, 3 (2012), 100\u2013101. https: //doi.org/10.1109/MS.2012.61 ",
        "[87] Angie Spoto and Natalia Oleynik. 2017. Library of Mixed-Initiative Creative Interfaces. Retrieved 19-Jun-2021 from http://mici.codingconduct.cc/ ",
        "[88] Ayushi Srivastava, Shivani Kapania, Anupriya Tuli, and Pushpendra Singh. 2021. Actionable UI Design Guidelines for Smartphone Applications Inclusive of Low-Literate Users. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1 (2021), 1\u201330. ",
        "[89] Margaret-Anne Storey and Alexey Zagalsky. 2016. Disrupting developer produc- tivity one bot at a time. In Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering. 928\u2013931. ",
        "[90] Kartik Talamadupula. 2021. Applied AI matters: AI4Code: applying artificial intelligence to source code. AI Matters 7, 1 (2021), 18\u201320. ",
        "[91] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul- shreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, and et al. 2022. LAMDA: Language models for dialog applications. https: //arxiv.org/abs/2201.08239 ",
        "[92] Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, and Neel Sundaresan. 2020. Unit Test Case Generation with Transformers and Focal Context. arXiv preprint arXiv:2009.05617 (2020). ",
        "[93] Severi Uusitalo, Anna Kantosalo, Antti Salovaara, Tapio Takala, and Christian Guckelsberger. 2022. Co-creative Product Design with Interactive Evolutionary Algorithms: A Practice-Based Reflection. In International Conference on Compu- tational Intelligence in Music, Sound, Art and Design (Part of EvoStar). Springer, 292\u2013307. ",
        "[94] Priyan Vaithilingam and Philip J Guo. 2019. Bespoke: Interactively synthesizing custom GUIs from command-line applications by demonstration. In Proceedings of the 32nd annual ACM symposium on user interface software and technology. 563\u2013576. ",
        "[95] Priyan Vaithilingam, Tianyi Zhang, and Elena L. Glassman. 2022. Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI EA 22). Association for Computing Machinery, New York, NY, USA, Article 332, 7 pages. https://doi.org/10.1145/3491101.3519665 ",
        "[96] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper/ 2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf ",
        "[97] Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S Yu. 2018. Improving automatic source code summarization via deep rein- forcement learning. In Proceedings of the 33rd ACM/IEEE international conference on automated software engineering. 397\u2013407. ",
        "[98] April Yi Wang, Dakuo Wang, Jaimie Drozdal, Michael Muller, Soya Park, Justin D Weisz, Xuye Liu, Lingfei Wu, and Casey Dugan. 2022. Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks. ACM Transactions on Computer-Human Interaction 29, 2 (2022), 1\u201333. ",
        "[99] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray. 2019. Human-AI collaboration in data science: Exploring data scientists perceptions of automated AI. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1\u201324. ",
        "[100] Qiaosi Wang, Koustuv Saha, Eric Gregori, David Joyner, and Ashok Goel. 2021. Towards mutual theory of mind in human-ai interaction: How language reflects what students perceive about a virtual teaching assistant. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201314. ",
        "[101] Jeremy Warner and Philip J Guo. 2017. Codepilot: Scaffolding end-to-end collaborative software development for novice programmers. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 1136\u20131141. ",
        "[102] Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agarwal, and Kartik Talamadupula. 2021. Per- fection Not Required? Human-AI Partnerships in Code Translation. In 26th International Conference on Intelligent User Interfaces. 402\u2013412. ",
        "[103] Justin D Weisz, Michael Muller, Steven I Ross, Fernando Martinez, Stephanie Houde, Mayank Agarwal, Kartik Talamadupula, and John T Richards. 2022. Bet- ter together? an evaluation of ai-supported code translation. In 27th International Conference on Intelligent User Interfaces. 369\u2013391. ",
        "[104] Joseph Weizenbaum. 1966. ELIZA a computer program for the study of natural language communication between man and machine. Commun. ACM 9 (1966), 36\u201345. ",
        "[105] Frank F Xu, Bogdan Vasilescu, and Graham Neubig. 2022. In-ide code generation from natural language: Promise and challenges. ACM Transactions on Software Engineering and Methodology (TOSEM) 31, 2 (2022), 1\u201347. ",
        "[106] Aditya Ankur Yadav, Ishan Garg, and Dr. Pratistha Mathur. 2019. PACT - Pro- gramming Assistant ChaTbot. In 2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT). 131\u2013136. ",
        "[107] Munazza Zaib, Quan Z. Sheng, and W. Zhang. 2020. A Short Survey of Pre- trained Language Models for Conversational AI-A New Age in NLP. Proceedings of the Australasian Computer Science Week Multiconference (2020). ",
        "[108] Elaine Zibrowski, Lisa Shepherd, Kamran Sedig, Richard Booth, Candace Gibson, et al. 2018. Easier and faster is not always better: grounded theory of the impact of large-scale system transformation on the clinical work of emergency medicine nurses and physicians. JMIR Human Factors 5, 4 (2018), e11013. ",
        "[109] Albert Ziegler, Eirini Kalliamvakou, X. Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian. 2022. Produc- tivity Assessment of Neural Code Completion. In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming (San Diego, CA, USA) (MAPS 2022). Association for Computing Machinery, New York, NY, USA, 21\u201329. https://doi.org/10.1145/3520312.3534864 510"
    ]
}