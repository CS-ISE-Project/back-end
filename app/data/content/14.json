{
    "info": {
        "title": "Improved stochastic subset optimization method for structural design optimization",
        "authors": [
            "Mohd Aman Khalid",
            "Sahil Bansal"
        ],
        "institutes": [
            "Department of Civil Engineering, Indian Institute of Technology Delhi, New Delhi 110016, India"
        ],
        "keywords": [
            "Stochastic subset optimization",
            "Voronoi tessellation",
            "Stochastic simulation",
            "Stochastic optimization",
            "Optimization under uncertainty"
        ],
        "abstract": "The Stochastic Subset Optimization (SSO) algorithm was proposed for optimal reliability problems that mini mizes the probability of system failure over the admissible space for the design parameters. It is based on the simulation of samples of the design parameters from an auxiliary Probability Density Function (PDF) and exploiting the information contained in these samples to identify subregions for the optimal design parameters within the original design space. This paper presents an improved version of SSO, named iSSO to overcome the shortcomings in the SSO. In the improved version, the Voronoi tessellation is implemented to partition the design space into nonoverlapping subregions using the pool of samples distributed according to the auxiliary PDF. A doublesort approach is then used to identify the subregions for the optimal design. The iSSO is presented as a generalized design optimization approach primarily tailored for the stochastic structural systems but also adaptable to deterministic systems. Several optimization problems are considered to illustrate the effectiveness and efficiency of the proposed iSSO."
    },
    "sections": {
        "1. Introduction": "Structural optimization may be defined as the rational establishment of an economical structural design with the available resources while satisfying specific performance criteria. In general terms, the economy may be characterized by minimum weight, minimum cost, maximum utility, or even minimum probability of failure. Broadly, structural optimization can be categorized into deterministic and stochastic opti mization [1,2]. The classical statement of unconstraint deterministic optimization is mathematically expressed as: minimize : \u03c6\u03a6 g(\u03c6) (1) where, \u03c6 = [\u03c61\u03c6n\u03c6]T \u03a6Rn\u03c6 is a set of deterministic adjustable pa rameters that define the structural design, referred to herein as design parameters, g(\u03c6) : Rn\u03c6R is the objective function to be minimized, and \u03a6 denotes the bounded admissible design space. The deterministic constraints can be considered by the appropriate definition of the ad missible design space \u03a6 for deterministic design parameters \u03c6, as mentioned in [3]. In the deterministic structural optimization problem, the uncertainties in parameters are ignored, and fixed values are assumed for all the parameters. There are numerous optimizations approaches available in the literature, however, but its worth noting that no onesizefitsall optimization approach is ideal for all sorts of problems [47]. The choice of optimization method is often determined by the specific characteristics of the problem, such as its complexity, dimensionality, constraints, and the nature of the objective function. As a result, there is always a scope for new approaches to be developed or the adaptation of existing methods to better suit specific problem clas ses. A detailed discussion of deterministic optimization approaches can be found in the literature [8,9]. In any practical situation, several parameters, such as loadings, structural parameters, geometric parameters, operation conditions, etc., are either not known at the design stage or are subjected to random fluctuations that give rise to performance variability and affect the performance of a system [10]. These parameters are characterized as uncertain parameters. Deterministic structural optimization discards the impact of uncertainty and can result in improper design. Therefore, it is desirable to account for the uncertainty in the parameters during opti mization by using the rational methods of probabilistic structural analysis [11]. Such structural optimization that accounts for un certainties is called stochastic optimization [12]. Although stochastic optimization refers to any method that employs randomness within some communities, in this paper, we will only consider settings where * Corresponding author. Email addresses: mohdamankhalid@gmail.com (M.A. Khalid), sahil@iitd.ac.in (S. Bansal). Contents lists available at ScienceDirect Advances in Engineering Software journal homepage: www.elsevier.com/locate/advengsoft https://doi.org/10.1016/j.advengsoft.2023.103568 Received 5 June 2023; Received in revised form 2 October 2023; Accepted 24 November 2023 Advances in Engineering Software 188 (2024) 103568 2 the objective function is random. Stochastic optimization or optimal design under uncertainty has been widely applied in many practical engineering fields, including civil engineering structures [1315], composite structures [16,17], and vehicles [18,19]. Consider an engineering system that involves deterministic design parameters \u03c6, and uncertain variables \u03b8 = [\u03b81\u03b8n\u03b8]T \u0398Rn\u03b8 following a joint PDF p(\u03b8\u03c6), where \u0398 denotes the parameter space of the uncer tain variables. The classical statement of stochastic optimization is mathematically expressed as: minimize : \u03c6\u03a6 E\u03b8[h(\u03c6, \u03b8)] (2) where, h(\u03c6, \u03b8) : Rn\u03b8+n\u03c6R is the structural performance function, and E\u03b8[ ] denotes expectation with respect to the PDF for \u03b8. Note that the objective function in the optimization problem in (2) is the expectation E\u03b8[h(\u03c6, \u03b8)] which is a deterministic function. Its worth mentioning that stochastic optimization may also involve other stochastic measures such as variance or quantile values. However, these stochastic measures can rarely be evaluated analytically; therefore, several methods have been proposed for solving stochastic optimization problems. These special ized methods include, for example, sample average approximation, stochastic approximation, stochastic subset optimization, and ap proaches based on the use of Taylor series expansion [15,20,21], response surface, and metamodels [2225]. Specific to structural engi neering, there are two broad categories of problems involving design optimization under uncertainty [2635]: ReliabilityBased Design Optimization (RBDO) and Robust Design Optimization (RDO). The objective of RBDO is to find an optimal solution that minimizes some deterministic, objective function under observance of probabilistic constraints instead of conventional deterministic constraints [36,37]. On the other hand, RDO aims to find an optimal solution that is insen sitive (or less sensitive) to input variations. It improves the design quality by minimizing performance variation without eliminating un certainty [29,38]. Taflanidis and Beck [39] introduced a novel algorithm for optimal reliability problem, the socalled SSO. SSO involves formulating an augmented problem where the design parameters are artificially considered uncertain and defining an auxiliary PDF that includes the structural performance function and the PDF of the uncertain variables. Next, SSO involves generating a pool of samples distributed according to this auxiliary PDF and identifying a subregion in the original design space, which, on average, improves the value of the objective function. By repeating this procedure several times, it is possible to determine at each step a smaller subregion in the design space, which in turn im proves the value of the objective function. Ultimately, this subregion will be sufficiently small to directly identify the optimal solution or provide sufficient information to launch another optimization algo rithm, such as the sample average approximation or stochastic approx imation. The implementation of the SSO method closely resembles the Subset Simulation (SS) algorithm [40] for reliability analysis. Since SSO is based on simulation, it can deal with linear or nonlinear problems and, at least theoretically, an unbounded number of design parameters. The numerical effort for solving a given optimization problem is indepen dent of the number of uncertain variables, and it grows linearly with the number of design parameters. Since the introduction of SSO, several extensions of SSO have been proposed. An extension of SSO termed NonParametric SSO, which adopts kernel density estimation to approximate the objective function, is presented in [41]. In [42], efficient integration of the Moving Least Squares approximation within SSO is introduced to reduce the compu tational effort in SSO. In [3], an augmented formulation is presented for the RDO of structures using SSO. SSO or its variants have also been applied to solve structural optimization problems. SSO has been used for reliability optimization and sensitivity analysis in system design in [39]. A framework for RDO of Tuned Mass Dampers (TMD) by SSO is dis cussed in [43]. Even though SSO has proved to be efficient for meeting various challenging optimization problems, it has two shortcomings. First, the effectiveness of SSO is dependent on the correct selection of the geometrical shape of the admissible subsets. Here, it is pertinent to mention that choosing a geometrical shape that effectively investigates the sensitivity of the objective function to each design variable is essential. The shapes, such as hyperrectangle and hyperellipse are suggested in the literature for the admissible subsets. However, as shown later via the illustrative example, these shapes fail to include the optimal solution in cases with complex design spaces or problems with multiple optimal solutions. And second, identifying the optimal subset that con tains the smallest volume density involves a nonsmooth optimization problem which is quite challenging. In this paper, an improved version of SSO is developed to overcome the shortcomings of the original SSO. This new version of the algorithm, as mentioned earlier, is named iSSO (improved SSO). Voronoi tessella tion is implemented to partition the design space into nonoverlapping subregions (a set of Voronoi cells) using the pool of samples distrib uted according to the auxiliary PDF. The admissible set (a set of all admissible subregions) is then defined as a set containing all subsets of the set of Voronoi cells. This approach is able to capture the regions with lower objective function values even if they are disjointed or when the design space is complex. The details of the Voronoi tessellation are presented in Appendix A. A doublesort algorithm is then implemented to identify the optimal subset containing the smallest volume density. In the next section, the original SSO is reviewed. Section 3 presents the general theoretical and computational framework for the iSSO al gorithm. Section 4 considers several optimization problems to illustrate the effectiveness and efficiency of the proposed iSSO algorithm.",
        "2. Original stochastic subset optimization": "In SSO, say at the i + 1th iteration, the design space is represented by a subset I(i), where I(i) I(i 1) I(0) \u03a6. Following the augmented formulation concept initially discussed in [44] for RBDO, the design parameters \u03c6, are artificially considered uncertain variables with a prescribed PDF p(\u03c6I(i)) over the design space I(i) [45]. For convenience, p(\u03c6I(i)) = 1/V(i) is considered, where V(i) is the volume of I(i). In this setting of the augmented stochastic design problem, the auxiliary PDF is defined as: \u03c0 ( \u03c6, \u03b8 I(i)) = h(\u03c6, \u03b8)p ( \u03c6, \u03b8 I(i)) E\u03c6,\u03b8[hs(\u03c6, \u03b8)] h(\u03c6, \u03b8)p ( \u03c6, \u03b8 I(i)) (3) where, p(\u03c6, \u03b8I(i)) = p(\u03b8\u03c6)p(\u03c6I(i)). Note that if h(\u03c6, \u03b8) 0, it must be suitably transformed to ensure that \u03c0(\u03c6, \u03b8I(i)) 0. One way to do this is to define hs(\u03c6,\u03b8) = h(\u03c6, \u03b8) s, since E\u03b8[hs(\u03c6,\u03b8)] = E\u03b8[h(\u03c6,\u03b8)] s, that is, the two expected values differ only by a constant, and the optimization of the expected value of h( ) is equivalent, in terms of the optimal design choice, to optimization for the expected value for hs( ). In the above equation, the denominator is a normalizing constant given by: E\u03c6,\u03b8[h(\u03c6, \u03b8)] = \u03a6 \u0398 h(\u03c6, \u03b8)p ( \u03c6, \u03b8 I(i)) d\u03b8d\u03c6. (4) Although this expected value is not explicitly needed, it can be determined using any stateoftheart stochastic simulation method. The objective function E\u03b8[hs(\u03c6, \u03b8)] in this context of the auxiliary PDF is expressed as: E\u03b8[h(\u03c6, \u03b8)] = \u03c0 ( \u03c6 I(i)) p ( \u03c6 I(i))E\u03c6,\u03b8[h(\u03c6, \u03b8)], (5) where, the marginal \u03c0(\u03c6I(i)) is given by: \u03c0 ( \u03c6 I(i)) = I(i)\u03c0(\u03c6, \u03b8)d\u03b8. (6) In (5), since E\u03c6,\u03b8[h(\u03c6, \u03b8)] is a normalizing constant, minimization of M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 3 E\u03b8[h(\u03c6, \u03b8)] is equivalent to minimization of J(\u03c6), which is equal to: J ( \u03c6 I(i)) = E\u03b8[hs(\u03c6, \u03b8)] E\u03c6,\u03b8[hs(\u03c6, \u03b8)] = \u03c0 ( \u03c6 I(i)) p ( \u03c6 I(i)). (7) The estimation of the marginal \u03c0(\u03c6I(i)) in (7) is necessary to mini mize J(\u03c6I(i)). Analytical approximations of \u03c0(\u03c6I(i)) based on kernel density approaches or the maximum entropy method might be arduous in case of complex problems, such as when design parameters n\u03c6 are large, or the sensitivity for some design parameters is complex [44]. In the SSO framework, such approximation of \u03c0(\u03c6I(i)) is avoided. In SSO, samples distributed as \u03c0(\u03c6I(i)) are obtained, and the information in these samples is exploited to identify a smaller subset of the design space with a high likelihood of containing the optimal design parameters. Samples distributed as \u03c0(\u03c6, \u03b8I(i)) are obtained using any appropriate stochastic sampling algorithm, such as Markov Chain Monte Carlo (MCMC) sampling [46]. The \u03c6 component of these samples then cor responds to samples from the marginal distribution \u03c0(\u03c6I(i)). The sensitivity of objective function E\u03b8[hs(\u03c6, \u03b8)] to \u03c6 is determined by evaluating the average value (or equivalently volume density) of J(\u03c6 I(i)) over any subset I in I(i), which is denoted by H(I) and defined as: H(I) = 1 VI I J ( \u03c6I(i)) d\u03c6 = 1 VI I \u03c0 ( \u03c6I(i)) p ( \u03c6I(i)) d\u03c6 = VI(i) VI I \u03c0 ( \u03c6I(i)) d\u03c6 (8) where, VI is the volume of subset I. Based on the samples distributed according to \u03c0(\u03c6I(i)) belonging to I(i), an estimate of H(I) is provided by: H(I) = NI/VI NI(i)/VI(i), (9) where, NI(i) is the number of samples distributed as \u03c0(\u03c6I(i)) belonging to I(i), and NI denotes the number of samples from \u03c0(\u03c6I(i)) belonging to the I (NI NI(i1)since II(k 1)). Say NI = p0NI(i1). A smaller value of \u03c1 re sults in a faster decrease in the size of the identified subsets but with poorer accuracy. The use of \u03c1 equal to 0.1 0.2 is suggested in the literature [39]. A deterministic optimization, based on the estimate H(I) of H(I), is next performed to identify the subset I A(i+1) \u03c1 , where A(i+1) \u03c1 is a set of admissible subsets in I(i), that contains the smallest volume density NI/ VI, that is, I(i+1) = argmin IA\u03c1H(I) = arg min IA(i+1) \u03c1 NI / VI A(i+1) \u03c1 = { II(i) : \u03c1 = NI / N(i)} . (10) The effectiveness of SSO is dependent on the correct selection of the geometrical shape and size of the admissible subsets. Choosing a geometrical shape that effectively investigates the sensitivity of the objective function to each design variable is essential. The optimization in (10) determines the subset with the smallest average value of J(\u03c6I(i)) (or equivalently E\u03b8[hs(\u03c6,\u03b8)]) within the admissible set A(i+1) \u03c1 . I(i + 1) is a subset of the design space I(i) with a high likelihood of containing the optimal design parameters. The above steps are repeated until the stopping criterion is met. This way, SSO adaptively converges to a relatively small subregion within the original design space. The imple mentation of SSO is demonstrated in Fig. 1. The reader may refer to the original publication for a detailed explanation of SSO [39]. H(I(i)) expresses the average relative sensitivity of E\u03b8[h(\u03c6,\u03b8)] to \u03c6. A low value of H(I(i)) indicates that E\u03b8[h(\u03c6,\u03b8)] is more sensitive to \u03c6, and vice versa. A high value of H(I(i)), close to 1 corresponds to a sample density in design space I(i) that approximates a uniform distribution and suggests that the identified subset I(i) has a low likelihood of containing \u03c6* [39]. Therefore, the SSO is stopped when H(I(i)) exceeds a threshold value. A threshold value of 0.750.80 has been found to give satisfactory results [39].",
        "3. Proposed approach": "In the proposed approach, the Voronoi tessellation is implemented to partition the design space into nonoverlapping subregions (a set of Voronoi cells) using the pool of samples distributed according to this auxiliary PDF. Conceptually, Voronoi tessellation involves partitioning a space into convex polygons, called Voronoi cells, such that each cell contains exactly one sample, called a cellgenerating sample. Every sample in a given polygon is closer to its generating sample compared to any other. In the proposed approach, the admissible set (a set of all admissible subspaces) is defined as a set containing all subsets of the set of Voronoi cells. An alternative approach to identify the optimal subset without performing any nonsmooth deterministic optimization is also presented. The general theoretical and computational framework for the iSSO algorithm is presented in the following subsections, and the Fig. 1. Illustration of the original SSO algorithm. M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 4 algorithm is demonstrated in Fig. 2.",
        "3.1. Partitioning of design space": "In the proposed approach, at the i + 1th iteration, say N(i) is the number of samples distributed as \u03c0(\u03c6I(i)) belonging to the design space I(i). Let nv = N(i) /(1 + \u03b3), \u03b3 0 be the number of unique samples. If sampling techniques such as accept rejection, importance sampling, etc., are used, then \u03b3 = 0, and each sample in the design space will be unique. However, if MCMC sampling techniques are used, the resulting samples will be correlated, that is \u03b3 0, and we will have repeated samples. Assume that the design space I(i) is divided into v(i) k , k = 1nv, Voronoi cells using nv unique samples, and say the Voronoi cell v(i) k contains \u03b7(i) k repeated samples, then, an estimate of \u03c0(\u03c6I(i)) is provided by: \u03c0 ( \u03c6I(i)) = \u03b7(i) k N(i)V(i) k 0, \u03c6 v(i) k , (11) where, V(i) k is the volume of the kth Voronoi cell. Obviously, I(i)\u03c0(\u03c6I(i)) d\u03c6 = 1. Similar to the original SSO, the sensitivity of the objective function J (\u03c6I(i)) to \u03c6 is determined by evaluating the average value of J(\u03c6I(i)) over any subspace I of the design space I(i). Subset I is any subset of nvVoronoi cells (these cells may be disjointed). Since the design space is partitioned into nv subspaces or Voronoi cells, the number of admissible subsets (proper subsets) is given by 2n\u03bd 1. Based on the estimate \u03c0(\u03c6I(i)) provided in (11), an estimate of H(I) is provided as: H(I) = V(i) VI I \u03c0 ( \u03c6I(i)) d\u03c6 = V(i) VI I\u03b7(i) i N(i) = V(i) VI NI N(i) (12) where, VI is the volume of the subset I and NI is the number of samples belonging to it. Let I = {v(i) (1), v(i) (2)v(i) (S)}, where S is the number of Vor onoi cells defining the subset I. Note that the parentheses are used in the subscript to differentiate between the Voronoi cell number defined in the previous section from the Voronoi cell index describing the subset I. An estimate of H(I) is then provided as: H(I) = V(i) N(i) [ \u03b7(i) (1) + \u03b7(i) (2) + + \u03b7(i) (S) V(i) (1) + V(i) (2) + + V(i) (S) ] . (13)",
        "3.2. Identification of an optimal subset": "A deterministic optimization needs to be performed to identify a subset I that contains the smallest volume density NI/VI. In the case of unique samples, since \u03b7(i) () = 1, the solution to the minimization problem in (10) is a set of \u03c1N(i) Voronoi cells with the largest volume. For the case with repeated samples, the optimization can be performed using methods appropriate for nonsmooth optimization problems, such as subgradient methods, bundle methods, gradient sampling methods, etc. In this study, we propose an alternative approach to identify the optimal subset without performing any nonsmooth deterministic opti mization. A doublesort algorithm is proposed, which involves sorting the Voronoi cells in ascending order of the sample counts and then in groups of cells with the same sample count in descending order of cell volume. Finally, the top cells containing \u03c1N(i)samples are selected as an approximate optimal solution from the sorted list. One may argue that the optimal subset can be obtained by first sorting the Voronoi cells in ascending order of the cell density, defined as \u03b7(i) k /V(i) k , and then by selecting the top cells containing \u03c1N(i) samples from the sorted list. However, this argument is erroneous because the objective is to minimize S s=1\u03b7(i) (s)/ S s=1V(i) (s) and not S s=1(\u03b7(i) (s) /V(i) (s)). The effectiveness of the proposed doublesort algorithm is demonstrated in Section 4 with the help of examples.",
        "3.3. Simulation of conditional samples": "At the i + 1th iteration, \u03c1N(i) samples distributed as \u03c0(\u03c6I(i + 1)) are available from the previous iteration. Using these samples as seeds, additional (1 \u03c1)N(i + 1) are simulated. The proposed method to simulate additional samples involves two steps: (a) randomly selecting a Voronoi cell within the subset I(i + 1) based on the estimate \u03c0(\u03c6I(i)) and (b) applying the MetropolisHastings algorithm within the selected Voronoi cell. A Voronoi cell is selected according to the following weights in the first step: w(i) k = \u03b7(i) k / V(i) k k \u03b7(i) k / V(i) k . (14) Fig. 2. Illustration of the proposed iSSO algorithm. M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 5 To simulate a new sample within a selected Voronoi cell, the sample that generated the selected Voronoi cell or the last simulated sample in the selected Voronoi cell is used as the seed sample, and the Metropolis Hastings algorithm is implemented. A candidate sample [\u03c6c,\u03b8c] is simulated using the proposal q(\u03c6c,\u03b8c\u03c6,\u03b8) and is accepted with the probability min(1, a0), where, a0 is given as: a0 = h(\u03c6c, \u03b8c)p(\u03c6c, \u03b8c)q(\u03c6, \u03b8\u03c6c, \u03b8c) h(\u03c6, \u03b8)p(\u03c6, \u03b8)q(\u03c6c, \u03b8c\u03c6, \u03b8) . (15) In the present study, the proposed PDF is equal to the uniform PDF for design parameters and the initial PDF for uncertain variables, i.e., q (\u03c6, \u03b8\u03c6c,\u03b8c) = p(\u03c6, \u03b8). Therefore, on simplifying (15), a0 is given as: a0 = h(\u03c6c, \u03b8c) h(\u03c6, \u03b8) . (16)",
        "3.4. Stopping criteria": "A new stopping criterion is proposed in this study. The convergence of the expected value of the performance measure h(\u03c6, \u03b8) with respect to the PDF for \u03c6 and \u03b8 in consecutive iterations is used as the stopping criterion. Mathematically the proposed stopping criterion is represented by: E\u03c6,\u03b8[h(\u03c6, \u03b8)]i E\u03c6,\u03b8[h(\u03c6, \u03b8)]i1 \u03b5 (17) where, \u03b5 is a userspecified tolerance limit. Other stopping criteria, as indicated in [39,47], can also be chosen.",
        "3.5. Implementation issues": "An important issue for the effective implementation of the iSSO is the creation of the Voronoi cells at the current iteration bounded within the Voronoi cell created at the previous iterations. Although it is possible to create such bounded Voronoi cells, due to the geometrical complexities, it is usually unfeasible for the higher dimensional problems (n\u03c62). An alternative approach is proposed in the present study for creating the Voronoi cells at any iteration of the iSSO. The proposed approach in volves creating Voronoi cells using the samples generated at the current and all previous iterations and then by considering Voronoi cells cor responding to the samples from the current iteration. This is shown in Fig. 3, where Fig. 3(a) shows the N samples at the first iteration and the corresponding Voronoi cells. Fig. 3(b) shows the \u03c1N selected Voronoi cells leading to the smallest volume density and the additional (1 \u03c1)N samples being generated using these \u03c1N samples as seeds. Fig. 3(c) shows that the Voronoi cells are generated using all N + (1 \u03c1)N samples that are generated in the two iterations. The Voronoi cells corresponding to the N samples for consideration at the second iteration are also highlighted in Fig. 3(c). Fig. 3(d) shows a zoomedin version of Fig. 3(c) where it can be observed that the area covered by the N Voronoi cells considered in the second iteration is not the same as the area covered by the \u03c1N Voronoi cells selected in the first iteration. On the contrary, the area covered by the Voronoi cells in the second iteration is more than the area covered by the Voronoi cells corresponding to the seed samples from the first iteration. This is because a new sample within the Voronoi cell between an existing sample and the existing Voronoi cell edge results in the relocation of the Voronoi cell edge in a Fig.",
        "3. Implementation of Voronoi tessellation in iSSO": ". M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 6 direction away from the new sample. The increase at each iteration in troduces a bias in the estimate of \u03c0(\u03c6I(i)) in (11). However, this does not affect the performance of the proposed approach as the objective is not to simulate the samples distributed as \u03c0(\u03c6I(i)) but to identify the subsets for an optimal solution. In addition, the increase is not substantial, as seen later in the illustrative examples in Section 4.",
        "3.6. Special case: deterministic optimization": "In the iSSO framework, a deterministic optimization problems can also be handled with the vector of uncertain variables \u03b8 set equal to a null vector (n\u03b8 = 0). Since the determination of the subset at each iSSO iteration is solely dependent on the samples distributed as \u03c0(\u03c6), no modification to the iSSO algorithm is required to solve a deterministic optimization problem, and the entire formulation remains valid.",
        "4. Illustrative examples": "In this section, typical optimization problems are considered to demonstrate the effectiveness and efficiency of the proposed approach. First, deterministic optimization problems are considered. These prob lems include several local and global minima. Next, stochastic optimi zation problems are illustrated. The second example presents an RDO problem of the TMD. In this example, the variance minimization of the protected structures displacement (TMD attached to the structure) is performed. In the third example, the mean minimization of 120 bars truss problems is explored to demonstrate the applicability of the pro posed approach to a highdimensional stochastic design problem. Finally, the fourth example investigates the reliabilitybased optimiza tion of a base isolation system for a 10story building. In this study, after implementing iSSO, the optimal design solution is identified as follows. Let \u03b8j, j = 1n be a set of independent, identically distributed realizations of \u03b8, and let h(\u03c6, \u03b8j) be the structural perfor mance function realization for \u03b8j. The expected structural performance function is approximated by the average of the realizations as: E\u03b8[h(\u03c6, \u03b8)] 1 n n j=1 h ( \u03c6, \u03b8j ) . (18) E\u03b8[h(\u03c6, \u03b8)] is evaluated for all unique \u03c6 samples obtained at the last iteration of the iSSO, and the \u03c6 sample resulting in the smallest value of E\u03b8[h(\u03c6, \u03b8)] is taken as the optimal solution. Alternatively, as the right hand side of (18) is deterministic, any deterministic optimization method can also be used to solve the optimization problem with the approximate expectation. In the following examples, both iSSO and SSO are implemented with N = 1000n\u03c6, \u03c1 = 0.20 and the stopping criteria as stated in (17). Here, a value of \u03b5 = 103 is adopted. Fig.",
        "4. Results for the Griewank function": ". M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 7",
        "4.1. Multimodal deterministic optimization problems": "In this section, three twodimensional benchmark deterministic optimization problems are considered. Results are also compared with the SSO. The test functions are: a) Griewank function: minh(\u03c6) = d i=1 \u03c62 i 4000 d i=1 cos (\u03c6i i ) + 1, s.t.\u03c6 = [ 10, 10] (19) b) CrossinTray function: minh(\u03c6) = 0.0001 (sin(\u03c61)sin(\u03c62)exp (100 \u03c62 1 + \u03c62 2 \u03c0 ) + 1 )0.1 , s.t.\u03c6 = [ 10, 10] (20) c) Holder Table function: minh(\u03c6) = sin(\u03c61)cos(\u03c62)exp (1 \u03c62 1 + \u03c62 2 \u03c0 ), s.t.\u03c6 = [ 10, 10] (21)) The results for the Griewank function are presented in Fig.",
        "4. Fig": ". 4(a, b) shows that the function has multiple closely spaced local minima with a single global minimum. Fig. 4(c, d) shows the SSO optimization using hyperrectangle and hyperellipse as shapes of admissible subsets. It is seen that these shapes fail to capture the region containing the optimal design due to the presence of multiple local minima. Next, the iSSO is implemented, where the Voronoi cells selected at the first and last iteration are shown in Fig. 4(e, f). It is observed that at the first iteration, the selected Voronoi cells effectively capture both the local and global minima and in the subsequent iterations, the selected cells are more concentrated near the global minimum. The region selected at the last iteration captures the optimal global solution. The CrossinTray function has a relatively complex design space compared to the Griewank function. Fig. 5(a, b) shows multiple local and global minima. Minimization by using SSO is demonstrated in Fig. 5 (c, d). It is found that both the hyperrectangle and hyperellipse are trapped around any one of the global minima. At the same time, the iSSO is able to capture the regions that include all of the global minima, as Fig.",
        "5. Results for the CrossinTray function": ". M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 8 seen in Fig. 5(e, f). The Holder Table function has multiple local and global minima; the global minima are placed at the boundary of the design space, as shown in Fig. 6(a, b). Once again, it is seen that both the hyperrectangle and hyperellipse are trapped around any of one of the global minima, and on the other hand, the iSSO is able to capture the regions that include all of the global minima, as seen in Fig. 6(e, f). The results from the three examples demonstrate that the proposed iSSO is able to capture the regions containing the optimal solution effectively. Next, the statistics of the results of 50 independent runs, both for SSO and iSSO are presented in Table 1. It also includes the results obtained by using stateoftheart approaches, such as the Genetic algorithm, particle swarm optimization, and the gradient based optimization approach (interiorpoint algorithm). The proposed iSSO outperforms all other approaches as more successes in determining the optimal solution are observed in all three optimization problems. It is also seen that both SSO and iSSO result in a similar value of volume reduction for the same stopping criterion; however, with SSO, the number of iterations required to achieve this volume reduction are relatively higher. The proposed approach outperformed the stateoftheart approaches, as indicated by the number of successes. These examples demonstrate that the main advantage of implementing Voronoi tessellation is an effective explo ration of the design space. Next, the performance of the proposed \"double sort algorithm\" for selecting the optimal subset is studied by using the abovementioned three functions. Fig. 7 shows the value of H(I(1)) for the 50 indepen dent simulation runs, which is estimated by implementing the proposed double sort algorithm and by using the Genetic algorithm. It can be noted that for each run, the H(I(1)) values obtained using the proposed double sort algorithm and Genetic algorithm are well matched, thereby confirming the adequacy of the proposed double sort algorithm. At any iteration of iSSO, new samples are simulated using the seed samples. In the proposed approach, the volume of the Voronoi cells corresponding to the seed and new samples is greater than the volume of the Voronoi cells corresponding only to the seed samples. Fig. 8 shows this change in volume V(seeds+new)V(seeds) V(seeds) due to the creation of Voronoi cells at any generation of iSSO using the procedure mentioned in Section 3.4. The increase is observed to be small which further reduces with an in crease in the iteration number. It is also observed that the increase in volume decreases with an increase in sample size at each iteration and increases with an increase in the dimension of the problem. 4.2. Robust design optimization of the tuned mass damper This example considers a stochastic design problem involving a Tuned Mass Damper (TMD) attached to a Single Degree of Freedom (SDOF) system. The problem is taken from [48] and is shown in Fig. 9. In this problem, the system is excited by a white noise signal with a mean zero and unit variance. The performance measure is the variance of the displacement of the system \u03c32 xs. The mass mS, stiffness kS, and Fig.",
        "6. Results for the Holder Table function": ". M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 9 damping cS of the system are taken as uncertain parameters, following independent Gaussian distribution. The mean value of these variables is taken to be 105 kg, 107 N/m, and 4 104 Ns/m respectively. To account for uncertainty, the c.o.v value for each variable taken is 0.05. The frequency ratio \u03b2 = \u03c9T /\u03c9S and damping \u03beT of the TMD are considered design parameters. The TMD has a mass ratio, mT/ms, of 0.10. The parameters mT,\u03c9T,and\u03c9S are, in order, the mass of the TMD, the natural frequency of the TMD ( kT/mT ), and the natural frequency of the structure ( ks/ms ). The optimization problem is written as: minimize : \u03c6\u03a6,\u03c6\u03a6 E\u03b8[h(\u03b8, \u03c6, \u03c6)] = E\u03b8 [( \u03c32 xs(\u03b8, \u03c6) \u03c6 )]2 , (22) Table 1 Statistics of optimization results for multimodal deterministic optimization problems. Example SSO iSSO GA* PSO* GBA* HyperRectangle HyperEllipse Griewank NF 30 32 5 38 35 47 NS 20 18 45 12 15 3 BV 0 0 0 0 0 0 WV 0.1028 0.1161 0.0270 0.0296 0.0232 0.0296 AV 0.0190 0.0292 0.0110 0.0094 0.0057 0.0173 c.o.v 1.1663 1.0168 0.5137 0.9603 0.8763 0.05971 FE 22,702 15,223 12,426 3385 1432 33 Gen 7 5 4 N/A VR 94.025 84.79 93.56 CrossInTray NF 50 50 1 50 50 50 NS 0 0 49 0 0 0 BV 2.0576 2.0626 2.0624 2.0626 2.0626 2.0626 WV 2.0472 2.0481 2.0260 2.0626 2.0626 1.3853 AV 2.0527 2.0621 2.0522 2.0626 2.0626 1.7360 c.o.v 0.0133 0.001 0.0042 0 0 0.0977 FE 27,563 21,595 9982 3178 933 32 Gen 9 7 3 N/A VR 99.89 98.95 88.71 HolderTable NF 50 50 3 50 50 50 NS 0 0 47 0 0 0 BV 19.2085 17.5025 19.2085 19.2085 19.2085 19.2085 WV 18.8916 1.1419 17.3030 9.5047 15.1402 1.1831 AV 19.0916 8.432 18.8798 19.0144 18.9745 6.5493 c.o.v 0.0025 0.3898 0.0182 0.0722 0.0443 0.8358 FE 40,700 24,684 18,142 3413 988 30 Gen 13 8 6 N/A VR 99.59 99.42 94.37 GA = genetic algorithm, PSO = particle swarm optimization, GBA = gradientbased optimization approach, NF = no. of. failure, NS = no. of. success, BV = best value, WV = worst value, AV = average value, c.o.v = coefficient of variation, FE = no. of. function evaluations, Gen = generations, VR = volume reduction percentage, * = efficiently applicable only for deterministic problems. Fig.",
        "7. Comparison of double sort algorithm and Genetic algorithm results": ". Fig.",
        "8. Percentage change in volume at each iSSO iteration": ". M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 10 where, 0.01 \u03b2 1.5, 0.01 \u03beT 1.0, 0 \u03c6 1000. (23) Table 2 presents the optimal design parameter values as well as the objective function value that solve the optimization problem in (22). Results obtained using SSO, Sample Average Approximation (SAA), and iSSO are shown. SAA is applied with a sample size of 103, as mentioned in [43]. The results demonstrate that iSSO is effective in locating the optimal solution. SSO implemented with hyperellipse gives an optimal solution but has a higher computational cost. 4.3. 120bars truss structure The third example involves minimizing the mean of the compliance of a 120bar linear elastic truss structure shown in Fig. 10 under the weight constraint W 15, 000kg. Because of structural symmetry, design parameters corresponding to the crosssectional areas of elements are divided into seven groups, each with a minimum area of 104 m2. The Youngs modulus for the bar groups are assumed as uncorrelated normal random variables with mean values equal to 210 GPa and the c. o.v equal to 0.10 respectively. The density of the material is 7971.89 kg/ m3. The dome is subjected to concentrated vertical loads acting down ward at the top node, normally distributed with a mean equal to 60 kN and c.o.v equal to 0.20. In addition, the mass of bars is concentrated at the nodes. The problem is taken from [48]. Table 3 presents the best of 10 independent run results obtained with SSO and iSSO. Once again, the SSO and iSSO solutions agree well, thereby demonstrating the effectiveness of the proposed approach. At the same time, the number of function evaluations is substantially less in the case of iSSO, indicating the efficiency of the proposed approach. 4.4. Reliabilitybased design of a base isolated structure This example, adapted from [49], involves the reliabilitybased Fig.",
        "9. TMD attached to a SDOF system [48]": ". Table 2 Variance minimization of TMDstructure. Method Admissible Subset shape Design parameters E\u03b8[h(\u03b8,\u03c6,\u03c6)] ( 1016 mm4) FE NS NF \u03b2 \u03beT SSO [48] HyperRectangle 0.551 0.623 41.324 7433 0 50 HyperEllipse 0.749 0.221 1.7586 8245 34 16 SAA N/A 0.749 0.221 1.7587 3 106 4 46 iSSO Voronoi tessellation 0.749 0.221 1.7586 6198 50 0 Fig. 10. 120bar dome truss structure [48]. Table 3 Results for the 120 bars truss structure. Method Design parameters \u03bcg(\u03c6) (Nm) \u03c32 g (\u03c6) (Nm)2 FE A1 (cm2) A2 (cm2) A3 (cm2) A4 (cm2) A5 (cm2) A6 (cm2) A7 (cm2) SSO [48] 47.2 67.5 42.7 9.4 30.1 55.6 13.1 242.3 5294.2 54,700 SAA 47.3 68.3 40.7 10.5 30.3 49.5 14.8 243.5 5407.4 3 106 iSSO 48.1 66.4 42.6 8.5 31.4 56.5 12.5 242.8 5317.2 14,937 M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 11 optimization of a baseisolation system attached to a 10story building as shown in Fig. 11. This optimization problem includes maximizing the reliability of the baseisolated structure which is performed by the minimization of its failure probability and mathematically expressed as: minimize : \u03c6\u03a6 P(F\u03c6) = E\u03b8[IF(\u03c6, \u03b8)] = \u0398 IF(\u03c6, \u03b8)p(\u03c6, \u03b8)d\u03b8, (24) where, IF(\u03c6,\u03b8) is the function that indicates failure, and it equals 1 when the system fails, i.e., when unacceptable performance occurs. Notably, in this problem h(\u03c6, \u03b8) = IF(\u03c6,\u03b8). The 10story building is considered as a shear structure with un certain interstory stiffness and damping. Each story has a total mass of 207 ton. The interstory stiffness ki of all stories are parameterized by ki = ki\u03b8i, i = 1, , 10 where the most probable values of the interstory stiffness are [ki] = [687.1, 613.1, 540.1, 481.1, 421.7, 353.7, 286.6, 225.6, 184.5, 104.5] MN/m. The entity \u03b8i is a set of nondimensional uncertain variables that are considered to be correlated Gaussian vari ables with a unit mean value \u03b8i = 1, i and a covariance matrix defined as: E [ (\u03b8i \u03b8i) ( \u03b8j \u03b8j )] = (0.2)2exp [ (j i)2 / 22] . (25) The damping ratios are considered independent Gaussian variables with mean values of 0.025 and c.o.v of 0.10 for all modes. The Kanai Tajimi model is used to simulate the ground excitation modelled as a filtered white noise process, with the power spectral density function given as: S(\u03c9) = S0 \u03c94 g + 4\u03b62 g\u03c92 g\u03c92 ( \u03c92 g \u03c92 )2 + 4\u03b62 g\u03c92 g\u03c92 , (26) S0 = \u03c32 \u03c9 2\u03b6g \u03c0\u03c9g ( 4\u03b62 g + 1 )m2 / s3, (27) where, \u03c9g, \u03b6gand \u03c3\u03c9 are the resonant frequency, damping, and RMS of the acceleration input of the filter, respectively. These are also considered uncertain variables with mean values of [2\u03c0rad/s, 0.5, 0.2g] and a c.o.v equal to 0.20. The nonstationarity of the excitation is modeled by multiplying the filter output with the envelope function as: e(t) = \u03bb3t\u03bb1exp( \u03bb2t), (28) with parameters \u03bb1 = 1.25, \u03bb2 = 0.2 and \u03bb3 = 0.353 chosen to simulate strong earthquake excitation for a duration of 40 s with a sampling time of 0.02 s. The baseisolation system considered is a leadrubber bilinear isolator with an additional viscous damper. The base has a 247ton mass. The design parameters \u03c6 for the base isolation structure system are the stiffness before yielding Kprand after yielding Kp, the yield force is Fy, and the damping coefficient cd. The reader may refer to [39,50] for additional details regarding the base isolation structure system adopted in this study. Failure is indicated when any of the normalized base displacements or interstory drifts exceeds unity. The normalization constants are 0.5 m and 0.033 m respectively. The design interval for each variable is specified as Kpr = [50, 600] MN/m, Fy = [1, 8] MN, Kp = [5, 60] MN/m, and cd = [0.1, 10]MNs/m. In this example, iSSO and SSO are imple mented with six number of iterations. Table 4 shows the optimization results for the best 10 independent simulation runs. The comparison of the results obtained using SSO, SAA (with a sample size of 103), and iSSO shows that the optimal design obtained using the proposed approach iSSO is in good agreement. The failure probability of the structure is reduced from 0.95 (without the base isolation system) to 0.0326 after installing the optimally designed base isolation system. 5. Conclusion This study attempts to provide an optimization approach called \"iSSO\", which is an improved version of SSO, primarily for stochastic optimization problems while it retains utility for deterministic optimi zation problems as well. Two novel ideas are introduced in this study: first, a better characterization of the design space is offered by parti tioning the design space into nonoverlapping subregions using Voronoi Fig. 11. (left) 10story base isolated shear model, and (right) forcedeformation of bilinear isolator [49]. Table 4 Base isolation structure system optimization results (best of 10 independent runs). Method Design parameters (\u03c6*) Failure probability PF(\u03c6*) Kpr (MN/ m) Fy (MN) Kp (MN/ m) cd (MNs/ m) SSO [39] 425.33 1.20 15.52 6.54 0.0340 SAA 414.68 1.16 16.15 6.26 0.0324 iSSO 418.34 1.11 15.88 7.08 0.0366 M.A. Khalid and S. Bansal Advances in Engineering Software 188 (2024) 103568 12 tessellation which improves the effectiveness and efficiency of the pro posed iSSO considerably in comparison to SSO. Second, a novel \"double sort\" approach is proposed, eliminating the need for optimization to identify the subregions for the optimal design at each iSSO iteration. Several mathematical and engineering design examples, including TMD, 120 bars truss structure, and baseisolated structure, are included in this study to demonstrate the efficacy of the proposed iSSO. The results show that the proposed iSSO effectively identifies the reduced design space for complex design problems with multiple global and local minima. This is attributable to the Voronoi tessellation, which eliminates the require ment of the presumed admissible design space form to resemble the contour of the original design. Voronoi tessellation enabled better design space exploration, allowing multiple global minima scattered throughout the design pace to be effectively identified. Due to the dis cretization of the design space via Voronoi tessellation, computation demand is significantly reduced as the number of function evaluations for all examples is lower visavis the original SSO. Moreover, the novel idea of the double sort approach achieves the requisite precision in identifying the subregions for optimal solutions and makes iSSO implementation simple and effective. The applicability of the approach is dependent on the creation of the Voronoi cells. At present the methods available in the literation for creating the Voronoi tessellation are computationally demanding when considering problems of very high dimension. Future work will focus on developing a method for creating the Voronoi tessellation in higher di mensions, particularly those greater than ten. CRediT authorship contribution statement Mohd Aman Khalid: Investigation, Methodology, Formal analysis, Software, Visualization, Writing original draft. Sahil Bansal: Conceptualization, Methodology, Supervision. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability No data was used for the research described in the article. AppendixA: Voronoi Tessellation Voronoi tessellation is a mathematical concept named after the Russian mathematician Georgy Voronoi. It is also known as the Voronoi diagram or Dirichlet tessellation. A Voronoi tessellation of a set of points P in a plane is a partition of the plane into a set of nonoverlapping convex polygons, with each polygon including precisely one point of P and each point in a polygon being closer to its associated point in P than to any other point in P. Each polygon is referred to as a Voronoi cell or a Dirichlet region. The boundary of each cell is constituted of points that are equidistant to two or more points in P. Fig. 12 shows the Voronoi diagram in a twodimensional design space. Fig. 12. Voronoi diagram in 2dimensional space. There are several efficient algorithms for creating Voronoi diagrams. One such basic algorithm is to start with a set of points and then compute the Voronoi cells by dividing the space into regions based on the distance to the nearest point. The BowyerWatson algorithm [51], which generates a Delaunay triangulation in any number of dimensions, can be applied while creating a Voronoi diagram. The Delaunay triangulation is a triangulation of the point in which no point falls within the circumcircle of any triangle. The polygon generated by the intersection of the halfplanes defined by the edges of the Delaunay triangles enclosing the point is therefore obtained as the Voronoi cell of a point. It can be summarized that Voronoi tessellation is a powerful mathematical concept that aids in dividing space into regions based on the distance to a set of points. Voronoi tessellation finds widespread applications in areas such as image processing [52], spatial topology analysis [53], and microstructure study [52]. The MATLAB command \"Voronoin\" from the \"Parallel Computing Toolbox\" [54] has been used in this study to create the Voronoi cells."
    },
    "references": [
        "[1] Marti K. Stochastic optimization methods. Berlin: Springer; 2008. ",
        "[2] Tsompanakis Y, Lagaros ND, Papadrakakis M. Structural design optimization considering uncertainties. CRC Press; 2008. ",
        "[3] Khalid MA, Bansal S, Ramamohan V. An augmented formulation for robust design optimization of structures using stochastic simulation method. Res Eng Des 2023; 34:179200. https://doi.org/10.1007/s0016302200405z. ",
        "[4] Meng Z, Li G, Wang X, Sait SM, R\u0131za A. A comparative study of metaheuristic algorithms for reliability based design optimization problems. Arch Comput Methods Eng 2021;28:185369. https://doi.org/10.1007/s1183102009443z. ",
        "[5] Abualigah L, Elaziz MA, Khasawneh AM, Alshinwan M. Metaheuristic optimization algorithms for solving realworld mechanical engineering design problems : a comprehensive survey, applications, comparative analysis, and results. Neural Comput Appl 2022;34:4081110. https://doi.org/10.1007/s00521 021067474. ",
        "[6] Katebi J, Shoaei M, Nguyen S, Trung T, Khorami M. Developed comparative analysis of metaheuristic optimization algorithms for optimal active control of M.A. Khalid and S. Bansal",
        "[7] Alorf A. Engineering applications of artificial intelligence a survey of recently developed metaheuristics and their comparative analysis. Eng Appl Artif Intell 2023;117:105622. https://doi.org/10.1016/j.engappai.2022.105622. ",
        "[8] Kirsch U. Structural optimization: fundamentals and applications. SpringerVerlag; 2012. ",
        "[9] Floudas CA, Pardalos PA. Encyclopedia of optimization. Springer; 2008. ",
        "[10] Kiureghian AD, Ditlevsen O. Aleatory or epistemic? Does it matter? Struct Saf 2009;31:10512. https://doi.org/10.1016/j.strusafe.2008.06.020. ",
        "[11] Schueller GI, Jensen HA. Computational methods in optimization considering uncertainties an overview. Comput Methods Appl Mech Eng 2008;198:213. https://doi.org/10.1016/j.cma.2008.05.004. ",
        "[12] Schneider J, Kirkpatrick S. Stochastic optimization. Springer; 2007. ",
        "[13] Do B, Ohsaki M. A random search for discrete robust design optimization of linear elastic steel frames under interval parametric uncertainty. Comput Struct 2021; 249:106506. https://doi.org/10.1016/j.compstruc.2021.106506. ",
        "[14] Asadpoure A, Tootkaboni M, Guest JK. Robust topology optimization of structures with uncertainties in stiffness application to truss structures. Comput Struct 2011. https://doi.org/10.1016/j.compstruc.2010.11.004. ",
        "[15] Doltsinis I, Kang Z. Robust design of structures using optimization methods. Comput Methods Appl Mech Eng 2004;193:222137. https://doi.org/10.1016/j. cma.2003.12.055. ",
        "[16] Carneiro G, das N, Antonio CC. Dimensional reduction applied to the reliability based robust design optimization of composite structures. Compos Struct 2021; 255. https://doi.org/10.1016/j.compstruct.2020.112937. ",
        "[17] An H, Youn BD, Kim HS. Reliabilitybased design optimization of laminated composite structures under delamination and material property uncertainties. Int J Mech Sci 2021. https://doi.org/10.1016/j.ijmecsci.2021.106561. ",
        "[18] Li Z, Duan LB, Cheng AG, Yao ZP, Chen T, Yao W. Lightweight and crashworthiness design of an electric vehicle using a sixsigma robust design optimization method. Eng Optim 2019. https://doi.org/10.1080/0305215X.2018.1521396. ",
        "[19] Gholinezhad H, Torabi SH. Reliabilitybased multidisciplinary design optimization of an underwater vehicle including cost analysis. J Mar Sci Technol 2021. https:// doi.org/10.1007/s00773021008042. ",
        "[20] Lee KH, Park GJ. Robust optimization considering tolerances of design variables. Comput Struct 2001;79:7786. https://doi.org/10.1016/S00457949(00)001176. ",
        "[21] Anderson TV, Mattson CA. Propagating skewness and kurtosis through engineering models for lowcost, meaningful, nondeterministic design. J Mech Des Trans ASME. 2012. https://doi.org/10.1115/1.4007389. ",
        "[22] Zhou Q, Wang Y, Choi SK, Jiang P, Shao X, Hu J, Shu L. A robust optimization approach based on multifidelity metamodel. Struct Multidiscip Optim 2018. https://doi.org/10.1007/s0015801717834. ",
        "[23] Wang GG, Shan S. Review of metamodeling techniques in support of engineering design optimization. J Mech Des Trans ASME. 2007;129:37080. https://doi.org/ 10.1115/1.2429697. ",
        "[24] Chatterjee T, Chakraborty S, Chowdhury R. A critical review of surrogate assisted robust design optimization. Arch Comput Methods Eng 2019;26:24574. https:// doi.org/10.1007/s1183101792405. ",
        "[25] Chatterjee T, Friswell MI, Adhikari S, Chowdhury R. A global twolayer meta model for response statistics in robust design optimization. Eng Optim 2021. https://doi.org/10.1080/0305215X.2020.1861262. ",
        "[26] Guo X, Zhao X, Zhang W, Yan J, Sun G. Multiscale robust design and optimization considering load uncertainties. Comput Methods Appl Mech Eng 2015;283: 9941009. https://doi.org/10.1016/j.cma.2014.10.014. ",
        "[27] Jerez DJ, Jensen HA, Beer M. Reliabilitybased design optimization of structural systems under stochastic excitation: an overview. Mech Syst Signal Process 2022. https://doi.org/10.1016/j.ymssp.2021.108397. ",
        "[28] Li W, Gao L, Xiao M. Multidisciplinary robust design optimization under parameter and model uncertainties. Eng Optim 2020;52:42645. https://doi.org/10.1080/ 0305215X.2019.1590564. ",
        "[29] Beyer HG, Sendhoff B. Robust optimization a comprehensive survey. Comput Methods Appl Mech Eng 2007;196:3190218. https://doi.org/10.1016/j. cma.2007.03.003. ",
        "[30] Motta R, de S, Afonso SMB. An efficient procedure for structural reliabilitybased robust design optimization. Struct Multidiscip Optim 2016;54:51130. https://doi. org/10.1007/s0015801614181. ",
        "[31] Yildiz AR. Comparison of evolutionarybased optimization algorithms for structural design optimization. Eng Appl Artif Intell 2013;26:32733. https://doi. org/10.1016/j.engappai.2012.05.014. ",
        "[32] Beck AT, Gomes WJDS. A comparison of deterministic, reliabilitybased and risk based structural optimization under uncertainty. Probab Eng Mech 2012;28:1829. https://doi.org/10.1016/j.probengmech.2011.08.007. ",
        "[33] Acar, E., Bayrak, G., Jung, Y., Lee, I., Ramu, P., Ravichandran, S.S.: Modeling, analysis, and optimization under uncertainties: a review, (2021). 10.1007/s001 58021030267. ",
        "[34] Georghiou A, Kuhn D, Wiesemann W. The decision rule approach to optimization under uncertainty: methodology and applications. Comput Manag Sci 2019. https://doi.org/10.1007/s1028701803385. ",
        "[35] Braydi O, Lafon P, Younes R. Study of uncertainties and objective function modeling effects on probabilistic optimization results. ASCE ASME J Risk Uncertain Eng Syst Part B Mech Eng 2019. https://doi.org/10.1115/1.4044152. ",
        "[36] Liu WS, Cheung SH. Reliability based design optimization with approximate failure probability function in partitioned design space. Reliab Eng Syst Saf 2017;167: 60211. https://doi.org/10.1016/j.ress.2017.07.007. ",
        "[37] Chiralaksanakul A, Mahadevan S. Firstorder approximation methods in reliability based design optimization. J Mech Des Trans ASME 2005. https://doi.org/ 10.1115/1.1899691. ",
        "[38] Doltsinis I, Kang Z, Cheng G. Robust design of nonlinear structures using optimization methods. Comput Methods Appl Mech Eng 2005;194:177995. https://doi.org/10.1016/j.cma.2004.02.027. ",
        "[39] Taflanidis AA, Beck JL. Stochastic Subset Optimization for optimal reliability problems. Probab Eng Mech 2008. https://doi.org/10.1016/j. probengmech.2007.12.011. ",
        "[40] Au SK, Beck JL. Estimation of small failure probabilities in high dimensions by subset simulation. Probab Eng Mech 2001;16:26377. https://doi.org/10.1016/ S02668920(01)000194. ",
        "[41] Jia GF, Taflanidis AA. Nonparametric stochastic subset optimization for optimal reliability design problems. Comput Struct 2013;126:8699. https://doi.org/ 10.1016/j.compstruc.2012.12.009. ",
        "[42] Taflanidis AA. Stochastic subset optimization incorporating moving least squares response surface methodologies for stochastic sampling. Adv Eng Softw 2012;44: 314. https://doi.org/10.1016/j.advengsoft.2011.07.009. ",
        "[43] Khalid MA, Bansal S. Framework for robust design optimization of tuned mass dampers by stochastic subset optimization. Int J Struct Stab Dyn 2023;23. https:// doi.org/10.1142/S0219455423501559. ",
        "[44] Au SK. Reliabilitybased design sensitivity by efficient simulation. Comput Struct 2005;83:104861. ",
        "[45] Taflanidis AA, Beck JL. An efficient framework for optimal robust stochastic system design using stochastic simulation. Comput Methods Appl Mech Eng 2008. https:// doi.org/10.1016/j.cma.2008.03.029. ",
        "[46] Robert CP, Casella G. Monte carlo statistical methods. New York, NY: Springer; 2004. ",
        "[47] Li HS. Subset simulation for unconstrained global optimization. Appl Math Model 2011;35:510820. https://doi.org/10.1016/j.apm.2011.04.023. ",
        "[48] Khalid MA, Bansal S, Ramamohan V. An augmented formulation for robust design optimization of structures using stochastic simulation method. Res Eng Des 2022. https://doi.org/10.1007/s0016302200405z. ",
        "[49] Taflanidis AA, Beck JL. An efficient framework for optimal robust stochastic system design using stochastic simulation. Comput Methods Appl Mech Eng 2008;198: 88101. https://doi.org/10.1016/j.cma.2008.03.029. ",
        "[50] Kandemir EC, Mortazavi A. Optimization of seismic base isolation system using a fuzzy reinforced swarm intelligence. Adv Eng Softw 2022;174:103323. https://doi. org/10.1016/j.advengsoft.2022.103323. ",
        "[51] Rebay S. Efficient unstructured mesh generation by means of delaunay triangulation and BowyerWatson algorithm. J Comput Phys 1993;106:12538. ",
        "[52] Wade N, GrahamBrady L. Estimating microstructural feature distributions from image data using a Bayesian framework. J Microsc 2023:116. https://doi.org/ 10.1111/jmi.13184. ",
        "[53] Duan X, Li L, Ge Y, Liu B. Exact Voronoi diagram for topographic spatial analysis. GIScience Remote Sens 2023;60. https://doi.org/10.1080/ 15481603.2023.2171703. ",
        "[54] MATLAB and parallel computing toolbox release. Natick, Massachusetts, United States: The Mathworks, Inc.; 2021. M.A. Khalid and S. Bansal"
    ]
}